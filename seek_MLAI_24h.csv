Job ID,Job Title,Company,Detail URL,Posted Label,Hours Old,Posted Datetime (Local),Location,Category,Work Type,Salary,Ad Text
89268123,MuleSoft Developer,Slade Group,https://www.seek.com.au/job/89268123?type=standard&ref=search-standalone&origin=jobCard#sol=f26b702e65eb288e4b151f626cce2116420d8e03,1h ago,1.0,2025-12-22T01:00:00+00:00,Melbourne VIC (Hybrid),Developers/Programmers (Information & Communication Technology),Full time,,"We’re looking for an experienced MuleSoft Developer to join our growing integration team and help design, build, and support scalable enterprise integrations across a modern technology ecosystem.

You’ll play a key role in developing new APIs and integration interfaces, enhancing existing codebases, and ensuring smooth communication between multiple enterprise systems. 

What You’ll Do
Design, develop, and maintain MuleSoft integrations and APIs using Mule 4 and Anypoint Platform
Translate technical requirements into scalable and reusable integration solutions
Deliver high-quality, well-documented code
Support existing integrations through analysis, troubleshooting, and defect resolution
Contribute to proofs of concept and prototypes for new connectors and patterns
Collaborate with architects and leads to ensure alignment with integration standards
Work within GitHub, following defined branching and CI/CD practices
What You’ll Bring
5-7+ years’ experience in MuleSoft integration development
Strong knowledge of Mule 4, Anypoint Studio, API Manager, Runtime Manager, and Exchange
Solid understanding of API-led architecture and common integration patterns
Hands-on experience with JMS technologies (e.g. ActiveMQ)
Proficiency with DataWeave, batch processing, exception handling, and OAuth 2.0 security
Familiarity with DevOps practices (Azure DevOps, GitHub, CI/CD pipelines)
Excellent problem-solving and debugging skills across multiple environments
Clear communication skills and the ability to collaborate with technical and non-technical stakeholders
Bonus points if you have:

Experience with SAP connectors
MuleSoft Certification (Developer or Architect)
Degree in Computer Science, Engineering, or Information Systems
If this position is of interest, click APPLY today or contact Sam Makdesi on smakdesi@synchropartners.com.au"
89267844,Senior Engineer - MQ-28 Data Architect,Boeing Defence Australia,https://www.seek.com.au/job/89267844?type=standard&ref=search-standalone&origin=jobCard#sol=fbc816e7276babccf964ced20f6f2d5ae1737325,1h ago,1.0,2025-12-22T01:00:00+00:00,Brisbane QLD (Hybrid),Engineering - Software (Information & Communication Technology),Full time,,"The Opportunity

The Boeing MQ-28 - Ghost Bat is a globally significant program delivering disruptive advantage to support Defence operational capabilities. Developed in partnership with the Royal Australian Air Force, it is the first military combat aircraft to be designed, manufactured and assembled in Australia in 50 years. 

MQ-28 is expanding globally with international customers as well as its international design and partner network. Those ambitions require a Global Digital Ecosystem that facilitates a global military digital design network as well as closer ongoing digital collaboration with military operators. 

Role overview

You will define and lead the evolution of a capability-based MQ-28 Global Digital Ecosystem ensuring it is secure, adhering to export-compliant digital architectures and solution patterns that enable global design collaboration. 

Key responsibilities

Design and implement a Global Digital Ecosystem solution architecture for complex, multi‑stakeholder Defence programs
Work with export control and the MQ-28 Data Architect ensuring data sovereignty and contractual IP/data rights as they relate to cloud and collaboration platforms
Lead platform selection and migration for digital toolchains
Produce architectural artefacts such as capability maps, sequence/flow diagrams, data models, interface specifications
Stakeholder engagement with senior leaders and international partners 

Essential skills & experience

Deep understanding of cloud and hybrid integration patterns, including secure data flows, identity federation, multi‑tenant isolation and cross‑jurisdictional compliance
Proven experience in business or solution architecture roles for complex, multi‑stakeholder engineering or defence programs
Expertise in capability‑based planning and translating capability maps into implementable solution roadmaps
Strong background in systems thinking and ability to map value streams across engineering, manufacturing, supply chain and sustainment
Practical experience working with digital engineering toolchains
Excellent stakeholder engagement, communication and leadership skills with ability to influence senior leaders and international partners.
Australian Citizenship (required for Defence security clearance). 

Desirable skills & experience

Hands-on experience with tools such as 3DExperience, Teamcenter, CATIA, NX, DOORS, Ansys, Matlab, GitLab, Python and secure cloud platforms (AWS/Azure/GCP)
Familiarity with model-based systems engineering (MBSE) and digital thread concepts
Practical experience automating tasks via scripting and CI/CD for engineering toolchains
Prior exposure to international defence programs or globally distributed supplier networks 

Other benefits

Work on cutting edge projects with opportunities to work across platforms
Attractive remuneration and annual bonus
Formal reward and recognition program
Access discounts for health insurance, travel and accommodation
Paid parental leave and Defence leave
Salary packaging options available
Health and wellbeing benefits include annual flu vaccinations and Employee Assistance Program
Social and community groups 

BDA works with strong links with our global Boeing community, and we strongly encourage collaboration with our international counterparts.

 We are committed to building a diverse and inclusive workplace. Female applicants, people of Aboriginal or Torres Strait Island descent and veterans are encouraged to apply.

 Please note, this role will be shortlisted in 2026. Your patience is appreciated."
89267798,AI Analyst,DataMesh,https://www.seek.com.au/job/89267798?type=standard&ref=search-standalone&origin=jobCard#sol=57b74f82fad9e84d90dd6fe8326fc8944e185e7b,1h ago,1.0,2025-12-22T01:00:00+00:00,Sydney NSW (Hybrid),Business/Systems Analysts (Information & Communication Technology),Full time,,"Our Story!
DataMesh Group (DMG) is revolutionising the payment systems available to merchants and retailers, delivering integrated payment capabilities and valuable customer insights through bespoke payment and data processing solutions.
The company is in an exciting growth phase, and we are looking for individuals with the appetite and energy to make impactful changes and accelerate their career development with this unique opportunity!

Smarter connections, infinite possibilities! ��
  
About the role
As an AI Analyst, you will work closely with product, engineering, data, and business teams to analyse data, develop AI-driven insights, and support the deployment of machine learning and automation solutions. This role is ideal for someone who enjoys bridging the gap between technical capability and commercial outcomes in a fast-paced tech environment.
  
What you’ll be doing

Analyse large, complex datasets to identify patterns, trends, and insights that support AI and machine learning initiatives.
Support the development, testing, and monitoring of AI and ML models used across products and internal systems.
Translate business problems into analytical and AI-driven solutions.
Partner with product and engineering teams to integrate AI models into software applications.
Build dashboards, reports, and visualisations to communicate insights to stakeholders.
Monitor model performance, data quality, bias, and drift, recommending improvements as needed.
Ensure AI solutions align with regulatory, ethical, and data governance standards, particularly in a fintech context.
  
  
  
What we’re looking for

3–6 years’ experience in data analytics, AI, or machine learning roles, ideally within software, fintech, or technology-led environments.
Bachelor’s degree in Data Science, Computer Science, Mathematics, Statistics, Engineering, or a related field. Postgraduate qualifications are advantageous.
Strong analytical and problem-solving skills with the ability to translate data into actionable insights.
Experience working with machine learning models, statistical analysis, and data pipelines.
Proficiency in tools such as Python, SQL, and data visualisation platforms (e.g. Power BI, Tableau, Looker).
Familiarity with cloud platforms and AI frameworks (e.g. AWS, GCP, Azure, TensorFlow, PyTorch) is desirable.
Strong communication skills and confidence working with both technical and non-technical stakeholders.
  

Why You’ll Love Working with Us

Innovation at Its Core:Be part of a company that’s shaping the future of tech with cutting-edge solutions
Collaborative Culture:Work with smart, driven, and supportive teammates who value your input
Career Growth:Enjoy a clear path for growth and development in an expanding organisation
Impactful Work:See the results of your efforts as you help bring transformative projects to life
Social Perks: Enjoy company events, including lunches, celebrations and after work drinks!
 
If you’re ready to make an impact in the payments tech space and thrive in an agile, high-growth environment, we’d love to chat! ��"
89267405,Control Systems Engineer (Full-time),AIM Defence,https://www.seek.com.au/job/89267405?type=standard&ref=search-standalone&origin=jobCard#sol=315bd58ad3e6f3c1cc2a7efa20e52bce07a5682e,1h ago,1.0,2025-12-22T01:00:00+00:00,"Port Melbourne, Melbourne VIC",Electrical/Electronic Engineering (Engineering),Full time,,"The Role 

AIM is a deep-tech startup building advanced high power laser systems to protect people from weaponised drones. We are seeking a highly motivated and skilled Control Systems Engineer. At AIM, you will be an integral part in the Engineering and R&D team to develop leading edge products and systems for use in tomorrow’s defence technology. We are looking for candidates who are flexible and available to work overtime, based on business needs at our Melbourne facility. 

 What You will do 

Develop software and control systems for precision tracking and mechanical systems 

Work heavily in C++ and CUDA 

Build control systems that vary from PID loops to advanced model predictive and intelligent control in both SISO and MIMO environments  

Write, modify and debug software for embedded and local compute-based applications 

Provide input to architecture discussions 

Use source debuggers and visual development environments, including advanced tools for debugging multi-threaded applications. 

Document research and metrics-based outcomes for improvement and exploration 

Ensure work meets scheduled requirements and brings a software deliverable to completion. 

Provide technical support and mentoring. 

Assist in preparing work estimates and project schedules for work to be performed. 

Work as part of a multi-disciplinary fast paced development team 

Provide leadership to other team members 

Work closely with managers, engineers, and technicians to produce a wide variety of components 

 What You will bring 

Experience with C++, preferably more than 4 years 

A very strong understanding of control theory and intelligent control systems 

Experience with CUDA a bonus 

Tertiary degree in an engineering, science, or computer science discipline preferred 

Experience working with both local compute and embedded platforms 

Experience with python a bonus but not a hard requirement 

Familiarity with source code control and document configuration management systems 

Have excellent time management skills as you will need to be able to prioritise workloads and shift focus as necessary. 

Experience doing the detailed analysis necessary to make data driven decisions 

Ability to work cross-functionally to develop new solutions 

Able to work well under pressure while managing competing demands and tight deadlines 

Work efficiently and productively in independent and team settings 

Exemplary verbal and written communication skills 

Strong organisational skills with meticulous attention to detail 

Ability to acquire a Negative Vetting Level 1 (NV1) Security Clearance 

As a Defence security clearance is required for this role, applicants must be Australian citizens and eligible to obtain and maintain a Negative Vetting Level 1 (NV1) clearance. To learn more about clearances please visit – http://www.defence.gov.au/AGSVA 


How You Will Benefit 

Competitive remuneration 

Exciting projects and industry leading innovations 

Professional learning and development opportunities 

Opportunity to innovate and work in a fast-paced team 

Challenges at the edge of what’s possible 

 We are committed to ensuring diversity; inclusion and equality are embedded throughout our organisation for the benefit of our customers and our team. We strive for a positive and engaging workplace where mental health and wellbeing are supported. We welcome applicants from all diverse backgrounds, including Aboriginal and Torres Strait Islander people. If you are looking for a unique and exciting opportunity, we look forward to your application."
89267334,Computer Vision Engineer (Full-time),AIM Defence,https://www.seek.com.au/job/89267334?type=standard&ref=search-standalone&origin=jobCard#sol=d6467eed20923b26c6498cbc72e9f81197bb5821,1h ago,1.0,2025-12-22T01:00:00+00:00,"Port Melbourne, Melbourne VIC",Engineering - Software (Information & Communication Technology),Full time,,"The Role 

AIM is a deep-tech startup building advanced high power laser systems to protect people from weaponised drones. We are seeking a highly motivated and skilled Computer Vision Engineer. At AIM, you will be an integral part in the Engineering and R&D team to develop leading edge products and systems for use in tomorrow’s defence technology. We are looking for candidates who are flexible and available to outside of ordinary hours based on business needs at our Melbourne facility. 

 
What You Will Do

Develop software for precision detection and tracking systems 

Work heavily in CUDA on DSP, Neural Network, and classic machine vision applications 

Write, modify and debug software for embedded and GPU based applications 

Provide input to architecture discussions 

Use source debuggers and visual development environments, including advanced tools for debugging multi-threaded applications. 

Document research and metrics-based outcomes for improvement and exploration 

Ensure work meets scheduled requirements and brings a software deliverable to completion. 

Provide technical support and mentoring. 

Assist in preparing work estimates and project schedules for work to be performed. 

Work as part of a multi-disciplinary fast paced development team 

Provide leadership to other team members 

Work closely with managers, engineers, and technicians to produce a wide variety of components 


 What You Will Bring

Experience with C++ and CUDA preferably more than 4 years 

Tertiary degree in an engineering, science, or computer science discipline preferred 

Experience working with both GPU and embedded platforms 

Experience with python a bonus but not a hard requirement 

Familiarity with source code control and document configuration management systems 

Have excellent time management skills as you will need to be able to prioritise workloads and shift focus as necessary. 

Experience doing the detailed analysis necessary to make data driven decisions 

Ability to work cross-functionally to develop new solutions 

Able to work well under pressure while managing competing demands and tight deadlines 

Work efficiently and productively in independent and team settings 

Exemplary verbal and written communication skills 

Strong organisational skills with meticulous attention to detail 

Ability to acquire a Negative Vetting Level 1 (NV1) Security Clearance 

As a Defence security clearance is required for this role, applicants must be Australian citizens and eligible to obtain and maintain a Negative Vetting Level 1 (NV1) Security Clearance. To learn more about clearances please visit – http://www.defence.gov.au/AGSVA 


How You Will Benefit

Competitive remuneration 

Exciting projects and industry leading innovations 

Professional learning and development opportunities 

Opportunity to innovate and work in a fast-paced team 

Challenges at the edge of what’s possible 




We are committed to ensuring diversity; inclusion and equality are embedded throughout our organisation for the benefit of our customers and our team. We strive for a positive and engaging workplace where mental health and wellbeing are supported. We welcome applicants from all diverse backgrounds, including Aboriginal and Torres Strait Islander people. If you are looking for a unique and exciting opportunity, we look forward to your application."
89266720,Principal Engineer - MQ-28 Global Digital Ecosystem,Boeing Defence Australia,https://www.seek.com.au/job/89266720?type=standard&ref=search-standalone&origin=jobCard#sol=63776f489e1cf065aa4e080f729d6ac72a7275de,2h ago,2.0,2025-12-22T00:00:00+00:00,Brisbane QLD (Hybrid),Engineering - Software (Information & Communication Technology),Full time,,"The Opportunity

The Boeing MQ-28 - Ghost Bat is a globally significant program delivering disruptive advantage to support Defence operational capabilities. Developed in partnership with the Royal Australian Air Force, it is the first military combat aircraft to be designed, manufactured and assembled in Australia in 50 years. 

As MQ-28 expands internationally, the program requires robust, secure and export-compliant data architecture to manage and store data across multiple customer nations. 

Role overview

You will partner closely with the MQ-28 Global Digital Ecosystem Principal Engineer to define, implement and govern the MQ-28 enterprise data architecture and reference data platforms.  Your role will deliver on the digital architecture and solution patterns that enable global design collaboration for engineering design, flight test, maintenance, logistics and operational analytics.

Key responsibilities

Define and maintain the MQ-28 enterprise data architecture and data product roadmap in alignment with program strategic roadmaps and product architecture.
Design reference data platform architectures (cloud, hybrid, and on‑prem) to ingest, store, process and serve high‑volume flight test, telemetry, sensor and maintenance data at scale.
Specify data models, canonical schemas, ontologies and metadata standards to enable cross‑domain interoperability (engineering, operations, logistics, analytics).
Establish data governance, stewardship, cataloguing and lifecycle policies that incorporate export control, data rights, IP, and cross‑jurisdictional access constraints.
Define secure data integration and exchange patterns.
Develop architectures for efficient analytics and ML/AI workflows (data lakes, feature stores, data warehouses, MLOps pipelines) supporting test analysis, performance trending and predictive maintenance.
Create reference implementation patterns and reusable data platform blueprints for supplier/partner onboarding and rapid capability delivery.
Collaborate with security, export control, legal and compliance teams to ensure architecture meet export constraints and national security requirements.
Define interoperability contracts, APIs, data contracts and SLAs for internal systems and external partners/nations.
Lead data migrations, ingestion design and coexistence strategies for existing PLM/ALM/SE systems and new data platforms.
Produce architecture artefacts including data flow diagrams, logical & physical data models, data lifecycle diagrams, capacity & cost models and interface specifications.
Provide technical leadership and mentoring to data engineers, platform teams and stakeholders.
Communicate architecture rationale, risks, cost/benefit tradeoffs and timelines to program leadership and international partners.

Essential skills & experience

Proven experience as a Data Architect or Senior Data Engineering/Architecture role on complex, multi‑stakeholder defence, aerospace or mission‑critical programs
Expertise designing large‑scale data platforms: data lakes, data warehouses, streaming platforms, feature stores and analytical pipelines
Strong experience with cloud data architectures (AWS/Azure/GCP) and hybrid/on‑premises integration in regulated environments
Deep understanding of data modelling (relational, time-series, event-sourced), metadata, master data management and ontologies
Practical experience with ingestion and integration patterns (e.g. Kafka/streaming, ETL/ELT, CDC, APIs, message buses and batch processing)
Experience implementing data security controls and familiarity with cyber control frameworks (e.g. Essential 8, ISM, NIST800-43)
Familiarity with export control frameworks (ITAR/EAR or equivalents), data sovereignty requirements and contractual data/IP rights
Australian Citizenship (required for Defence security clearance). 

Desirable skills & experience

Hands-on with data platform technologies and tools such as AWS (S3, Glue, Kinesis, Redshift, SageMaker), Azure (Data Lake, Event Hubs, Synapse, ML), GCP (BigQuery, Dataflow), Kafka, Snowflake, Databricks, Postgres/TimescaleDB.
Familiarity with PLM/ALM/SE ecosystems and integrating engineering toolchains into data platforms.
Experience with observability, data lineage and catalog tools (OpenLineage, Amundsen, DataHub, Collibra).
Knowledge of ML/AI operationalisation, feature stores and MLOps practices.
Scripting and automation skills (Python, CI/CD tooling) to support prototype and reference implementations.
Prior exposure to global defence programs or multi‑national supplier networks. 

Other benefits

Work on cutting edge projects with opportunities to work across platforms
Attractive remuneration and annual bonus
Formal reward and recognition program
Access discounts for health insurance, travel and accommodation
Paid parental leave and Defence leave
Salary packaging options available
Health and wellbeing benefits include annual flu vaccinations and Employee Assistance Program
Social and community groups 

BDA works with strong links with our global Boeing community, and we strongly encourage collaboration with our international counterparts.

We are committed to building a diverse and inclusive workplace. Female applicants, people of Aboriginal or Torres Strait Island descent and veterans are encouraged to apply.

Please note, this role will be shortlisted in 2026. Your patience is appreciated."
89266547,EL2 Senior Cloud Engineer / Architect,"Talent – Specialists in tech, transformation & beyond",https://www.seek.com.au/job/89266547?type=standard&ref=search-standalone&origin=jobCard#sol=07ea71f6dbbad9233432dfbbe5844a8d4e7e52fb,2h ago,2.0,2025-12-22T00:00:00+00:00,Melbourne VIC (Hybrid),Architects (Information & Communication Technology),Contract/Temp,,"The opportunity

Our client is a community focused Federal Government Agency. They are currently seeking an EL2 Senior Cloud Engineer / Architect to determine the appropriate technologies to be used in the service development and delivery environment.


This is a 12 month initial contract with the possibility of 2x 12 month extensions, offering open market hourly rates. This is a hybrid role based out of the Melbourne CBD.

Your responsibilities will include:

Design and deploy greenfield and brownfield cloud platforms in either Azure or AWS, including foundational structures like Azure Landing Zones/Management Groups or AWS Landing Zone/Organizations/Control Tower, to support organisational scalability and hierarchy.
Implement Infrastructure as Code (IaC) using tools such as Terraform, ARM/Bicep (Azure), or CloudFormation (AWS) for reusable, automated, and secure deployments.
Configure and manage core services, such as Azure Key Vault/Blob Storage/Virtual Machines or AWS Secrets Manager/S3/EC2, ensuring secure-by-design principles like least privilege, encryption at rest/transit, and threat modelling.
Establish robust networking components, including Azure VNets/Subnets/NSGs/Firewall or AWS VPCs/Subnets/Security Groups/Transit Gateway, with focus on secure connectivity (e.g., VPN/ExpressRoute in Azure or Direct Connect in AWS).
Develop and enforce governance frameworks, including policies and guardrails via Azure Policy/RBAC or AWS Control Tower/IAM, to align with Australian government standards (e.g., ISM, PSPF), incorporating security assessments, cost optimisation, and compliance monitoring.
Integrate secure-by-design practices throughout the lifecycle, such as zero-trust models, automated vulnerability scanning, and identity federation.
Provide technical guidance, documentation, and training to teams on best practices for both Azure and AWS environments.
Document, present and discuss the end-to-end implementation options, recommendations and implications, to facilitate and support the decision-making process.
Ensure work aligns with business processes and overall delivery outcomes.
Drive innovation, continuous improvement and manage and lead change.
Proactively share knowledge and expertise as the subject matter expert.
Oversee and prepare a range of documentation and reports.
Collaborate with a broad range of internal and external stakeholders to achieve outcomes and key deliverables.
Resolve very complex, sensitive and/or escalated technical issues.
Develop and present outcomes confidently to a range of stakeholders across multiple forums.

*Please note that Australian Citizenship is requirement to be eligible to work for this Federal Government Agency*

About you

5+ years of hands-on experience as a Cloud Engineer, with expertise in building greenfield and brownfield setups in either Azure OR AWS public clouds, including IaC implementations and secure-by-design principles.
Proven track record with foundational elements in Azure (Landing Zones, Management Groups, Resource Groups, Key Vault, Blob Storage, Virtual Machines) OR AWS equivalents (Landing Zone, Organizations, VPCs, Secrets Manager, S3, EC2).
Strong knowledge of networking in either or both platforms: Azure (VNets, peering, NSGs, routing) and/or AWS (VPCs, subnets, security groups, NAT gateways), including hybrid connectivity.
Experience in governance and security: Implementing policies, guardrails, RBAC/IAM, and tools like Azure Security Center or AWS Security Hub.
Experience with DevOps practices, CI/CD pipelines (e.g., Azure DevOps, AWS CodePipeline), and scripting (PowerShell, Python, Bash).
Understanding of Australian government cloud requirements, including data sovereignty, security classifications, and regulatory compliance.
Proficiency in relevant technologies, frameworks, and tools, as well as the ability to translate complex technical requirements into scalable and sustainable solutions is imperative.
Current or previous held NV1 AGSVA clearance.


Applications close Friday the 16th of January.

APPLY

Submit your resume, or for further information please contact Liam.Lasslett@talentinternational.com or Jarrodd.Edwards@talentinternational.com"
89266485,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266485?type=standard&ref=search-standalone&origin=jobCard#sol=afbd31cbb08f5a8b20ad688a6e1fba20724d0891,2h ago,2.0,2025-12-22T00:00:00+00:00,Canberra ACT,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266481,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266481?type=standard&ref=search-standalone&origin=jobCard#sol=c06968b067e449d2a34994e1a3025adbf6615ee4,2h ago,2.0,2025-12-22T00:00:00+00:00,Sydney NSW,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266471,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266471?type=standard&ref=search-standalone&origin=jobCard#sol=3beb8dc7d0e565a507d041a962ac83f85fc96cbe,2h ago,2.0,2025-12-22T00:00:00+00:00,Darwin NT,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266464,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266464?type=standard&ref=search-standalone&origin=jobCard#sol=8c22f8fb9a973b49b04febdc13a0e1dbff52c86e,2h ago,2.0,2025-12-22T00:00:00+00:00,Brisbane QLD,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266461,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266461?type=standard&ref=search-standalone&origin=jobCard#sol=afe6f3c1e804611f40dd72375bcf7f8b64c0d1c9,2h ago,2.0,2025-12-22T00:00:00+00:00,Adelaide SA,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266456,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266456?type=standard&ref=search-standalone&origin=jobCard#sol=21b8a2c37a138592aca4bdf7baf7a8d76d590021,2h ago,2.0,2025-12-22T00:00:00+00:00,Hobart TAS,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266455,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266455?type=standard&ref=search-standalone&origin=jobCard#sol=0a98a5305e948aa69cc56109dbb8e456c5ae3b72,2h ago,2.0,2025-12-22T00:00:00+00:00,Melbourne VIC,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266453,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266453?type=standard&ref=search-standalone&origin=jobCard#sol=55816bbbc7a0d66fa59ec9e866721b43ba9fc263,2h ago,2.0,2025-12-22T00:00:00+00:00,Perth WA,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266288,Senior Software Engineer AI/ML,Cleared Recruitment,https://www.seek.com.au/job/89266288?type=standard&ref=search-standalone&origin=jobCard#sol=a703e79ca4b8fa519706beede73606bade7be678,3h ago,3.0,2025-12-21T23:00:00+00:00,"Deakin, Canberra ACT (Hybrid)",Engineering - Software (Information & Communication Technology),Full time,,"Cleared Recruitment are supporting a privately owned Australian defence company seeking a Senior Software Engineer with AI/ML experience and baseline clearance or above to join their Adelaide-based team in a permanent role.
This opportunity suits someone stepping into a hands-on technical leadership role, combining senior-level software engineering with practical AI/ML application. You'll remain deeply technical while helping guide technical direction, mentoring engineers, and working with engineering leadership to define technical goals, scope work, and align development with program and customer objectives.
You'll contribute to impactful defence programs, building AI-enabled, interactive and real-time modelling and simulation applications in a collaborative, delivery-focused environment.
Skills and Experience
Essential


Strong backend software engineering experience using Python, C++, Ja or C#

Experience applying AI/ML techniques in production or R&D environments, including exposure to frameworks such as TensorFlow and/or PyTorch

Ability to design, write, test, and document clean, efficient, and maintainable code

Experience developing Windows and/or Linux native applications, including GUI-based systems

Excellent problem-solving, reasoning, and systems-thinking skills

Exposure to defence-related systems such as weapons, electronic warfare, command and control, or flight systems


Desirable

Experience building distributed and networked systems, including network communications and system configuration
Experience working on modelling and simulation systems

Experience with real-time graphics, visualisation, or user interface design

Familiarity with graphics and compute technologies such as DirectX, OpenGL, Vulkan, CUDA, OpenCL, HLSL, or GLSL

Experience with microservices, virtualisation, and containerisation

Working knowledge of Atlassian tools (Jira, Confluence, Bitbucket)

Experience working in Agile development and testing environments

About you:
You are a senior, highly motivated Software Engineer with strong backend development experience in C++, Python, or C#, and practical exposure to AI/ML techniques used to enhance real-world systems. You enjoy working on complex, mission-critical software and take pride in writing clean, maintainable code that performs reliably in demanding environments.
You thrive in hands-on technical roles where you can contribute at both the code and system level, collaborating closely with multi-disciplinary teams to translate operational and user requirements into robust software solutions. Your experience spans modelling and simulation, native Windows and Linux applications, and integrating software with broader systems, with an appreciation for performance, scalability, and long-term maintainability.
Comfortable working in defence-aligned environments, you bring strong problem-solving skills, sound engineering judgement, and the ability to balance innovation with discipline when delivering software that truly matters.
What you will do
Participate in crafting and advancing systems integral to shaping the future defence capabilities of Australia.

Collaborate with clients and team members to analyse and discern requirements for development initiatives or workflow enhancements.

Advocate for software best practices, including Agile development and testing methodologies; actively encourage and engage in collaboration throughout all stages of the system development life cycle.

Take charge of project advancement and convey project status updates to the team lead, partners, and clients.

Provide proactive mentoring to nurture the growth of software engineers in their development endeavours.

Benefits
Experience fulfilling and captivating tasks within an environment that fosters growth and support in a dynamic and expanding organisation. Enjoy a vibrant and supportive workplace culture that thrives on engagement, creating a stimulating atmosphere.
Benefit from a 37.5-hour workweek complemented by flexible hybrid work arrangements, emphasizing a harmonious work-life balance. Recognize the value placed on professional development and receive competitive remuneration for your contributions. It's an opportunity for interesting and rewarding work in a setting that values your well-being and career growth.

Clearance required
Baseline clearance or above required - Unsure? Visit before applying- https://www.agsva.gov.au/about/security-clearance-definitions

At Cleared, we provide tailored recruitment solutions to individuals seeking their next opportunity and to organisations searching for talent within Defence Industry, Intelligence and National Security.

To arrange a confidential conversation or apply, please contact Emily on 0401791117 or to view all our current openings, please visit https://www.clearedrecruitment.com.au/"
89266220,Senior Software Engineer AI/ML,Cleared Recruitment,https://www.seek.com.au/job/89266220?type=standard&ref=search-standalone&origin=jobCard#sol=110df41aebf83aaae86ef8bc3dd0cfcbc5eef7f8,3h ago,3.0,2025-12-21T23:00:00+00:00,Adelaide SA (Hybrid),Engineering - Software (Information & Communication Technology),Full time,,"Cleared Recruitment are supporting a privately owned Australian defence company seeking a Senior Software Engineer with AI/ML experience and baseline clearance or above to join their Adelaide-based team in a permanent role.
This opportunity suits someone stepping into a hands-on technical leadership role, combining senior-level software engineering with practical AI/ML application. You'll remain deeply technical while helping guide technical direction, mentoring engineers, and working with engineering leadership to define technical goals, scope work, and align development with program and customer objectives.
You'll contribute to impactful defence programs, building AI-enabled, interactive and real-time modelling and simulation applications in a collaborative, delivery-focused environment.
Skills and Experience
Essential


Strong backend software engineering experience using Python, C++, Ja or C#

Experience applying AI/ML techniques in production or R&D environments, including exposure to frameworks such as TensorFlow and/or PyTorch

Ability to design, write, test, and document clean, efficient, and maintainable code

Experience developing Windows and/or Linux native applications, including GUI-based systems

Excellent problem-solving, reasoning, and systems-thinking skills

Exposure to defence-related systems such as weapons, electronic warfare, command and control, or flight systems


Desirable

Experience building distributed and networked systems, including network communications and system configuration
Experience working on modelling and simulation systems

Experience with real-time graphics, visualisation, or user interface design

Familiarity with graphics and compute technologies such as DirectX, OpenGL, Vulkan, CUDA, OpenCL, HLSL, or GLSL

Experience with microservices, virtualisation, and containerisation

Working knowledge of Atlassian tools (Jira, Confluence, Bitbucket)

Experience working in Agile development and testing environments

About you:
You are a senior, highly motivated Software Engineer with strong backend development experience in C++, Python, or C#, and practical exposure to AI/ML techniques used to enhance real-world systems. You enjoy working on complex, mission-critical software and take pride in writing clean, maintainable code that performs reliably in demanding environments.
You thrive in hands-on technical roles where you can contribute at both the code and system level, collaborating closely with multi-disciplinary teams to translate operational and user requirements into robust software solutions. Your experience spans modelling and simulation, native Windows and Linux applications, and integrating software with broader systems, with an appreciation for performance, scalability, and long-term maintainability.
Comfortable working in defence-aligned environments, you bring strong problem-solving skills, sound engineering judgement, and the ability to balance innovation with discipline when delivering software that truly matters.
What you will do
Participate in crafting and advancing systems integral to shaping the future defence capabilities of Australia.

Collaborate with clients and team members to analyse and discern requirements for development initiatives or workflow enhancements.

Advocate for software best practices, including Agile development and testing methodologies; actively encourage and engage in collaboration throughout all stages of the system development life cycle.

Take charge of project advancement and convey project status updates to the team lead, partners, and clients.

Provide proactive mentoring to nurture the growth of software engineers in their development endeavours.

Benefits
Experience fulfilling and captivating tasks within an environment that fosters growth and support in a dynamic and expanding organisation. Enjoy a vibrant and supportive workplace culture that thrives on engagement, creating a stimulating atmosphere.
Benefit from a 37.5-hour workweek complemented by flexible hybrid work arrangements, emphasizing a harmonious work-life balance. Recognize the value placed on professional development and receive competitive remuneration for your contributions. It's an opportunity for interesting and rewarding work in a setting that values your well-being and career growth.

Clearances
Must be able to obtain baseline - Australian citizenship is a must.

At Cleared, we provide tailored recruitment solutions to individuals seeking their next opportunity and to organisations searching for talent within Defence Industry, Intelligence and National Security.

To arrange a confidential conversation or apply, please contact Emily on 0401791117 or to view all our current openings, please visit https://www.clearedrecruitment.com.au/"
89265620,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265620?type=standard&ref=search-standalone&origin=jobCard#sol=abbf4ae30dc29a14958c6a92fab8d48438cd0be5,3h ago,3.0,2025-12-21T23:00:00+00:00,Canberra ACT,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265616,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265616?type=standard&ref=search-standalone&origin=jobCard#sol=e4b9358670328b071fa99c48280363ce1686287e,3h ago,3.0,2025-12-21T23:00:00+00:00,Sydney NSW,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265613,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265613?type=standard&ref=search-standalone&origin=jobCard#sol=e13657687170153cb03d2d6a047dd0623fdadef4,4h ago,4.0,2025-12-21T22:00:00+00:00,Darwin NT,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265606,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265606?type=standard&ref=search-standalone&origin=jobCard#sol=3b25b12b1e116edcbc90a3c44713af367925951b,4h ago,4.0,2025-12-21T22:00:00+00:00,Brisbane QLD,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265598,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265598?type=standard&ref=search-standalone&origin=jobCard#sol=0fbe458ef1dd2acc26e2c31fe69dc99131f877e9,4h ago,4.0,2025-12-21T22:00:00+00:00,Adelaide SA,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265588,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265588?type=standard&ref=search-standalone&origin=jobCard#sol=7d017174504c01b2861558bb82ee263275f33003,4h ago,4.0,2025-12-21T22:00:00+00:00,Hobart TAS,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265541,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265541?type=standard&ref=search-standalone&origin=jobCard#sol=343983a1a73982d52bb8fad54f8fa822a4bf108f,4h ago,4.0,2025-12-21T22:00:00+00:00,Melbourne VIC,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265483,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265483?type=standard&ref=search-standalone&origin=jobCard#sol=de7a2a41a4839b75e2594fd5f457ecb5d83f0c5e,4h ago,4.0,2025-12-21T22:00:00+00:00,Perth WA,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89263856,Senior Data Engineer,Department of Health - Queensland,https://www.seek.com.au/job/89263856?type=standard&ref=search-standalone&origin=jobCard#sol=302f1b381796fcae28ade21ffb7e8db49ea198aa,12h ago,12.0,2025-12-21T14:00:00+00:00,"Fortitude Valley, Brisbane QLD","Engineering - Software (Information & Communication Technology)
Government - State (Government & Defence)",Full time,"$136,035 - $145,990 per annum + super","What you'll do  

Be working within the Queensland Health Enterprise Reporting Team, which involves members of a multi-disciplinary team supporting the department's SAP reporting instance that includes the clinical data.
Lead the development and maintenance of QLD health data warehouse including associated integrations and process orchestration.
Lead the development and maintenance of QLD Health semantic and security models for access to health data.
Lead the development and maintenance of QLD Health reports and dashboards.
Consult, Develop and maintain QLD Health business intelligence architecture and support processes.
Provide expert technical and functional consulting to wider support team.
Provide strategic and expert advice to management in the support and maintenance of health data and associated processes.
Consult and mentor QLD Health staff in the processes and technology supporting health data.

About you  

You will be assessed on your ability to demonstrate the following key capabilities, knowledge and experience. Within the context of the responsibilities described above under ‘Key Responsibilities', the ideal applicant will be someone who can demonstrate the following:

Demonstrate extensive experience in the implementation and maintenance of the Business Intelligence & Data Warehousing Systems
Proven ability to analyse both business and system problems and develop innovative solutions with a strong focus on delivering high quality client services and outcomes
Proven high level of knowledge in data ETL and reporting products.
Proven high level of knowledge in Health Data modelling, security and mining, familiar with data relationship behind Clinical Application systems.
Proven ability to work effectively as a member of a diverse team and assist management and team leaders in supervising and assisting other team members to deliver effective service to clients
Proven high level of client service skills and working to deadlines and service level timelines
Proven high level of knowledge in ITIL foundations and the expert provision of consulting in service management and the design of business intelligence or information services
Proven high level of written and verbal communication skills with demonstrated ability to build effect client and stakeholder relationships by negotiating client needs and ensuring proposed solutions are properly understood and resolved.

Why work with us?  

Work alongside passionate professionals in a supportive and inclusive environment that values people and prioritises employee success and wellbeing. 

Competitive salaries 

12.75% superannuation  
17.5% leave loading 

Employee wellbeing & development 

Access to 24/7 confidential employee support providers and counsellors including for immediate family members 
Additional flexibility to support your work life balance including access to generous leave entitlements, such as purchased leave, domestic violence leave, reproductive health leave, cultural leave, study and examination leave. 
Access to a variety of programs and initiatives to support training and career growth.  
Grow your skills through hands-on experience and access to internal training opportunities and additional financial and leave benefits for approved external training and development. 

Our commitment to equity, diversity and inclusion  

At Queensland Health, our work environment is inclusive and supportive, and we value our employees. We are an equal opportunity employer and encourage applications from people of all cultures, abilities and backgrounds.  

Our commitment to cultural safety, equity, diversity and inclusion means we understand some people may need changes to the recruitment process. If you need support during the recruitment process, such as meeting with the panel virtually instead of in person, please reach out to the hiring manager. We value diverse candidates and your need for adjustments will not affect our hiring decisions.  

Ready to apply? 

For further information on how to apply please review the attached Role Description."
