Job ID,Job Title,Company,Detail URL,Posted Label,Hours Old,Posted Datetime (Local),Location,Category,Work Type,Salary,Ad Text
90326384,AI Engineer (Data Science),Monysoft,https://www.seek.com.au/job/90326384?type=standard&ref=search-standalone&origin=jobCard#sol=40b9551e40db3bc2999a3b08dbc7e60ad5df7095,1h ago,1.0,2026-02-13T04:00:00+00:00,Sydney NSW (Hybrid),Developers/Programmers (Information & Communication Technology),Full time,"$90,000 – $100,000 per year","We’re expanding and looking for an AI Engineer (Data Scientists) to join our Sydney office.

Why You’ll Love This Role

Work on meaningful, real‑world AI projects

Build next‑gen LLM solutions used by global enterprises

Learn from world‑class engineers and technical leaders

Hybrid working

Supportive, high‑performance team culture

What You’ll Do

Develop & deploy ML models that shape our products

Analyse large datasets to uncover insights

Improve LLM output across multiple use cases

Implement MLOps workflows & benchmarking

Contribute to data strategy, governance & ethical AI

Collaborate with engineers, product teams & stakeholders"
90326313,Senior Data Scientist,Gallagher Bassett,https://www.seek.com.au/job/90326313?type=standard&ref=search-standalone&origin=jobCard#sol=40f98d01c60ab709ee3450852d2eb7ecffdc0644,1h ago,1.0,2026-02-13T04:00:00+00:00,Brisbane QLD (Hybrid),"Mathematics, Statistics & Information Sciences (Science & Technology)",Full time,,"About the Role

 

As a Data Scientist, you will play a pivotal role in identifying opportunities to leverage data science, machine learning, and GenAI to solve complex business challenges. You will work collaboratively with cross-functional teams to develop, deploy, and monitor advanced data-driven solutions that enhance decision-making and deliver measurable outcomes. This role will also involve close collaboration with, and will report to Gallagher Bassett’s global data science team, ensuring alignment with global strategies and sharing best practices across regions.

 


Responsibilities

Key Responsibilities:

 

Identify opportunities for data science, machine learning, and GenAI solutions to address business challenges and deliver value at scale.
Develop and implement advanced data science and machine learning models, ensuring alignment with business objectives.
Research and evaluate competing solutions to determine optimal approaches for problem-solving.
Extract, clean, and prepare data for analysis, addressing data quality issues and performing feature engineering.
Collaborate with product managers and team members to design and deploy data science solutions.
Monitor and optimise model performance over time to ensure sustained predictive accuracy.
Develop and evaluate GenAI applications using tools such as LlamaIndex, LangChain, and LLMOps tools like DeepEval.
Create and refine prompts for querying large language models (LLMs) and assess their outputs.
Work with technology partners to build and maintain systems for deploying models and algorithms.
Provide guidance and mentorship to team members, fostering a collaborative and innovative environment.

Qualifications

About You

 

We are looking for a passionate and experienced Data Scientist who thrives in a collaborative environment and is eager to push the boundaries of innovation.

 

Essential Skills and Experience:

 

A degree in Data Science, Machine Learning, Statistics, or a related field (Master’s degree preferred).
Strong understanding of data science and machine learning concepts, methodologies, and evaluation techniques.
Minimum of 5 years of hands-on experience in end-to-end data science projects.
Proficiency in Python and its data science libraries (e.g., Pandas, Scikit-Learn, Catboost, Keras, TensorFlow, PyTorch, NumPy, Matplotlib).
Expertise in SQL for data extraction, manipulation, and analysis.
Proven ability to lead and deliver projects independently, with a track record of mentoring and guiding team members.
Experience working in cloud-based environments, preferably Azure Databricks.
Familiarity with developing business applications using GenAI/LLM technologies and building LLM workflows on platforms like Azure Foundry.
Proficiency in tools such as LlamaIndex, LangChain, and LangGraph.
Strong communication skills to effectively convey complex data science concepts to non-technical stakeholders.
Experience in insurance or claims management is highly desirable.

 

 

How to Apply

 

Apply now to join our team and help us shape the future of insurance and risk management through data-driven insights and cutting-edge technology.


Click on Apply for this Job to submit your application.

 

To be considered for this opportunity, you must have the right to live and work in Australia at the time of application. Please note that agency applications will not be considered for this position."
90326202,Devops Engineer,Advancedlife Pty Ltd,https://www.seek.com.au/job/90326202?type=standard&ref=search-standalone&origin=jobCard#sol=6257c639444c531413e598fc827e548897302431,1h ago,1.0,2026-02-13T04:00:00+00:00,"Brookvale, Sydney NSW",Networks & Systems Administration (Information & Communication Technology),Full time,"$110,000 – $130,000 per year","KEY JOB RESPONSIBILITIES

Infrastructure Automation: Design, implement and maintain CI/CD pipelines to streamline deployments, scaling, and management of applications and infrastructure.

Networking and Monitoring: Apply strong networking knowledge to design, configure and optimise infrastructure, while building and enhancing our NMS to deliver real-time dashboards showing hardware, application, and service health status.

Application Ownership & Development: Take full responsibility for two C# applications; delivering timely bug fixes, developing new features, and ensuring reliable ongoing operation.

NMS Development & Maturity: Actively grow our early-stage NMS, adding functionality, improving monitoring capabilities, and creating intuitive dashboards for operational visibility.

Network Architecture Leadership: Contribute to defining and evolving the company’s network architecture, driving scalable and resilient designs that support national business growth.

System Modernisation: Drive the move from legacy platforms to modern approaches including containerisation, cloud services, and infrastructure-as-code practices.

Performance & Reliability: Proactively monitor systems, identify bottlenecks, and implement improvements to maintain high availability and performance.

Collaboration & Culture: Partner closely with developers, operations, and business teams to embed DevOps principles, share knowledge, and solve problems together.

Incident Resolution: Rapidly diagnose and resolve production issues, then implement lasting preventive measures.

Documentation & Enablement: Produce clear, maintainable documentation and deliver training to help the wider team adopt new tools and practices.

Continuous Learning & Improvement: Embrace emerging technologies and best practices to recommend and implement forward-thinking enhancements.

Other Duties: Flexibly support evolving IT priorities as the business continues to grow.

PERSON SPECIFICATION:

Strong analytical and problem-solving skills combined with a genuine growth mindset; eager to learn, experiment, take ownership, and continuously develop.

Proactive, self-motivated, and comfortable with autonomy in a fast-paced environment.

Excellent communicator who can translate technical concepts clearly for both technical and non-technical stakeholders.

High ethical standards, particularly when working with sensitive student and school data.

KNOWLEDGE/SKILLS/EXPERIENCE:

3+ years in DevOps engineering or closely related roles, with proven experience in networks and infrastructure in growing teams.

Solid C# development experience, including maintaining applications, fixing issues, and building features.

Practical familiarity with Canon SDK and ImageMagick is highly beneficial for supporting our photography applications.

Hands-on experience developing or maturing a Network Management System (NMS), including building monitoring dashboards for hardware, applications, and service health.

Strong networking fundamentals: protocols, routing, switching, firewalls, and performance optimisation.

Core DevOps skills including CI/CD pipeline design, scripting, automation, and infrastructure-as-code principles.

Experience working with infrastructure, cloud platforms, containerisation, and modern architectures.

Background in IT environments handling sensitive data (medical-tech, education, media, or photography sectors preferred).

Location: Brookvale, Seven Hills or Toronto NSW (with support for Australia-wide operations) Salary: Competitive market rate (around AUD 110,000 - 130,000 per year, depending on experience)

Work Type: On-Site in Brookvale, Seven Hills or Toronto NSW.

How to Apply: Submit your resume and a brief cover letter highlighting your DevOps experience, C# skills, networking background, NMS/monitoring dashboard work, familiarity with Canon SDK and ImageMagick, and your growth mindset to Jonathon.m@advancedlife.com.au.

 We’re excited to meet someone ready to help shape our technical future!"
90324256,Technical Support Escalation Engineer - Data Platform,Microsoft,https://www.seek.com.au/job/90324256?type=standard&ref=search-standalone&origin=jobCard#sol=c7a5f799b9323c6844b2985a68bd89bc62fd08c2,1h ago,1.0,2026-02-13T04:00:00+00:00,Sydney NSW,Help Desk & IT Support (Information & Communication Technology),Full time,Subsidised health insurance + stock discounts,"Overview


With more than 45,000 employees and partners worldwide, the Customer Experience and Success (CE&S) organization is on a mission to empower customers to accelerate business value through differentiated customer experiences that leverage Microsoft’s products and services, ignited by our people and culture. We drive cross-company alignment and execution, ensuring that we consistently exceed customers’ expectations in every interaction, whether in-product, digital, or human-centered. CE&S is responsible for all up services across the company, including consulting, customer success, and support across Microsoft’s portfolio of solutions and products. Join CE&S and help us accelerate AI transformation for our customers and the world.

Interested in being on the cutting edge of Cloud Services? Then come join Microsoft as an Embedded Escalation Engineer (EEE) working with Azure Analytics. 

As EEE, you will be working with Azure Databricks Engineering team within support to be “the” differentiator in the marketplace and need the best and brightest to take our Azure Analytics Service to the next level.

As an Embedded Escalation Engineer (EEE), you will be an important member of the Customer Service and Support (CSS) Data and AI Support Engineering Team and a virtual member of the Azure Databricks Product Group. You will have the following key responsibilities: 

Lead engineering investigations to bring quicker issue resolution to support incidents impacting our customers and improve customer experience. 

Build solutions, help create tools, help automate issue detection and diagnosis, to enable customers or support to self-resolve the issues.

Identify emerging trends or re-occurring escalation scenarios and drive engineering opportunities to mitigate and/or eliminate them from the workflow. This can include a range of potential work item categories; such as self-healing mechanisms, self-serve, transparency, automation, and/or increasing the capabilities for Azure support.

Contribute to product improvements by filing impactful bugs, design change requests and helping developers to fix and ship them to production, preventing customers from being impacted. 

As a trusted advisor to the Microsoft Azure engineering team and the Serviceability Technology Lead, you will suggest changes to future versions to better equip our support teams as well as our partners and customers and help influence in-market solutions today. 

As a customer ambassador, you will also partner with engineering leadership for strategic technical, architectural and design discussions, and drive strategic thought leadership for Azure Diagnostics/UDE tools creation and usage worldwide bringing the customer voice to the center of impactful decisions. These strategic areas of focus will target our highest impact pain points for our partners, customers and team members. 

Able to work well in challenging situations while exhibiting flexibility and ability tolerate and manage through ambiguity and uncertainty. 

Beyond extensive technical and product focus, this role requires the ability to frame and communicate issues and recommendations clearly and concisely, show exceptional attention to detail, and demonstrate the ability to build broad relationships with the right influencers, leveraging those relationships to impact key business results. The successful candidate will have a solid understanding of the competitive landscape and use this understanding to influence decision makers in both support and the Azure Databricks Product Group. 

It’s your chance to:  

Work directly with our Azure Databricks Product Group to provide world-class engineering support at a product component level. 

Perform complex product debugging and remediation when needed; working alongside the development teams to drive support incident resolution for configuration, code, or other service deficiencies impacting customers.

Embedded Escalation Engineers are not expected to write product code; however, should be able to apply their code skills and understanding towards efficiently resolving support issues as appropriate.

Identify emerging trends or recurring escalation scenarios and drive engineering opportunities to mitigate and/or eliminate them from the workflow. This can include a range of potential work item categories; such as self-healing mechanisms, transparency, automation, and/or increasing the capabilities of Azure Databricks analytics and AI Platform.

Provide periodic on-call rotation (low frequency) service as primary response to service escalations.

The position is primarily “behind the scenes” providing engineering support to the broader Microsoft SQL Cloud support delivery teams for incidents that require product group engagement. At the same time, individuals should be capable and prepared to occasionally engage directly with customers to help facilitate incident resolution as appropriate. 

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

Responsibilities

As an Embedded Escalation Engineer (EEE), you will be an important member of the Customer Service and Support (CSS) Data and AI Support Engineering Team and a virtual member of the Azure Databricks Product Group. You will have the following key responsibilities: 

Lead engineering investigations to bring quicker issue resolution to support incidents impacting our customers and improve customer experience. 

Build solutions, help create tools, help automate issue detection and diagnosis, to enable customers or support to self-resolve the issues.

Identify emerging trends or re-occurring escalation scenarios and drive engineering opportunities to mitigate and/or eliminate them from the workflow. This can include a range of potential work item categories; such as self-healing mechanisms, self-serve, transparency, automation, and/or increasing the capabilities for Azure support.

Contribute to product improvements by filing impactful bugs, design change requests and helping developers to fix and ship them to production, preventing customers from being impacted. 

As a trusted advisor to the Microsoft Azure engineering team and the Serviceability Technology Lead, you will suggest changes to future versions to better equip our support teams as well as our partners and customers and help influence in-market solutions today. 

As a customer ambassador, you will also partner with engineering leadership for strategic technical, architectural and design discussions, and drive strategic thought leadership for Azure Diagnostics/UDE tools creation and usage worldwide bringing the customer voice to the center of impactful decisions. These strategic areas of focus will target our highest impact pain points for our partners, customers and team members. 

Able to work well in challenging situations while exhibiting flexibility and ability tolerate and manage through ambiguity and uncertainty. 

Beyond extensive technical and product focus, this role requires the ability to frame and communicate issues and recommendations clearly and concisely, show exceptional attention to detail, and demonstrate the ability to build broad relationships with the right influencers, leveraging those relationships to impact key business results. The successful candidate will have a solid understanding of the competitive landscape and use this understanding to influence decision makers in both support and the Azure Databricks Product Group. 

It’s your chance to:  

Work directly with our Azure Databricks Product Group to provide world-class engineering support at a product component level. 

Perform complex product debugging and remediation when needed; working alongside the development teams to drive support incident resolution for configuration, code, or other service deficiencies impacting customers.

Embedded Escalation Engineers are not expected to write product code; however, should be able to apply their code skills and understanding towards efficiently resolving support issues as appropriate.

Identify emerging trends or recurring escalation scenarios and drive engineering opportunities to mitigate and/or eliminate them from the workflow. This can include a range of potential work item categories; such as self-healing mechanisms, transparency, automation, and/or increasing the capabilities of Azure Databricks analytics and AI Platform.

Provide periodic on-call rotation (low frequency) service as primary response to service escalations.

The position is primarily “behind the scenes” providing engineering support to the broader Microsoft SQL Cloud support delivery teams for incidents that require product group engagement. At the same time, individuals should be capable and prepared to occasionally engage directly with customers to help facilitate incident resolution as appropriate. 

Qualifications

Required Qualifications:

Bachelor's degree in Computer Science, Information Technology (IT), or related field AND 5+ years of technical support, technical consulting experience, or information technology experience 

OR 7+ years of technical support, technical consulting experience, or information technology experience. 

OR equivalent experience

3+ years of experience in a customer-facing or support role in any of the following: technical escalation support, product support, developer support, IT DevOps, IT Admin/support, Systems Development, or Consulting or IT/Network Operations.

2+ years of experience in one or more of the following:

Microsoft Azure Platform

Azure Networking Services, Azure Virtual Machine, Azure Storage

Microsoft Azure Analytics – Azure Databricks 

Experience in any JAVA, JavaScript, Python, R, Scala, REST concepts, PowerShell

Familiarity with development: tools, language, process, methods, troubleshooting

Experience with Data Integration solutions and services

Experience with Open-Source technology preferred

Service engineering and/or DevOps experience at internet scale involving user data and/or software development for an enterprise level product

Superior problem solving and troubleshooting skills, an ability to use various data collection tools and methodologies to analyze problems and develop solutions

BS in computer science or engineering or equivalent industry experience is preferred

Please note that applicants must possess Australian Citizenship to be considered for this position and requires flexibility in working shift based on the business needs. The working shift may vary depending on the operational demand, and it may include shift rotations of Monday to Friday from 9:00AM to 6:00PM, or Tuesday to Saturday from 7:00am to 4:00pm or Sunday to Thursday from 7:00am to 4:00pm. 

Ability to meet Microsoft, customer and / or government security screening requirements are required for this role.  These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud Background Check upon hire / transfer and every two years thereafter.

This position will be open for a minimum of 5 days, with applications accepted on an ongoing basis until the position is filled.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance with religious accommodations and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations."
90325674,AI Analyst,Pepper Money ANZ,https://www.seek.com.au/job/90325674?type=standard&ref=search-standalone&origin=jobCard#sol=411cd58f7fcc0bf58437f5e42213e4ec9ced012c,1h ago,1.0,2026-02-13T04:00:00+00:00,Sydney NSW (Hybrid),Consultants (Information & Communication Technology),Full time,,"Who We Are

At Pepper Money, we’re dedicated to helping people succeed—whether it’s buying a family home, a dream car, developing professionally, or growing their business. We’ve become one of the largest, most trusted, and award-winning non-bank lenders in Australia and New Zealand. Over our 25 years, we’ve achieved a lot, but our proudest accomplishment is helping over half a million Australians reach their goals with our ever-expanding lending options. 

The Role

Pepper Money is looking for an AI Analyst to join our digital and AI squads at a pivotal moment in our technological evolution. This isn't just a position; it’s a seat at the table as we define and deliver the next generation of innovative customer, employee and partner experiences. You will serve as the critical interface between strategic business intent and technical execution, ensuring our Agentic AI roadmap is translated into high-performing, responsible solutions.

We are looking for a professional who thrives in the space between business and technology. The successful candidate will be able to seamlessly integrate high-level stakeholder collaboration and expert articulation with a proactive, self-sufficient ""doer"" mentality, ensuring that a relentless drive for learning emerging AI technologies and strong analytical thinking are consistently grounded in the meticulous attention to detail required for precise prompt engineering and documentation.

About you

We’re looking for an AI Analyst with a minimum of 5 years’ experience. We recognise that the AI landscape is shifting daily, so we value your analytical rigour and hunger for growth as much as your current technical stack. Whether you are an experienced Analyst looking to specialise or a tech-forward professional ready to pivot, we are looking for:

A Relentless Learner: You possess a self-directed drive for upskilling, staying ahead of emerging AI trends, and experimenting with new tools.

A Strategic Storyteller: You have experience in business or technical analysis, with the ability to influence through great storytelling and customer journey mapping. Experience in Human-Centred Design or Design Thinking applied to AI projects is desirable.

An AI Enthusiast: You may already have foundational prompting literacy and an interest in refining instructions for LLMs like ChatGPT, Gemini, or Claude. Expertise in iterative prompt refinement and partnering with AI engineers is desirable.

QA & Testing Specialist: A structured approach to the end-to-end testing lifecycle and UAT. Experience in the specialised field of AI Testing and Quality Assurance is highly desirable

Agile Practitioner: Advanced expertise in Agile processes, leading refinement sessions and cross-functional collaboration.

Responsible Innovator: A baseline understanding of AI risks, such as hallucinations and data privacy, to ensure ethical solution delivery.

At Pepper Money, collaboration is just as vital as your skills. Our values are the heartbeat of our success, driving everything we do:

Can Do: We think outside the box and harness the power of teamwork to achieve the extraordinary.
Balanced: We set our customers up for success, crafting win-win outcomes that are both human and profitable.
Real: We keep it honest and respect everyone, building genuine connections.

Our Benefits

At Pepper, we're dedicated to making this a fantastic place to work and supporting you every step of the way. Enjoy a values-driven, diverse environment with a leadership team that inspires success and a culture that rewards excellence. We're always finding new ways to make Pepper a place for everyone:

Development: a full suite of development opportunities and a great team to learn from

Recognition: Celebrate efforts with our Spice Reward and Recognition Program and diversity through our DE&I initiatives 

Flexibility: Embrace our hybrid working model, flexible parental leave policies and purchased leave options

Health and Wealth: Free gym membership, discounted health insurance policies, novated leasing and staff loan rates to manage your mind, body and wallet!

Referral Bonus: Earn $2000 for referring great people.

If this role sounds like it’s for you, we want to hear from you. Click the Apply button now.

For more information on Pepper, visit www.peppermoney.com.au.

Pepper is proud of the inclusive and diverse workplace that we have built over the last 25 years. Diversity is embedded in our people practices, the way we communicate and connect, and it is recognised throughout our values.   We believe in the power of diversity and encourage candidates from all backgrounds to apply."
90325465,Head of Data and Engineering,xceltium,https://www.seek.com.au/job/90325465?type=standard&ref=search-standalone&origin=jobCard#sol=0fe137d5a1698b758a1cac9392eea40bc26a3d65,1h ago,1.0,2026-02-13T04:00:00+00:00,"Homebush, Sydney NSW (Hybrid)",Management (Information & Communication Technology),Full time,"c. $200,000 - $210,000 + super + 20% STI","At this stage of your career, the challenge is rarely about the tools.

The platforms are in place. ERP is progressing. Microsoft Fabric is live. Reporting has replaced legacy systems. Vendors are engaged. Teams are busy. Yet outcomes still feel effortful. Rework absorbs capacity. Technical debt accumulates. Timelines shift. Senior leaders remain closer to architectural and engineering decisions than they should, simply to keep delivery on track.

The issue is not ambition or capability. It is operational readiness and practice maturity.

Standards vary. Modelling discipline is inconsistent. Architectural ownership is fragmented. Decisions are sometimes made reactively or too locally. Good people are working hard, but delivery is not yet operating like a well-oiled machine. It is not yet predictable or repeatable.

You can see what it could look like. Clear enterprise principles. Defined architectural accountability. Strong data modelling standards across Fabric. Vendors guided properly. Engineering and integration teams operating under disciplined patterns. Work flowing from design through to BAU with fewer surprises and less rework.

This role exists to build exactly that level of maturity.

Why This Role Exists

This organisation is a high-growth, omni-channel national retailer operating across stores, supply chain, manufacturing, and ecommerce in a live trading environment.

Over time, it has built a complex technology ecosystem spanning ERP, POS, WMS, ecommerce, integration, and data platforms. Significant investment has been made in Microsoft Fabric and analytics capability. AI and machine learning use cases are emerging, but sustainable value depends on stronger modelling discipline and architectural governance.

The constraint is not tooling. It is readiness.

Practice maturity across engineering, data, and architecture has not kept pace with platform investment. Some design decisions require rework. Modelling standards need tightening. Vendors require clearer guardrails. Senior leadership bandwidth is being absorbed compensating for gaps.

The mandate is clear:

Lift data platform maturity and modelling discipline within Fabric
Strengthen engineering and integration standards
Establish enterprise architectural ownership across platforms
Reduce rework and technical debt through stronger upfront design
Build a predictable, repeatable technology practice that scales

Architecture is not an add-on in this role. It sits squarely within your remit. You will own the architectural lens across engineering, data, and integration, ensuring decisions align to enterprise standards and scale with the business.

The Role

This is a senior leadership role, but it is not an ivory tower.

You will lead engineering, data, and architecture across internal capability and third-party partners. You will not be hired as the deepest technical expert in the room. You are hired to mature the way the room operates.

You will:

Define and enforce architectural principles and decision frameworks
Own enterprise architectural oversight across platforms, integration, and data
Uplift Microsoft Fabric practices, including modelling, pipelines, documentation, and governance
Improve engineering discipline across .NET and integration teams
Govern vendor delivery to ensure extensibility, security, and supportability
Reduce delivery rework by embedding stronger design and readiness standards
Act as the senior escalation point for complex technical and architectural trade-offs
Partner closely with the Head of Technology Delivery to ensure work lands cleanly into BAU

You will stay close enough to delivery to ask the right questions, challenge assumptions, and validate decisions, while maintaining the leadership altitude required to embed repeatable behaviour.

Environment and Context

National retailer operating in live trading conditions
Microsoft Fabric analytics environment supporting enterprise reporting and AI readiness
Active ERP and integration uplift across supply chain and digital platforms
Digital delivery cadence is strong, engineering and data practices require maturity uplift
Based at the South West Sydney head office, four days on site Monday to Thursday, with the option to work from home on Fridays

This is not greenfield. It is not broken. It is a partially mature environment that requires focused leadership to become predictable, disciplined, and scalable.

What You’ll Bring

You are a practice uplifter.

You are likely someone who started close to technology, possibly in development, data, integration, or systems roles, and broadened into leadership positions where your value came from lifting how teams operate rather than being the most specialised technical expert in the room.

You will bring:

Experience leading data or engineering teams through maturity transitions
Strong grounding in data platforms and modelling within Microsoft analytics environments
Enough architectural and software engineering depth to challenge vendors and guide standards without building solutions yourself
A track record of walking into low-maturity environments and making them materially better
The ability to embed repeatable principles, patterns, and governance across teams
Commercial judgement around AI and analytics investment, focusing on meaningful value rather than experimentation for its own sake

This is a highly visible role with broad exposure across the business and the opportunity to shape engineering, data, and architecture practice in a complex retail environment.

Next Steps

If you would value a confidential discussion before deciding whether to proceed, contact Steven Fulop at xceltium on 0418 994 446 or steven@xceltium.com"
90325012,Senior AI Engineer,Hot Toast,https://www.seek.com.au/job/90325012?type=standard&ref=search-standalone&origin=jobCard#sol=bc57f7d8baa6463bfcfd2c6bd829e7206fb1df12,1h ago,1.0,2026-02-13T04:00:00+00:00,Sydney NSW (Remote),Engineering - Software (Information & Communication Technology),Full time,,"About Hot Toast AI


Hot Toast AI is building a digital workforce for finance and operations.

Not AI demos. Not slide decks about transformation.

Production systems that do real work inside real businesses.

We started in accounting because it’s regulated, exception-heavy and intolerant of silent failure. If digital workers can operate here, they can operate anywhere.

Our platform combines RPA, APIs and agentic AI into a managed AI operations layer. Clients don’t buy tools. They buy outcomes:

•       Fewer manual hours

•       Cleaner data

•       Faster close cycles

•       Confidence that nothing breaks quietly




Reliability over hype. Always.




The Role

We’re hiring a Senior AI Engineer to become the technical backbone of Hot Toast AI.

This is a hands-on building role. Not management. Not architecture theatre.

You’ll work directly with the Founder/CEO and our automation developer to design, build and ship the systems that power our digital workforce.

You’ll operate across AI, RPA, APIs and automation. You’ll work with real clients. You’ll own outcomes end-to-end.

This is early-stage. The upside is real.


What You’ll Actually Do

•       Run technical discovery with clients and translate messy workflows into structured system designs

•       Decide what gets automated, AI-assisted or left human

•       Build and maintain orchestration across RPA, APIs and AI agents

•       Design systems that act deterministically when rules apply and escalate intelligently when judgement is required

•       Implement observability, logging and control from day one

•       Pair with our automation developer to ship production systems, not prototypes

•       Partner with the Founder/CEO on product direction and platform evolution




If something fails silently, that’s a bug. If something hallucinates in production, that’s unacceptable.




What We’re Looking For

•       Strong hands-on Python engineering

•       Real experience shipping AI/LLM systems into production

•       Experience building multi-step agent workflows or orchestration layers

•       Comfort across APIs, automation tooling and system integration

•       A track record of building production systems, not just proofs of concept

•       A mindset that designs for failure, monitoring and control

•       The ability to reason about workflows and business processes, not just code

•       Ownership mentality

•       Comfortable with ambiguity and startup pace

•       Confident speaking with CFOs and operators

We can teach accounting nuance. We cannot teach engineering instinct.




Nice-to-Have

•       Experience in finance, accounting or regulated environments

•       Early-stage or startup experience

•       Experience mentoring or leading small technical teams




What We Offer

•       Competitive salary + super

•       Meaningful equity with vesting

•       Direct access to the Founder/CEO

•       A clear pathway into technical leadership as the company scales

•       The opportunity to define how AI actually operates inside real businesses




This Role Isn’t For You If

•       You want to hire before you build

•       You prefer managing roadmaps over shipping systems

•       You need detailed specs to do good work

•       You’re looking for comfort over ownership




If building reliable AI systems inside businesses excites you, we’d love to talk."
90323395,Python engineer - Generative AI (Mid-Level),Enterprise Ai,https://www.seek.com.au/job/90323395?type=standard&ref=search-standalone&origin=jobCard#sol=6988aecaed8ee317a5d2892ae4cc2f229953752b,2h ago,2.0,2026-02-13T03:00:00+00:00,Sydney NSW,Engineering - Software (Information & Communication Technology),Full time,"$95,000 – $110,000 per year","About the role

Are you a Python engineer with a passion for generative AI? Do you dream of building something extraordinary and seeing it make a real impact at leading companies? We're looking for someone like you – an ambitious coder who thrives on innovation, rapid growth, and tackling big challenges in a fun, supportive environment.

As a mid-level Python Engineer (Generative AI) at Enterprise AI Group, you'll work at the intersection of software development and machine learning. Your code will directly contribute to our intelligent SaaS platform, helping major organisations harness AI to drive efficiency, enhance customer engagement, and turn data into actionable insights. In short, you'll play a key role in our mission to bring AI into real-world workflows quickly and safely, transforming how businesses operate with cutting-edge tech.

What you'll be doing

Full-time, 5 days onsite in Sydney. We iterate face-to-face to outpace competitors.

Build new features and RESTful APIs using Python (FastAPI) to expand our generative AI platform's capabilities.

Develop and fine-tune AI-driven services using large language models.

Leverage Azure's AI ecosystem: integrate Azure OpenAI, Cognitive Search, and data services into our products, and connect our platform with client systems via APIs.

Optimise our AI pipelines for scalability: work with MongoDB/Cosmos DB and vector databases to handle big data efficiently.

Collaborate closely with a tight-knit team of engineers and data scientists, rapidly prototyping ideas (Monday brainstorm to Friday demo is how we roll!) and delivering improvements that wow our customers.

What we're looking for

Must-haves:

Strong Python skills: You've built backend applications or APIs (FastAPI or similar) and can write clean, efficient code.

Python Development Experience: Minimum of 2+ years of Python development experience required.

AI/ML enthusiasm: Hands-on experience with machine learning or generative AI (NLP, large language models) – you've maybe played with GPT APIs and can show us your projects in Github

AI/ML Experience: Any demonstrable hands-on AI/ML experience including personal projects, commercial projects, or academic work.

Problem-solving mindset: Love tackling complex problems and debugging; you're logical, curious, and resourceful.

Team player: Great communication skills and collaborative spirit – you thrive in a team, sharing ideas and building solutions together.

BS/MS in CompSci (or equivalent experience): A solid foundation in CS principles and the ability to learn new tech quickly.

Nice-to-haves:

Node.js or Full-Stack: Some experience with Node or front-end frameworks (React/Next.js) – we appreciate versatility.

Azure/cloud experience: Familiarity with Azure AI Services, Azure ML, or cloud infrastructure (Azure DevOps, Bicep/Terraform) is a big plus.

Search/DB expertise: Experience with search engines or graph/vector databases for semantic search.

Certifications: Azure or AI certifications, or any cool open-source AI projects you've contributed to – show off your passion!

What we offer

Competitive salary + equity: Starting from A$95,000 - A$110k base + Employee Share Options – you'll share in our success

High-impact culture: We have a culture that ships – we collaborate in person, move fast, and release often to stay ahead

Career growth: Grow with us – you'll take on more responsibility over time, learn from experienced tech leaders, and accelerate your development

Modern tech & tools: Work with the latest stack (React, Next.js, TypeScript, AI/ML APIs) and propose new tools – we love adopting best tech for the job

Inclusive, fun team: Join a friendly, diverse group that celebrates ideas and wins. We brainstorm over coffee, bond over team lunches, and enjoy a bit of banter

Fast process: No drawn-out interviews – our hiring process is quick and transparent, and we respect your time (expect feedback within days)

Our Tech Stack

Front-end: React, Next.js, TypeScript, Tailwind CSS

Back-end: Node.js (serverless APIs), Python (for AI/ML services)

AI/ML: OpenAI GPT-4, LangChain, and other generative AI frameworks

Infrastructure: Everything Azure

About us

Enterprise AI is a Sydney-based AI startup delivering cutting-edge generative AI solutions on a SaaS platform so clients get results fasterau.linkedin.com. We bridge AI theory with real-world impact, helping enterprises stay ahead of the competition with data-driven, scalable technology. Founded in 2024, we're already partnering with major players (like Microsoft) and serving government and top-tier industries with our AI products. Our team culture is high-energy, collaborative, and innovative – we move fast, learn faster, and have fun doing it."
90323087,Senior AI Engineer,Emanate Technology Pty Ltd,https://www.seek.com.au/job/90323087?type=standard&ref=search-standalone&origin=jobCard#sol=8604f9ee486a879c4d484927b5356c72cc50df3b,2h ago,2.0,2026-02-13T03:00:00+00:00,Melbourne VIC (Hybrid),Developers/Programmers (Information & Communication Technology),Contract/Temp,,"Senior AI Engineer 

We are seeking a highly capable and experienced AI Engineer (Microsoft Platform). The successful candidate will demonstrate deep expertise across Microsoft development technologies, AI integration, and automation frameworks, with a strong track record of delivering scalable, enterprise-grade solutions. This position requires hands-on proficiency in C#, Power Automate, Power Apps, and Microsoft Fabric AI, enabling the development of intelligent, streamlined business solutions. A key focus of the role is ensuring all AI and automation initiatives adhere to organisational security policies, data protection requirements, and established IT governance standards.

What you’ll be doing

Design, develop, and implement AI-driven automation solutions across the Microsoft ecosystem.
Design and implement automation workflows using Microsoft Power Automate, Power Apps, and related Microsoft tools.
Collaborate with IT teams and business stakeholders to deliver high-quality, scalable solutions.
Leverage C#, Power Automate, Power Apps, and Microsoft Fabric AI to enhance operational efficiency and innovation.
Support digital transformation initiatives through intelligent automation and AI integration.
Lead system integration efforts, automation strategy, and end-to-end process optimisation.
Ensure all solutions are secure, maintainable, and aligned with business objectives.
Ensure automation and AI implementations comply with security policies, data protection standards, and IT governance frameworks.
What you bring

Create automation workflows leveraging Power Automate, Power Apps, and Microsoft Fabric AI.
Develop scalable and robust C# applications to support AI-driven automation and system integrations.
Conduct code reviews and follow best practices for building secure, maintainable automation and AI solutions.
Maintain expertise in the Microsoft ecosystem, including data models, security standards, and governance protocols.
Partner with business and IT teams to gather requirements and deliver high-quality, effective solutions.
Mentor team members and champion the adoption of AI-powered automation best practices.
Why this opportunity?

Collaborative, values-driven leadership environment
Hybrid work model built on flexibility and trust
Opportunity to contribute to an organisation that values clarity, trust, and genuine expertise



We are an inclusive employer committed to fostering a diverse and accessible workplace. We encourage applications from Aboriginal and Torres Strait Islander peoples, people with disabilities, LGBTQIA+ individuals, people of all ages, and those from culturally and linguistically diverse backgrounds."
90322114,Lead AI Engineer,Michael Page,https://www.seek.com.au/job/90322114?type=standard&ref=search-standalone&origin=jobCard#sol=21b91f25aa914fe2a38e0f55ce30eee4cbb4b85c,2h ago,2.0,2026-02-13T03:00:00+00:00,Sydney NSW,Engineering - Software (Information & Communication Technology),Full time,Corporate,"We are seeking a highly experienced Principal / Lead AI Engineer who can confidently drive complex client engagements, architect & build sophisticated generative AI solutions, and lead delivery teams across the APAC region. This role blends deep hands‑on technical capability with strong consulting presence, solution leadership, and the ability to engage directly with C‑suite stakeholders.


Client Details

One of the fastest‑growing global AI consultancies, self‑funded and proudly revenue‑driven, the business has grown from 0 to 80+ people in just two years.

The organisation operates with a flat structure, exceptionally high technical talent density (80%+ AI Engineers), and significant involvement from all co‑founders. Women and individuals from diverse or minority backgrounds are strongly encouraged to apply



Description

Solution Leadership & Architecture
Own the end‑to‑end design of agentic LLM systems and generative AI solutions.
Provide architectural leadership across data, models, integrations, and deployment.
Translate ambiguous client challenges into clear, buildable technical roadmaps.
Client Engagement & Consulting
Act as the trusted technical advisor for senior stakeholders, including the C‑suite.
Support (and often lead) pre‑sales conversations, scoping workshops, and solution pitches.
Confidently represent the company in Australia
Delivery & Technical Oversight
Lead teams of Senior & Mid AI Engineers (without formal people management).
Guide engineering quality, code reviews, solution validation, and best practice.
Contribute directly to hands‑on Python, agentic workflows, LLM orchestration, and system building.






Profile

Mandatory Experience
Demonstrated experience as a Principal, Lead AI Engineer, or very senior AI/ML Engineer.
Proven capability to lead end‑to‑end client projects, including architecture and delivery.
Exceptional consulting presence and confidence engaging enterprise clients.
Advanced Python engineering capability (production‑grade).
Strong experience with Generative AI, LLMs, and ideally agentic AI systems.
Ability to guide teams, set standards, and make key technical decisions.


Valid working rights for Australia - no sponsorship available.
Nice to Have
Experience in fast‑growth scale‑up or consulting environments.
Exposure to pre‑sales, scoping, or commercial solutioning.
Familiarity with modern MLOps, LLM Ops, orchestration frameworks, or vector databases.
Experience working with global or distributed engineering teams.



Job Offer

Salary: Senior Principal / Lead level with a competitive high‑band package
EMI Share Scheme available (5‑year execution cycle) for long‑term wealth creation.
Lead flagship AI projects with globally recognised blue‑chip clients across APAC.
Opportunity to build and shape the company's Australian capability from the ground up.
Autonomy, a flat org structure, deep co‑founder access, and a highly technical peer group.
Flexible working, friendly culture, and annual salary review.

To apply online please click the 'Apply' button below"
90320398,Lead AI Engineer,TalentLink,https://www.seek.com.au/job/90320398?type=standard&ref=search-standalone&origin=jobCard#sol=de95dd6949dbc5931073aefedc280da20599f29d,3h ago,3.0,2026-02-13T02:00:00+00:00,Sydney NSW (Hybrid),Engineering - Software (Information & Communication Technology),Full time,,"Lead AI Engineer - Enterprise AI Platforms (LLMs | AWS | Databricks)
 
We're partnering with a large enterprise at a critical point in its AI evolution.
 
This role is for a Lead Engineer who can own the design, delivery and operation of production AI systems — setting technical direction while staying hands-on. You'll lead the build of AI platforms that are safe, scalable, observable and trusted, not experimental or hype-driven.
 
This is a true technical leadership role at the intersection of AI engineering, platform architecture, governance and cross-functional delivery.
 
 
What You'll Own

Technical ownership of enterprise-grade AI systems using LLMs and agentic architectures
Design and operation of LLMOps / AgentOps (prompt lifecycle, evaluation, red-teaming, HITL controls)
Architecture of end-to-end AI data paths: ingestion, embeddings, vector stores, RAG pipelines, caching and quality controls
Safe release strategies: canary deployments, A/B testing, feature flags and controlled exposure
AI system observability, reliability and incident response
Platform evolution, architectural standards and technical debt roadmaps
Technical leadership across teams, including mentoring and engineering standards
Deep collaboration with Product, Security, Legal/Privacy and Executive stakeholders
 
What You Bring

6+ years in software engineering with significant ownership of production AI systems
Deep hands-on experience with LLMs, RAG, tool/function calling, planning and memory
Strong delivery experience on AWS and Databricks (MLflow / Mosaic AI)
Advanced Python engineering (FastAPI / FastMCP preferred)
Strong cloud architecture, CI/CD and Infrastructure-as-Code capability
Deep understanding of AI safety, evaluation, governance and risk controls
Experience leading engineers and setting technical direction
Technical Environment
 
- Python | FastAPI | React + TypeScript
- Databricks Lakehouse | Vector DBs (pgvector or equivalent)
- Advanced RAG + guardrails
- AWS cloud platforms
- CI/CD, automated evals, model registries
- Observability (metrics, logs, traces)
 
This Role Suits Someone Who

Thinks in systems, not demos
Understands AI failure modes and operational risk
Balances speed, safety and scalability
Can lead technically while remaining hands-on
Is comfortable influencing across engineering, product and executive teams
If you want to shape enterprise AI platforms that are safe, trusted and built to last, this is a rare leadership opportunity.
 
Apply now or reach out for a confidential discussion."
90320230,Senior AI Engineer,TalentLink,https://www.seek.com.au/job/90320230?type=standard&ref=search-standalone&origin=jobCard#sol=713a70f8b3b9feb1903530b25668a4e59da803f4,3h ago,3.0,2026-02-13T02:00:00+00:00,Sydney NSW (Hybrid),Engineering - Software (Information & Communication Technology),Full time,,"Senior AI Engineer - Production Systems (LLMs | AWS | Databricks)
 
We're partnering with a large enterprise at a pivotal stage of its AI journey.
They need a Senior Software Engineer who understands AI deeply enough to build safe, reliable, production-grade systems — not prototypes. Someone who can translate AI capability into scalable, governed solutions that solve real business problems.
 
This role sits at the intersection of AI engineering, platform architecture and cross-functional delivery.
 
 
What You'll Do

Design and ship production AI systems using LLMs and agentic architectures
Build and operate LLMOps / AgentOps (prompt management, automated evals, red-teaming, human-in-the-loop)
Engineer end-to-end AI pipelines: ingestion, embeddings, vector stores, retrieval (RAG), caching and quality controls
Deploy safely using canary releases, A/B experiments and controlled rollouts
Implement observability (metrics, logs, traces) and participate in incident response
Partner across Product, Security, Engineering and Leadership to deliver trusted AI solutions
 
Essential Experience

3+ years delivering production-grade AI systems
Hands-on with LLMs, RAG, tool/function calling, planning, memory
Deploying AI on AWS and Databricks (MLflow / Mosaic AI)
Strong Python engineering capability (FastAPI preferred)
CI/CD, model registries and secure cloud architecture
Security fundamentals (IAM, secrets, PII handling, auditability)
Technical Stack
 
- Python | FastAPI | React + TypeScript
- Databricks | Vector DBs (pgvector or equivalent)
- AWS cloud architecture
- Advanced RAG + guardrails
- CI/CD + automated evaluation frameworks
 
 
We're Looking For Someone Who

Thinks beyond experimentation and understands production risk
Designs AI systems that are safe, observable and scalable
Balances speed with governance and reliability
Can communicate complex architecture clearly across technical and executive audiences
If you want to build enterprise AI that actually works — safely, reliably and at scale — we'd love to speak with you."
90319750,Data Architect,Bureau Of Meteorology,https://www.seek.com.au/job/90319750?type=standard&ref=search-standalone&origin=jobCard#sol=41b96a4fe78fccbbf8f2626b4eee13bb1359db52,4h ago,4.0,2026-02-13T01:00:00+00:00,Canberra ACT (Hybrid),"Architects (Information & Communication Technology)
Government - Federal (Government & Defence)",Full time,"$135,402 – $152,073, plus an additional 15.4% supe","Data Architect

Executive Level 2

Melbourne and Canberra

Position overview

The Planning and Architecture Program is seeking a talented and dynamic Data Architect with significant strategic, communication, interpersonal, and organisational skills.

The Data Architect will have a focus on technology and can work in a strategic manner across all programs. This role will assist in collating and developing Data Technology Solutions (Including Cloud) to be used by all users at the Bureau, as well as in the development and maturity of the Planning and Architecture future state for Data.

Under broad direction, the Data Architect will undertake or assist with the functions of:

Domain Architecture:
Data standards including Metadata, Master data and refence data for the Bureau
Knowledge and understanding of multi-dimensional scientific data files, timeseries data and geospatial data. This will include input into the development, publishing and maintenance of various policies, procedures, guide, and reference artefacts to assist the Bureau technology use across all teams and programs.
Effective data sharing between internal users and external parties.
Input and Maintenance of the appropriate data technology components of the Technology Reference Model (TRM)
Experience and understanding of on-premise to Cloud and cloud to premise pipelines for data and processing as part of Cloud and Hybrid Solutions focusing on AWS and Azure.
Large data experience and awareness of Machine Learning and Artificial Intelligence.
Data Technology Roadmap Development: Set the strategic direction to support long-term technology planning and investment aligned to the business trajectory.
Technology Investment Planning: Assist GM Planning & Architecture with investment planning and recommendations to CITO where Cloud technologies are to be considered used
Solution Architecture: Working with the Lead Architect, Chief Architect and other members of the Planning and Architecture team as well as operational staff across DDG to help generate solutions in accordance with business requirements.

The successful candidate will have:

· Experience in architecting, designing, developing and Implementing Solutions on premise, Hybrid, and cloud (AWS and Azure)

· Experience in producing detailed designs utilising components, including Compute, Storage, Data Processing, Machine Learning and Artificial Intelligence, HPC, Networking, Alerting and

Monitoring

· Awareness and understanding with Scientific Data formats including HDF5, NetCDF, and Zarr

· Well-developed engagement and communication skills

Application Closing Date: Sunday, 1 March 2026

For further information please review the position description on https://bomcareers.nga.net.au/?jati=44FB3633-1397-3B75-247A-ECA95980C235"
90319742,Data Architect,Bureau Of Meteorology,https://www.seek.com.au/job/90319742?type=standard&ref=search-standalone&origin=jobCard#sol=ad3c4a67a38f84064b24d9b8d917cf3019e139e9,4h ago,4.0,2026-02-13T01:00:00+00:00,Melbourne VIC (Hybrid),"Architects (Information & Communication Technology)
Government - Federal (Government & Defence)",Full time,"$135,402 – $152,073, plus an additional 15.4% supe","Data Architect

Executive Level 2

Melbourne and Canberra

Position overview

The Planning and Architecture Program is seeking a talented and dynamic Data Architect with significant strategic, communication, interpersonal, and organisational skills.

The Data Architect will have a focus on technology and can work in a strategic manner across all programs. This role will assist in collating and developing Data Technology Solutions (Including Cloud) to be used by all users at the Bureau, as well as in the development and maturity of the Planning and Architecture future state for Data.

Under broad direction, the Data Architect will undertake or assist with the functions of:

Domain Architecture:
Data standards including Metadata, Master data and refence data for the Bureau
Knowledge and understanding of multi-dimensional scientific data files, timeseries data and geospatial data. This will include input into the development, publishing and maintenance of various policies, procedures, guide, and reference artefacts to assist the Bureau technology use across all teams and programs.
Effective data sharing between internal users and external parties.
Input and Maintenance of the appropriate data technology components of the Technology Reference Model (TRM)
Experience and understanding of on-premise to Cloud and cloud to premise pipelines for data and processing as part of Cloud and Hybrid Solutions focusing on AWS and Azure.
Large data experience and awareness of Machine Learning and Artificial Intelligence.
Data Technology Roadmap Development: Set the strategic direction to support long-term technology planning and investment aligned to the business trajectory.
Technology Investment Planning: Assist GM Planning & Architecture with investment planning and recommendations to CITO where Cloud technologies are to be considered used
Solution Architecture: Working with the Lead Architect, Chief Architect and other members of the Planning and Architecture team as well as operational staff across DDG to help generate solutions in accordance with business requirements.

The successful candidate will have:

· Experience in architecting, designing, developing and Implementing Solutions on premise, Hybrid, and cloud (AWS and Azure)

· Experience in producing detailed designs utilising components, including Compute, Storage, Data Processing, Machine Learning and Artificial Intelligence, HPC, Networking, Alerting and

Monitoring

· Awareness and understanding with Scientific Data formats including HDF5, NetCDF, and Zarr

· Well-developed engagement and communication skills

Application Closing Date: Sunday, 1 March 2026

 

For further information please review the position description on https://bomcareers.nga.net.au/?jati=44FB3633-1397-3B75-247A-ECA95980C235"
90319147,Azure Cloud Architect,Latitude IT,https://www.seek.com.au/job/90319147?type=standard&ref=search-standalone&origin=jobCard#sol=4f1d2a7299299c07da9f9074e041441148b1eec5,4h ago,4.0,2026-02-13T01:00:00+00:00,Sydney NSW (Hybrid),Architects (Information & Communication Technology),Full time,Up to $190k base + super,"Azure Cloud Architect
Location: Sydney, 50/50 hybrid
Package: Up to $190k base + 15% super
  
The Opportunity
A nationally critical Government regulator is entering the next phase of its cloud and cyber evolution. The cloud foundations are in place. Core platforms are operating across Azure and AWS. The migration is done.
  
Now the focus shifts to hardening, securing, and governing the environment at the national scale.
  
A multi-year cyber uplift program is underway. Identity, monitoring, data governance, and secure delivery are being strengthened across the Microsoft ecosystem. This is enterprise cloud architecture inside a PROTECTED environment. Decisions made here influence how regulatory systems operate across Australia.
  
This is not a SOC role. Not policy-only. Not GRC advisory. It is a platform-level Microsoft architecture with ownership. Think Real systems. Real scrutiny. Real accountability.
  
The Role:

You will operate as a senior Microsoft-aligned Cloud Architect embedded within a long-term cyber uplift program.
Producing high and low-level architecture across Azure and Microsoft security workloads
Designing and strengthening identity architecture across Entra ID and Active Directory
Embedding security controls into M365, Sentinel, and Purview environments
Contributing to secure SDLC integration across CI/CD pipelines
Shaping platform guardrails and governance patterns aligned to PROTECTED controls
Improving monitoring, logging, and security visibility across the estate
Partnering with cyber, infrastructure, and engineering teams to remove architectural friction
Presenting and defending design decisions within governance forums
Balancing strong security posture with operational pragmatism
Business Context:

Enterprise-scale regulated environment
Commercial off-the-shelf platforms hosted in the cloud
Strict governance and compliance frameworks
Multi-year cybersecurity uplift program
This role is structured as a 2-year FTC aligned to the cyber program roadmap. The broader program extends beyond that timeframe, and high performers are typically retained where possible.
  
What We’re Looking For:

5+ years in Azure cloud or infrastructure architecture
Strong alignment with the Microsoft ecosystem
Experience across Azure, M365, Sentinel, Purview, and identity architecture
Exposure to regulated, enterprise, financial services, or government environments
Confidence operating in structured governance settings
Clear, concise communicator with strong architectural judgement
Australian citizen with Baseline eligibility
Ideal career trajectory: Infrastructure or identity engineer → cloud/security engineer → cloud architect.
Less suited: Pure GRC or compliance-only profiles without deep platform architecture experience.
Apply now or reach out for a confidential discussion."
90318802,Mid-Senior AI Engineer – Agents & AWS (Music Industry),Tuned Global Pty Ltd,https://www.seek.com.au/job/90318802?type=standard&ref=search-standalone&origin=jobCard#sol=58fc812a0952ced94e898428e7a857e2192886cb,4h ago,4.0,2026-02-13T01:00:00+00:00,"Docklands, Melbourne VIC (Hybrid)",Engineering - Software (Information & Communication Technology),Full time,"$150,000 – $165,000 per year","At Tuned Global, we build the technology that powers music and audio streaming for some of the world's most recognisable brands. Our platforms sit behind large-scale consumer products, delivering millions of audio experiences every day.

We're not experimenting with AI, we're shipping it into production at scale.

Across the company, we are investing heavily in AI capabilities including:

Proprietary in-house audio detection models

LLM-powered agent systems

Personalisation and recommendation intelligence

Scalable AI infrastructure and orchestration

Headquartered in Melbourne, we also have an expanding global AI capability group, including an AI Sciences team based in the UK, and a Data Science team in Sweden, working alongside our local product and engineering teams to deliver next-generation music intelligence products.

We're now looking for a Mid-Senior AI Software Engineer to join our Melbourne team and help build the next wave of applied AI systems for audio and streaming platforms.

We are located on the edge of the CBD in Docklands, with easy access via train, tram, or car. We offer an excellent package and flexible work arrangements, including working from home for a number of days each week and birthday leave.

The Role

As a Mid-Senior AI Engineer you will be focused on designing, building, and scaling AI agents that operate within real business workflows and combine modern cloud engineering with advanced Agentic workflows.

You will help define the technical patterns, standards, and best practices for how AI agents are built and operated across our music cloud platform.

You will work on projects such as:

LLM-powered orchestration systems and AI agents

Retrieval-Augmented Generation (RAG) pipelines

AI-powered automation tools integrated into real platforms

Internal AI developer tooling and infrastructure

AI services deployed on AWS for reliability, scale, and performance

This is a hands-on engineering role with real ownership, building AI agents that are used at scale in commercial environments.

You will work hands-on with Python, AWS, AWS Bedrock, LLMs, and modern agent frameworks, collaborating closely with product, platform, and operational teams in a fast-moving scale-up environment.

Key Responsibilities
AI Agent & Workflow Development

Design and build AI-powered agents and multi-step agentic workflows to automate and augment internal business processes using LLMs.

Implement tool-using agents that can call internal services, APIs, and data sources.

Build retrieval-augmented generation (RAG) pipelines and structured knowledge access.

Apply modern agent patterns such as multi step planning, orchestration, and human-in-the-loop workflows.

Platform & Cloud Engineering

Develop and operate AI systems using AWS-native services, including Lambda, ECS/EKS, Step Functions, SQS, DynamoDB, and S3, Bedrock (or equivalent LLM services).

Design secure, scalable, and cost-aware solutions suitable for production environments.

Build internal tools and services required to support agents (APIs, data models, workflow services).

Integration & Collaboration

Work closely with engineering, product, and operational teams to identify high-impact use cases for AI agents.

Translate business problems into reliable, maintainable AI-driven systems.

Contribute to architectural decisions and technical standards around AI and automation.

Reliability & Continuous Improvement

Implement monitoring, logging, and evaluation for agent behaviour and system performance.

Continuously improve prompt quality, agent reliability, and workflow efficiency.

Stay current with emerging best practices in LLMs, agent frameworks, and AI system design.




Skills / Experience:
Required

5+ years of professional software engineering experience

Strong experience building backend services in production environments

Minimum 2+ years of AWS cloud experience designing and deploying real workloads

Experience working with LLMs, including API-based models and prompt engineering

Understanding of AI system patterns (RAG, agents, embeddings, vector stores, evaluation)

Strong proficiency in Python (and/or other backend languages)

Strong engineering fundamentals: system design, scalability, performance, reliability

Australian work authorisation required at time of application

Preferred / Nice to Have

Experience with agent frameworks such as:

LangChain

Function / tool calling

Multi-agent or orchestrated workflows

Familiarity with Model Context Protocol (MCP) or similar approaches to structured tool and context integration.

Experience with:

Retrieval-augmented generation (RAG)

Vector databases and embeddings

Event-driven or asynchronous architectures

Experience building internal developer or operational tooling.

Exposure to music, media, or content platforms.



Why Tuned Global

This is an opportunity to join a company with:

A mature, global platform powering real audio streaming businesses

A growing AI investment strategy with international collaboration

A culture of building and shipping, not endless experimentation

Access to real-world datasets and production systems

The chance to build applied AI that directly improves products




What's on Offer

Competitive salary package

Hybrid work model based in Melbourne

Opportunity to work with world-class engineering and AI teams across Australia, the UK and Sweden

High-impact role with real ownership and room to grow

Work on cutting-edge LLM and AI agent systems deployed into production



No Agencies Please"
90320060,"Domain Expert, Analyst - Defense (12 Month Fixed-Term)","Dataminr, Inc and Affiliates",https://www.seek.com.au/job/90320060?type=standard&ref=search-standalone&origin=jobCard#sol=3fd1491a8d086be851b27b99aaee88ac589d5908,5h ago,5.0,2026-02-13T00:00:00+00:00,Melbourne VIC (Hybrid),Engineering - Software (Information & Communication Technology),Full time,,"See yourself at Dataminr

Dataminr’s Domain Experts work with Dataminr’s AI platform in real time ensuring the alerts and intelligence we send to our clients are of the best possible quality. Domain Experts use deep human expertise to examine and analyze our data feeds and annotate, label, and edit signals in real time. You will be an integral part of our algorithm training process and our advanced realtime human-AI feedback loop that integrates key knowledge domains into our AI models and develops our AI platform. As a Domain Expert, you will also play a key role in defining new factors to improve our alerts, data source coverage, machine learning, AI models, and AI tooling.

This role is open as remote (Australia) or hybrid, and requires the ability to work core hours of 8:00am - 4:00pm AEST or 10:00am - 6:00pm AEDT in a real-time information environment. Please note that this role requires rotational weekend work as well as projects and meetings outside of business hours. This role is a fixed term contract opportunity that runs for a period of up to 12 months.

AI Innovation at Dataminr 

Working at Dataminr you’ll have the opportunity to tackle the most exciting trends in AI on a daily basis to power a revolutionary product that uncovers critical events around the world as they unfold.

Regenerative AI: our AI technology, ReGenAI, is a new form of generative AI that automatically regenerates real-time Live Event Briefs as events unfold. Learn more here.

Agentic AI: we recently launched our Agentic AI capability, what we’re calling our Intel Agents, that autonomously generates critical context for our clients on real-time events, threats, and risks allowing them to see the clearest, most accurate view of what’s happening on the ground. Learn more here

Multimodal AI: our platform detects events from many different types of data (images, video, sensor data, audio, and text in over 150 languages). Learn more here. 

The opportunity


 Serve as an expert on Defense, Military Affairs and related geopolitical developments and the relevant source environment and data sets associated with these areas to improve our AI models

Monitor and analyse the quality of our data feeds

Annotate and label complex real time events, making real-time decisions with incomplete data

Own and develop projects to improve performance of AI models and AI tooling in the real time event detection space

Collaborate and communicate about daily priorities in a team-centric environment 

What you bring


At Dataminr, we value you for who you are. We encourage you to apply for this role, even if you don't meet every qualification. Our candidates are reviewed on the basis of their skill and potential to succeed.

Bachelor's degree required; ideally with a concentration in: Defense or Strategic Studies, political science, security/conflict studies, or a closely related field strongly preferred

Ability to monitor and analyze data with strong online research skills in a fast-paced environment in English; other languages a plus

An understanding of geopolitical risk and world events

Passion for breaking news, current world events, technology, and a great understanding of both social media and publicly-available data

Ability to interpret and succinctly describe ongoing, complex events with incomplete data

Fluency with AI tools and LLMs, and experience using them to solve problems, improve workflows, and make efficiencies 

Enthusiastic approach to innovation and strategic thinking

#LI-SM

#LI-REMOTE

About Dataminr

At Dataminr, we are a mission driven team of talented builders, creators and visionaries who have real-world impact on how organizations are able to respond to events. Dataminr’s groundbreaking, AI-powered, intelligence platform provides organizations with the earliest signals of emerging risks, events, and threats before they unfold. Trusted by two-thirds of the Fortune 50 and half of the Fortune 100, Dataminr’s platform analyzes billions of public data inputs spanning text, image, video, audio and sensor data across 150+ languages, empowering our clients to stay one step ahead in an increasingly complex world where every second counts. 

Founded in 2009, we have pioneered the world’s first real-time event detection platform, long before the recent Gen AI ‘boom.’ Dataminr operates all around the world united by our passion to use AI for the greater good, be agents of positive change and put our technology into the hands of clients charged with the responsibility to keep organizations running and keep people safe.

As our employees focus on developing our revolutionary technology, we focus on our employees. Dataminr is proud to offer a variety of flexible work arrangements, offices all over the world to foster collaboration, generous PTO and sick leave, and more, as part of our competitive benefits package aimed at keeping all our employees happy and healthy. Explore all our benefits here. 

We believe our differences give us strength. Our employees are empowered to be their best, authentic selves through various opportunities, such as our robust employee resource group (ERG) network, manager development programming, professional development funds, and more.

We serve a global community made up of many cultures and strive to reflect the world and clients we serve, with a workforce built on merit and equity. We actively condemn racism and discrimination in any form. We stand for social good, fostering a culture of allyship, and standing up for those who face systemic barriers to equality. We lead with empathy and strive to be agents of positive change in our company and in our communities.

Dataminr is an equal opportunity and affirmative action employer. Individuals seeking employment at Dataminr are considered without regards to race, sex, colour, creed, religion, national origin, age, disability, genetics, marital status, pregnancy, unemployment status, sexual orientation, citizenship status or veteran status.

Dataminr will collect and process your personal data. All personal data will be processed in accordance with applicable data protection laws. Please see Dataminr's candidate privacy notice available here. By providing your details and applying via our careers website, you acknowledge that you have read our candidate privacy notice. If you have any queries, please contact the People Team at hr@dataminr.com or privacy@dataminr.com."
90318056,Conversational AI Designer,Emanate Technology Pty Ltd,https://www.seek.com.au/job/90318056?type=standard&ref=search-standalone&origin=jobCard#sol=b392ce4f487bc0e464942c3caca8e68848a08808,5h ago,5.0,2026-02-13T00:00:00+00:00,Adelaide SA (Hybrid),Engineering - Software (Information & Communication Technology),Full time,,"Conversational AI Designer ( Mid / Senior or Lead )  

Adelaide CBD

Hybrid (3 days onsite)

Full-time | Permanent
Emanate Technology is partnering with a leading enterprise organisation to appoint a Conversational AI Designer to play a key role in designing and delivering next-generation, AI-driven customer experiences.

This is an opportunity to move beyond traditional chatbot flows and lead the design and development of Agentic AI systems that can plan, reason and take action across complex booking and service platforms.
If you’re excited by AI that doesn’t just respond but acts, this role is for you.

The Opportunity
You will design, build and optimise intelligent conversational systems across digital channels, with a strong focus on booking platforms, transactional workflows and automation at scale.
Working within an agile delivery environment, you will collaborate with product, engineering, architecture and operational stakeholders to transform complex service journeys into scalable, AI-powered experiences.
This role requires someone who understands how conversational AI operates inside large corporate ecosystems, particularly those with high-volume digital transactions and contact centre operations.

Key Responsibilities
Design and develop Agentic AI systems capable of multi-step reasoning, planning and workflow orchestration
Translate business requirements into conversational architectures and automated service flows
Design NLU models, prompt frameworks, dialog structures and decision trees
Map and optimise end-to-end booking and transactional journeys
Improve containment rates and reduce agent handling time through intelligent automation
Analyse performance data and continuously optimise AI behaviour
Collaborate with technical teams on API integrations, backend systems and orchestration layers
Influence conversational AI standards and best practice across the organisation

About You
We’re open to diverse backgrounds including Conversation Design, UX, Service Design, Product, Business Analysis or Development — what matters is your ability to design systems that work in the real world.
You will ideally bring:
Experience designing conversational AI across chat, voice or messaging platforms
Exposure to LLMs, NLU/NLP frameworks and prompt engineering
Experience building or contributing to Agentic systems or multi-step automated workflows
Experience working on booking platforms, transactional systems or high-volume digital services
Experience in large corporate environments
Exposure to contact centre technology (Genesys, Salesforce, Cognigy or similar) highly regarded
Strong stakeholder engagement and workshop facilitation skills
Ability to navigate ambiguity and turn complexity into structured, scalable solutions
Why Apply
This is an opportunity to work on enterprise-grade AI solutions that impact thousands of users daily. You will help shape how intelligent systems operate within complex corporate environments and contribute to the evolution of AI-driven customer engagement. If you’re ready to design AI that doesn’t just talk — but acts — we’d welcome a confidential discussion.
This role also comes with fantastic employee benefits unique to the client. 


We are an inclusive employer committed to fostering a diverse and accessible workplace. We encourage applications from Aboriginal and Torres Strait Islander peoples, people with disabilities, LGBTQIA+ individuals, people of all ages, and those from culturally and linguistically diverse backgrounds."
90317954,Azure AI Solutions Architect - 100% remote.,Eagna Consulting,https://www.seek.com.au/job/90317954?type=standard&ref=search-standalone&origin=jobCard#sol=00e083dfbb27a3b6d8e9c5140e4947221457e372,5h ago,5.0,2026-02-13T00:00:00+00:00,Sydney NSW (Remote),Architects (Information & Communication Technology),Full time,Up To $240K,"Senior Azure AI Architect. GenAI & Agentic AI Permanent | 100% Remote | Government Projects. Security clearance Required.

The Opportunity We are seeking a Senior Azure AI Architect to lead the design and delivery of Azure native Generative AI and agentic AI solutions across complex enterprise and government environments.

This is a senior, hands-on architecture role requiring deep expertise in Python, Azure OpenAI, Semantic Kernel, and modern LLM orchestration patterns. You will shape AI strategy, lead technical direction, and deliver secure, scalable, production-grade solutions.

If you’re passionate about building real-world AI systems at scale and influencing long-term transformation programs, this role offers genuine impact.
Key Responsibilities
Architect and implement Generative AI and agentic AI solutions on Microsoft Azure
Build intelligent agents using Azure AI Semantic Kernel, vector memory, and orchestration patterns
Design scalable AI pipelines, integrations, and model optimisation workflows
Lead stakeholder workshops and define AI strategies aligned to government and enterprise objectives
Provide architectural leadership and best-practice guidance to engineering and delivery teams
Translate complex AI concepts into clear, commercially aligned solutions
Skills & Experience
10+ years’ IT experience, including 5+ years on Microsoft Azure
Strong Python engineering skills for workflows and orchestration
Hands-on experience with Azure AI Services, Azure OpenAI, Cognitive Search, and vector databases
Practical experience with agentic AI, MLOps/LLMOps, CI/CD, and enterprise governance
Experience working in distributed and containerised environments such as Kubernetes and Git
Ability to engage confidently with senior business and technology stakeholders
Desirable
Microsoft Azure certifications such as AI-102, AZ-204, or Azure Solutions Architect
Experience in data engineering and large-scale data processing including PySpark or Databricks"
90317753,AI Engineer - Data,PERSOL,https://www.seek.com.au/job/90317753?type=standard&ref=search-standalone&origin=jobCard#sol=4002c6e9f15a2aec48193d6a5402ee525f6b36cb,5h ago,5.0,2026-02-13T00:00:00+00:00,Perth WA,Developers/Programmers (Information & Communication Technology),Contract/Temp,$70-$90 per hour super,"PERSOL is one of Australia's largest and longest serving recruitment providers. Delivering both quality temporary and permanent options, we specialise in the recruitment of Professional, ICT, Government, STEM, Management and Executive talent.

We are currently hiring for AI Engineer to join the Data & AI Platform team that design and operate the platforms, components, and workflows that support machine learning, GenAI, data-driven optimisation, and enterprise automation.

As an AI Engineer / Developer, you will help build and operate AI platform-supporting traditional ML, LLM-based applications, orchestration frameworks, and end-to-end MLOps/LLM Ops processes. You'll work with data scientists, architects, and product teams to deliver reliable, integrated, and value-focused AI solutions across the business.

Responsibilities

Develop and maintain reusable AI components, APIs, microservices, and orchestration frameworks.
Support the implementation of ML and GenAI architectures, including retrieval pipelines and agentic workflows.
Build platform capabilities for model deployment, automation, monitoring, evaluation, and lifecycle management (MLOps & LLM Ops).
Integrate AI services into business workflows, ensuring alignment with enterprise architecture, security, and data governance.
Collaborate with cross-functional teams to deliver scalable and production-ready AI solutions.

Experience Required

Bachelor's degree in Computer Science, Engineering, Artificial Intelligence, or related field.
Minimum 2+ years of experience in designing, developing and deliverin AI/ML systems, including cloud-native solutions.
Software Engineering/Programming: Proficient in Python (essential). Familiarity with TypeScript/JavaScript, C#, or Go beneficial.
ML/AI Frameworks: Practical experience with ML frameworks such as PyTorch, TensorFlow, Hugging Face, and LangChain.
GenAI & RAG: Exposure to embedding models, vector stores, retrieval chains, and agentic orchestration approaches is desirable.
Cloud & DevOps: Working knowledge of cloud platforms (AWS or Azure), containerization (Docker), orchestration (Kubernetes), infrastructure-as-code (Terraform), and familiarity with CI/CD processes and monitoring tools.

If interested in this role please apply today or alternatively send your resume to Neema Mehra, neema.mehra@persolapac.com Please note that due to the high volume of applicants only shortlisted candidates will be contacted."
90317584,"Data Engineers - Azure / Databricks - Fabric, Synapse Link, PowerBI",Novon,https://www.seek.com.au/job/90317584?type=standard&ref=search-standalone&origin=jobCard#sol=ddf8ca132015651135447966f7b8fd65bfd29bc6,5h ago,5.0,2026-02-13T00:00:00+00:00,Sydney NSW (Hybrid),Consultants (Information & Communication Technology),Full time,,"Are you a senior Data Engineer, immersed in data-driven projects that help organisations modernise their platforms and build scalable analytics solutions?

Support our customers by designing and delivering data engineering solutions. Success will come from being proactive, clarifying requirements, and building trust with stakeholders while solving complex problems.

Requirements:

Design, Develop, Model and Optimise Databricks Lakehouse services
Design, build, and test Data Services and Pipelines using DBT
Ensure data quality, integrity, and platform reliability
Build scalable solutions using modern, cloud-native tools
Apply best practices around data security and compliance
Monitor and improve data workflows and performance
Technology / Tooling:

Databricks
DBT
Synapse / Azure
Synapse Link
Power BI (preferable)

About YOU: You’ll ideally bring min 5 years’ experience in data engineering roles and be confident deploying and maintaining Databricks Lakehouse on Azure. You’re a team player, curious, coachable, and love learning from others as much as teaching them.

• Challenging Projects – You’ll be embedded in client teams helping deliver high-impact data engineering initiatives across ingestion, modelling, transformation, and governance.

• Learn from Experts – Be part of a collaborative, knowledge-sharing consulting team that values mentorship, continuous learning and community."
90317079,Data Engineer,Live Nation Australasia,https://www.seek.com.au/job/90317079?type=standard&ref=search-standalone&origin=jobCard#sol=bd94b7c5797269eb690284b0ef528fd8db0ba9b5,5h ago,5.0,2026-02-13T00:00:00+00:00,Melbourne VIC (Hybrid),Engineering - Software (Information & Communication Technology),Contract/Temp,,"About Live Nation:
Join the team at Live Nation, where innovation meets live entertainment on a global scale! With 40,000 shows and 500 million tickets sold each year, we’re the industry leader, powered by 44,000 talented individuals worldwide. At Live Nation, we’re passionate about transforming live events and creating extraordinary moments for artists, event professionals, and fans.




About the Role:
We’re looking for a Data Engineer (6-month contract) to play a key role in evolving our cloud data platforms across Live Nation Australia and New Zealand.

Working within our AWS and Databricks environments, you’ll design, build, and optimise data pipelines that underpin reporting, business intelligence, marketing performance, and emerging AI initiatives. Your focus will be on data quality, scalability, and operational excellence – ensuring our teams can trust and leverage data at speed.

This is a hands on role within a modern, cloud-first data ecosystem supporting millions of fan interactions and high impact commercial decisions.




What you’ll be doing: 

Pipeline development and operations: Build, maintain, and monitor data pipelines in AWS and Databricks, ingesting and transforming data from ticketing, POS, access systems, subscriptions, and marketing platforms to support analytics and AI/ML use cases.

Data quality and governance: Ensure data integrity, security, and availability across first-party and partner sources while contributing to governance standards including access controls, naming conventions, and documentation.

Analytics and modelling: Develop and maintain modelled datasets for BI, segmentation, and downstream use cases, supporting reliable reporting and business decision-making.

AI/ML enablement: Prepare production-ready datasets and features for predictive models including propensity, churn, demand, and lifecycle use cases.

Platform monitoring and optimisation: Monitor pipeline health and platform usage, escalating performance or reliability issues and assisting with onboarding new data sources as business needs evolve.

Cross-functional collaboration: Act as the day-to-day engineering voice within projects, translating business requirements into practical data solutions while maintaining clear technical documentation and runbooks.




What we’re looking for:

Cloud and platform expertise: Strong hands-on experience with AWS (S3, IAM, cost awareness) and Databricks (Jobs, Workflows, Lakehouse concepts), with solid Apache Spark proficiency in SQL and DataFrame APIs.

Production-level SQL and Python: Strong, production-ready skills in SQL and Python for complex data transformations, pipeline orchestration, and large-scale data processing.

Data modelling and pipeline reliability: Experience building data models for analytics and segmentation, with a strong focus on data quality, validation, pipeline monitoring, and operational support to maintain high availability.

Security and governance mindset: Familiarity with secure data access practices including secure views, Delta Sharing, and RBAC, along with a commitment to clear documentation and governance standards.

AI/ML dataset preparation: Ability to prepare datasets and features for predictive and machine learning use cases, understanding how to structure data for effective model training and deployment.

Practical problem-solver: A solutions-focused engineer who communicates clearly, documents thoroughly, and enjoys working across teams to turn complex requirements into reliable data solutions.



Equal Opportunities: 
We are passionate and committed to our people and go beyond the rhetoric of diversity and inclusion. You will be working in an inclusive environment and be encouraged to bring your whole self to work. We will do all that we can to help you successfully balance your work and Homelife. As a growing business, we will encourage you to develop your professional and personal aspirations, enjoy new experiences, and learn from the talented people you will be working with. It's talent that matters to us and we encourage applications from people irrespective of their gender, race, sexual orientation, religion, age, disability status or caring responsibilities."
90293890,Senior MLOps Engineer,"TRU Recognition AI Pty Ltd,",https://www.seek.com.au/job/90293890?type=standard&ref=search-standalone&origin=jobCard#sol=e3a00c05424e8a850e37abf06abb44aadb0de056,6h ago,6.0,2026-02-12T23:00:00+00:00,Melbourne VIC (Remote),Engineering - Software (Information & Communication Technology),Full time,,"Role Overview

As a Senior–Staff–Principal MLOps Engineer, you will own the end-to-end ML systems lifecycle at TRU: training, evaluation, deployment, monitoring, and continuous improvement of production models.

This is not a support role. You will design the ML platform itself—setting standards, defining architecture, and making trade-offs that directly affect product performance, cost, and customer trust.

You will work tightly with Computer Vision, Backend, and Product teams to ensure that experimentation translates into stable, observable, and scalable production systems.

Key Responsibilities
Foundation Model Ops

Design deployment patterns for LLM/VLM inference (GPU scheduling, concurrency control, caching, batching, streaming responses where relevant).

Implement RAG and multimodal retrieval pipelines (vector DBs, embedding lifecycle, evaluation, refresh policies).

Build evaluation harnesses for LLM/VLM systems (golden sets, regression tests, hallucination/consistency checks, safety filters).

Support fine-tuning / adapters (LoRA/QLoRA), model registry, and rollback-safe release processes.

Own cost/performance governance for foundation models (latency SLOs, token/image cost budgets, GPU utilization).

ML Platform & Deployment

Design and operate CI/CD pipelines for ML training, validation, and deployment (GitHub Actions, GitLab CI, Jenkins).

Build and maintain scalable, GPU-backed model serving infrastructure (Triton, TorchServe, FastAPI/gRPC, or managed services).

Own containerization and Kubernetes deployment patterns for inference and batch workloads.

Data & Streaming Systems

Design and operate real-time, event-driven pipelines using Kafka / Redpanda / Pulsar / Kinesis / Pub/Sub / NATS.
Implement and tune stream processing frameworks (Flink, Beam, Spark Structured Streaming) for low-latency analytics.

Enforce data contracts, schemas, and lineage across training and inference paths.

Model Lifecycle & Observability

Implement experiment tracking, model versioning, and lineage (MLflow, W&B, DVC, custom).

Build automated retraining and continuous evaluation pipelines.

Own observability across infrastructure and model behavior (latency, throughput, drift, quality metrics).
Design alerting and dashboards (Prometheus, Grafana, Datadog).

Performance & Reliability

Collaborate with CV engineers to optimize GPU inference (batching, concurrency, memory, profiling).

Drive cost/performance trade-offs across cloud, hybrid, and on-prem deployments.

Ensure secure, reproducible, and auditable ML releases.

Leadership

Act as a technical authority for MLOps architecture.

Mentor junior engineers and influence engineering best practices across teams.

Required Skills & Experience

5+ years in MLOps / ML Platform / DevOps for ML, with deep Python experience.

Strong production experience with Docker and Kubernetes.

Proven operation of real-time or near-real-time streaming systems.

Hands-on production model serving experience, including GPU workloads.

CI/CD, IaC (Terraform, Helm), and experience on AWS, GCP, or Azure.

Strong systems thinking and cross-team communication skills.

Nice to Have

CUDA, TensorRT, mixed precision, quantization, or model optimization for edge.

vLLM / TensorRT-LLM / Triton for LLMs, KV-cache management.

Multimodal pipelines (image/video + text), prompt/version management, LLM eval tooling (custom or open-source).

Experience deploying foundation models in on-prem / constrained / privacy-sensitive environments.

Video analytics or large-scale computer vision systems.

On-prem / air-gapped deployments, secure model packaging, encryption.

Data governance and lakehouse technologies (Delta, Iceberg, Hudi)."
90316562,Data Engineer,Charterhouse,https://www.seek.com.au/job/90316562?type=standard&ref=search-standalone&origin=jobCard#sol=71b6ac14e9dd6bc50f5b3a2f20679d7958d94bd3,6h ago,6.0,2026-02-12T23:00:00+00:00,Sydney NSW (Hybrid),Other (Information & Communication Technology),Full time,AUD 140000 - 160000 per annum,"About the Role

We’re working with a high-growth, technology-led financial services organisation building a modern Data & AI Platform that underpins analytics, machine learning, and emerging AI-driven capabilities across the business.
As a Data Engineer, you’ll play a pivotal role in designing and scaling the pipelines, infrastructure, and data products that power business intelligence, advanced analytics, and AI experimentation.
This is a hands-on engineering role combining strong software engineering fundamentals with modern data architecture practices. You’ll help enable secure, scalable, and production-ready data and AI solutions that empower cross-functional teams to leverage data effectively.

What You’ll Be Doing

Core Platform Engineering
Design, build and maintain robust, scalable data pipelines and integrations
Improve performance, observability and resilience across the data stack
Support ingestion, transformation and quality assurance within modern cloud data warehouses
Apply DevOps and infrastructure-as-code practices to enhance platform reliability
AI Enablement & Experimentation
Collaborate with Product and Engineering teams to operationalise machine learning and generative AI solutions
Build strong data foundations and feature pipelines to support LLMs and advanced AI use cases
Contribute to governance frameworks that enable safe and responsible AI deployment
Collaboration & Delivery
Work within cross-functional squads to support analytics, reporting and AI initiatives
Develop data products, APIs and dashboards that improve access to trusted data across Finance, Risk, Product and other teams
Continuously enhance the scalability, resilience and security of the broader data ecosystem
Quality, Security & Governance
Embed best practices across testing, version control and security
Uphold high standards of data quality, observability and compliance within a regulated environment
Promote responsible and ethical AI principles

What You’ll Bring
Strong experience with cloud-based data platforms (AWS preferred)
Hands-on experience with modern cloud data warehouses (e.g. Snowflake)
Experience with streaming and distributed data processing technologies (e.g. Kafka, Spark, Kinesis, Flink)
Strong software engineering skills in Python, Scala, Java or Kotlin
Exposure to machine learning or AI systems in production environments
Familiarity with MLOps tooling, feature stores or vector databases (advantageous)
Experience building dashboards or working with analytics tools (e.g. Tableau, Looker)
Understanding of data governance, security and compliance within regulated industries

What’s in It for You?
Hybrid working model
Strong focus on learning, growth and career development
Generous parental leave policies
Additional wellbeing and recharge days
Team-based volunteer initiatives
Regular social events and collaborative team culture
Health and wellness support initiatives"
90316402,Data & AI Engineer,Charterhouse,https://www.seek.com.au/job/90316402?type=standard&ref=search-standalone&origin=jobCard#sol=79eac9009511d397121282aa9a8fb9b2f05ea9d6,6h ago,6.0,2026-02-12T23:00:00+00:00,Sydney NSW,Other (Information & Communication Technology),Full time,AUD 140000 - 160000 per annum,"About the Role

We’re partnering with a high-growth, technology-led financial services organisation building a modern Data & AI Platform to power analytics, machine learning, and next-generation AI capabilities across the business.
This is a hands-on engineering role within a small, high-impact team responsible for designing and scaling the foundations that enable trusted data, advanced analytics, and production-grade AI solutions.
Depending on your strengths, you may focus on:

Building and scaling robust data pipelines and infrastructure
Developing reusable platform patterns and guardrails
Enabling product teams to safely deploy AI-driven features
Operationalising machine learning and generative AI solutions
You’ll work closely with engineering, product, risk, and cloud teams to deliver secure, scalable, and production-ready data and AI capabilities.

What You’ll Be

Doing Build & Scale the Data Platform
Design, build and maintain scalable data pipelines and integrations
Manage ingestion, transformation and quality across cloud data warehouses
Improve reliability, performance and observability across the data stack
Apply modern DevOps and infrastructure-as-code practices
Enable AI & Advanced Analytics
Support the deployment of machine learning and generative AI solutions into production
Build strong data foundations and feature pipelines for AI experimentation
Develop reusable templates and reference architectures for training, inference and deployment
Enable squads to safely ship AI capabilities within defined governance frameworks
Deliver Business Impact
Partner with cross-functional teams to support analytics, reporting and AI use cases
Develop APIs, data products and trusted datasets for enterprise consumption
Continuously enhance scalability, resilience and security of the platform
Champion Governance & Quality
Embed best practices in testing, version control and security
Support compliance within regulated environments
Promote responsible and ethical AI practices

What You’ll Bring
Strong experience with cloud-based data platforms (AWS preferred)
Hands-on experience with Snowflake or modern cloud data warehouses
Experience with streaming or distributed processing technologies (e.g. Kafka, Spark, Kinesis, Flink)
Strong software engineering skills in Python, Scala, Java or Kotlin
Exposure to machine learning or AI systems in production environments
Familiarity with MLOps, feature stores, or vector databases (highly regarded)
Experience with infrastructure-as-code and CI/CD practices
Understanding of governance, security and data quality in regulated industries

Why Apply?
Work on real-world AI use cases beyond experimentation
Influence architecture in a growing data and AI platform
Join a lean, high-impact team with strong executive backing
Build systems that directly power product innovation and business growth"
90316044,Senior Machine Learning Engineer - Design Import (ANZ remote),Canva,https://www.seek.com.au/job/90316044?type=standard&ref=search-standalone&origin=jobCard#sol=0febeefda920484c552ff6e9f3087644f82eef79,7h ago,7.0,2026-02-12T22:00:00+00:00,Sydney NSW (Hybrid),Engineering - Software (Information & Communication Technology),Full time,,"Company Description


Join the team redefining how the world experiences design.

Hey, g'day, mabuhay, kia ora,你好, hallo, vítejte!

Thanks for stopping by. We know job hunting can be a little time consuming and you're probably keen to find out what's on offer, so we'll get straight to the point. 

Where and how you can work

Our flagship campus is in Sydney, with a second campus in Melbourne and co-working spaces in Brisbane, Perth, Adelaide, and Auckland, NZ. You have flexibility in how and where you work — whether that's from one of our spaces, from home, or a mix of both. This role is remote-friendly within Australia or New Zealand, so you can choose the setup that empowers you and your team to do your best work.

Job Description


About the Group/Team

The Editing Platform group sits within the Design Experience supergroup and powers the foundations that enable anyone, anywhere, to create beautiful designs with speed and confidence. We build secure, performant, reliable, and scalable platform capabilities that support Canva’s editor and unlock powerful new product experiences.

Within this group, the Design Import team is focused on making it effortless for users to bring their designs into Canva from external tools and formats. We work at the intersection of rendering systems, file parsing, performance engineering, and user experience — ensuring that imported designs are accurate, editable, and production-ready. Our work plays a critical role in reducing friction for new users and deepening value for teams and enterprises migrating to Canva.

About the Role/Specialty:

As the first Senior Machine Learning Engineer on Design Import, you’ll be pioneering ML capability within the team. You’ll bring conceptual and practical expertise to complex problems and apply machine learning techniques to improve import accuracy, structure recognition, layout reconstruction, and performance optimization.

You’ll work cross-functionally with backend engineers, rendering experts, product managers, and designers to identify high-impact ML opportunities. As the first MLE in the team, you’ll shape strategy, define best practices, and build scalable ML systems that integrate deeply into Canva’s editor platform.

This role is ideal for someone who thrives in ambiguity, enjoys building from first principles, and wants to make foundational impact in a high-scale, product-led environment.

What you’ll do (responsibilities)

Design, build, and deploy machine learning models that improve the accuracy and quality of design imports at scale.

Work closely with engineers to integrate ML systems into high-performance backend and rendering pipelines.

Define data strategies — including data collection, labeling approaches, and evaluation frameworks — to continuously improve model performance.

Take a new perspective on existing import solutions and apply analytical thinking to solve complex, ambiguous problems.

Contribute to architectural decisions that impact the broader Editing Platform ecosystem.

Champion experimentation, monitoring, and model observability best practices.

Collaborate across teams to identify opportunities where ML can unlock step-change improvements in user experience.

What we're looking for:


You’re a strong technical craftsperson who combines deep ML expertise with product intuition. You’re comfortable operating independently and taking ownership of complex problem spaces, while still valuing collaboration and feedback.

We’re looking for someone who:

Has strong experience building and deploying machine learning models in production environments.

Has hands-on experience with Python and ML frameworks (e.g., PyTorch, TensorFlow) and experience shipping scalable systems.

Demonstrates conceptual and practical expertise in areas such as computer vision, document/layout understanding, structured data extraction, or related fields.

Is comfortable navigating ambiguity and shaping problem definitions in a fast-scaling environment.

Thinks beyond model performance — considering system design, latency, reliability, and user impact.

Communicates clearly and can translate complex ML concepts into actionable engineering decisions.

Additional Information


Don't tick all the boxes? Don't worry about that - nobody does!  

We’d still love to hear from you! At Canva, we know that great engineers come from a variety of backgrounds, and we value passion, curiosity, and a willingness to learn just as much as specific experience. If you're excited about this role but don’t tick every box, we encourage you to apply, you might a great fit in ways you didn’t expect!

What's in it for you?

Achieving our crazy big goals motivates us to work hard - and we do - but you'll experience lots of moments of magic, connectivity and fun woven throughout life at Canva, too. We also offer a stack of benefits to set you up for every success in and outside of work.

Here's a taste of what's on offer:

Equity packages - we want our success to be yours too
Inclusive parental leave policy that supports all parents & carers
An annual Vibe & Thrive allowance to support your wellbeing, social connection, office setup & more
Flexible leave options that empower you to be a force for good, take time to recharge and supports you personally

Check out  lifeatcanva.com for more info.

Other stuff to know

We make hiring decisions based on your experience, skills and passion, as well as how you can enhance Canva and our culture. When you apply, please tell us the pronouns you use and any reasonable adjustments you may need during the interview process."
90315793,Senior AI Research Computing Engineer,Monash University,https://www.seek.com.au/job/90315793?type=standard&ref=search-standalone&origin=jobCard#sol=b124aa068a81358ed5d63f22f09c2c3dd1c0aa36,7h ago,7.0,2026-02-12T22:00:00+00:00,"Clayton, Melbourne VIC (Hybrid)","Engineering - Software (Information & Communication Technology)
Other (Education & Training)",Full time,"$140,157 - $148,769 pa HEW Level 09 plus 17% super","Job No.: 686114

Location: Clayton campus

Employment Type: Full-time

Duration:  3 year fixed-term appointment

Remuneration: $xxx,xxx - $xxx,xxxx pa HEW Level 09 (plus 17% employer superannuation) although a competitive remuneration package can be applied for an experienced candidate

Amplify your impact at a world top 50 University
Join our inclusive, collaborative community
Be surrounded by extraordinary ideas - and the people who discover them

The Opportunity

Project MAVERIC is a Monash-led initiative pioneering the next generation of AI-driven research infrastructure. Its mission is to accelerate discovery in addressing some of humanity's most pressing challenges, from combating disease to advancing environmental science. By uniting high-performance computing, large-scale data systems, and cutting-edge AI infrastructure, MAVERIC is redefining how researchers develop, train, and scale artificial intelligence to solve complex real-world problems. 

We are seeking Senior AI Research Computing Engineers to play a pivotal technical leadership role in bringing this vision to life. In this position, you will act as the critical link between ambitious research goals and the powerful computing systems that enable them. You will architect, implement, and support the distributed AI platforms that form the foundation of MAVERIC’s mission, empowering researchers to push the limits of generative AI, computational science, and cross-disciplinary innovation. 

This role suits someone who excels at the intersection of software engineering, high-performance computing, and applied artificial intelligence. You'll work very closely with researchers to translate and accelerate their research using AI, turning complex scientific challenges into breakthrough computational solutions.

Key Responsibilities

Partner with researchers across diverse domains (drug discovery, healthcare, computer vision, and beyond) to translate scientific goals into scalable AI/ML solutions
Architect and optimise sophisticated AI models for high performance computing (HPC) environments, implementing distributed training strategies and performance tuning at scale
Lead development of automated MLOps pipelines using containerisation, orchestration platforms, and CI/CD practices.
Benchmark, profile, and optimise AI applications across software and hardware layers to maximise GPU cluster efficiency
Build research community capability through expert consultation, training programs, and technical documentation.
Evaluate and apply emerging AI/ML technologies to novel research problems.

What We're Looking For

Extensive experience applying AI/ML techniques (deep learning, natural language processing, computer vision, reinforcement learning) to complex scientific problems
Expert Python programming with major ML frameworks (TensorFlow, PyTorch or equivalent)
Proven experience designing and deploying AI workflows on HPC/GPU systems, including distributed training frameworks
Linux system administration and HPC environment troubleshooting
Ability to collaborate with researchers from diverse disciplines and work independently with minimal supervision

Highly Regarded Skills/Experience

Postgraduate degree in Computer Science, Data Science, Engineering, or related discipline with extensive relevant experience; OR equivalent combination of experience and education in AI/ML and research computing
MLOps experience: containerisation (Docker, Singularity), orchestration (Kubernetes, Slurm), CI/CD pipelines
Knowledge of GPU architecture, performance optimisation, and profiling tools

About Monash University

At Monash, work feels different. There’s a sense of belonging, from contributing to something ground breaking – a place where great things happen.

We value difference and diversity, and welcome and celebrate everyone's contributions, lived experience and expertise. That’s why we champion an inclusive and respectful workplace culture where everyone is supported to succeed.

Some 20,000 staff work for Monash around the world. We have 95,000 students, four Australian campuses, and campuses in Malaysia and Indonesia. We also have a major presence in India and China, and a significant centre and research foundation in Italy.

In our short history, we have skyrocketed through global university rankings and established ourselves consistently among the world's best tertiary institutions. We rank in the world’s top-50 universities in rankings including the QS World University Rankings 2026.

Learn more about Monash.

Today, we have the momentum to create the future we need for generations to come. Accelerate your change here. 

Monash supports flexible and hybrid working arrangements. We have a range of policies in place enabling staff to combine work and personal commitments. This includes supporting parents.

To Apply

For instructions on how to apply, please refer to 'How to apply for Monash Jobs'.

Diversity is one of our greatest strengths at Monash. We encourage applications from Aboriginal and Torres Strait Islander people, culturally and linguistically diverse people, people with disabilities, neurodivergent people, and people of all genders, sexualities, and age groups.

We are committed to fostering an inclusive and accessible recruitment process at Monash. If you need any reasonable adjustments, please contact us at hr-recruitment@monash.edu in an email titled 'Reasonable Adjustments Request' for a confidential discussion.

Your employment is contingent upon the satisfactory completion of all pre-employment and/or background checks required for the role, as determined by the University.

Enquiries: Joseph Pineda, Infrastructure Delivery Lead, joseph.pineda@monash.edu 

Position Description: Senior AI Research Computing Engineer

Applications Close: Tuesday 24 February 2026, 11:55pm AEST"
