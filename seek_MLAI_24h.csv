Job ID,Job Title,Company,Detail URL,Posted Label,Hours Old,Posted Datetime (Local),Location,Category,Work Type,Salary,Ad Text
89275187,Senior Software Engineer (AI),Eucalyptus,https://www.seek.com.au/job/89275187?type=standard&ref=search-standalone&origin=jobCard#sol=9f9cd361a1b7b66169fa0d0bce7354b771df387e,1h ago,1.0,2025-12-22T05:00:00+00:00,Sydney NSW,Developers/Programmers (Information & Communication Technology),Full time,,"Location of position: Sydney, Australia
Employment Type: Full TimeAbout Eucalyptus


We’re on a mission to make good health last a lifetime. More than 1 billion people live with obesity worldwide, driving preventable chronic conditions. We’re here to build better long-term care.

Euc is the company behind Juniper, one of the world’s largest weight-management programs combining GLP-1 medication with personalised nutrition, movement support, and clinician-led care from prescribers, nurses, health coaches, pharmacists, and dietitians. Our published clinical research shows that our combined clinical and behavioural approach helps patients lose significantly more weight during their treatment with Juniper by four times.

Our Growth Story:

130% YoY revenue growth and 90% reduction in cash burn, with $100M+ raised from investors including BOND, NewView, Blackbird and Airtree.
Scaled to over 100,000 monthly active patients across our weight-management program.
Grew the UK patient base from 4,000 to ~40,000 and received selective NICE endorsement to provide services to the NHS.
Tailored our offering to over 5,000 patients in Germany and Japan
About the role (What you'll be doing)


Eucalyptus is looking for a Senior Software Engineer I, Full Stack (AI focus) to join our high-performing engineering team. You’ll be part of a highly collaborative 40-person engineering group, building higher touch, higher quality healthcare technology that our patients around the world love using — now with AI as a core part of our platform.

Be a key engineering voice in designing and building scalable, production-grade AI-powered features across our multi-brand platform — from patient-facing conversational tools to intelligent decision-support systems.
Integrate with foundational LLM APIs (Gemini, OpenAI, etc.) and design scalable architectures for generative use cases, including RAG and multi-agent systems.
Work closely with cross-functional stakeholders in product, design, marketing, creative, analytics, and operations to deliver the best AI-enabled telehealth experiences for our patients.
Act as the AI subject matter expert — run demos, lead workshops, pair program, and document best practices to accelerate AI adoption across the eng org.
Provide architectural guidance and ensure AI systems are production-ready, safe, and scalable.
Lead the creation and ownership of shared LLM infrastructure (prompt management, evaluation tooling, safety/observability) in collaboration with Data Engineering and ML Ops.

What success looks like in this role:

Short-term (first 5 months): personally design, build, and ship at least one customer-facing LLM-powered feature end-to-end.
Long-term: enable all engineering teams to independently deliver LLM features by providing shared infrastructure, tooling, and best practices.
About you (Who you are)

Strong full-stack engineering track record (Typescript, Go/Node, GCP, distributed systems).
At least 1–2 years of recent, hands-on experience building LLM-powered features in production (e.g. conversational agents, personalised recommendation engines, retrieval-augmented systems, or agentic collaborative multi-agent systems).
Familiarity with LangChain, LangGraph, RAG patterns, and other common LLM integration frameworks.
Comfortable operating in an 80:20 individual contributor to tech leadership split, with scope to grow leadership responsibilities over time.
Exceptional ability to break down projects, estimate timelines, and execute complex initiatives with multiple workstreams.
Excellent written and verbal communication skills, with the ability to simplify complex AI concepts for different audiences.
Experience building reusable components and AI-enabled services across multiple applications and codebases.
You are curious and resourceful — comfortable navigating ambiguity, exploring new approaches, and solving problems without always having all the answers.
Bonus: experience in regulated environments, AI observability tooling, or guiding AI adoption in a team new to AI.
Why you should join Engineering at Euc

We’re on a quest to build a robust, scalable, configurable, multi-brand platform (that’s also enjoyable to work on!) on which we can solve the world’s biggest healthcare challenges, and you can be a pivotal player in that journey.
We have a high performance culture
We have a high bar for talent, so you’ll get to learn from some of the best engineers in the industry
We write as many low quality memes as we do high quality PRs
We optimise for velocity and deploy to production hundreds of times a month. Once you merge your code, it’s in prod in minutes
You’ll get to work with a modern tech stack that we’re always improving. If something isn’t working for us, we’ll iterate until we get it right and everyone on the team is encouraged to help refine it.
Frontend: React, React Native + Expo, TypeScript, Apollo, Tailwind
Backend: Node (TypeScript) and Go microservices, Federated GraphQL, gRPC, Protobufs, Pub/Sub and Postgres, hosted on GCP Kubernetes Engine (GKE)
You’ll work on interesting engineering challenges:
Euc has a large appetite for product development, so we have a roadmap of innovative, greenfield features to work on
We've been running microservices smoothly in production for a few years, but there is still a lot of complex business logic in our legacy mono-repo to understand, break down, improve and port across.
We strive for efficiency and invest heavily in internal tooling to improve developer experience
We’ll invest in your growth, development and career
When we introduced Go microservices we invested in upskilling the whole team in a new language
No matter which direction you want to take your career, we’ll provide opportunities for you
Every engineer has a yearly Learning and Development budget that they can use for courses, books, conferences, anything to help you learn.
Why join Eucalyptus?


Euc is also behind a growing family of digital healthcare clinics (Pilot, Kin, Software, Compound) across men’s health and well-being, fertility, skincare, and preventative health.

Here’s what makes joining Euc unique:

What’s next - Our goal for the next three years is to support 1 million patients globally to live better for longer. We’re launching into new conditions, demographics, and geographies as we build a truly preventive healthcare ecosystem.
Build something world-changing - We’re on the path to becoming the world’s largest international digital healthcare company. It will be challenging, fast-paced, and deeply rewarding.
Make real impact - You will deliver work that directly shapes patient outcomes and scales evidence-based care across markets.
Accelerate your growth - You will have high ownership, continuous feedback, and dedicated development support.
Join a motivated team - You will collaborate with talented peers to solve complex clinical and operational problems at scale.
What’s ahead in Australia?

Grow with us globally - Get mentorship from leaders across Australia, the UK, Germany, and Japan, collaborate with teams in the Philippines and South Africa, and explore new markets or travel internationally. Recognised on Hatch’s Hotlist as one of Australia’s top employers, we support early-career professionals to become future global leaders.
Shape your career - Access learning budgets, conferences, certifications, peer shadowing, and a global knowledge-sharing culture.
Be an owner - Equity for everyone means you share in our success.
Work where well-being matters - Experience catered wellness talks, exercise classes, whoops to track your wellbeing, free barista coffees, funded social clubs, and quarterly rooftop parties.
Innovate with purpose - Use state-of-the-art tools and contribute to bold, impactful solutions in healthcare.
Support at every stage - Benefit from parental and miscarriage leave, to health, professional development, and personal days, Whoop membership, and our Employee Assistance Program.

At Eucalyptus, we value individuals from all backgrounds, experiences, and perspectives, and we embrace the unique qualities each person brings. When you apply, please let us know of any reasonable adjustments you may need during the interview process."
89273071,Senior AI Engineer,Just Digital People,https://www.seek.com.au/job/89273071?type=standard&ref=search-standalone&origin=jobCard#sol=ffffe5ac31640bfc7a6e7873ae30c4153886b067,2h ago,2.0,2025-12-22T04:00:00+00:00,Melbourne VIC (Hybrid),Engineering - Software (Information & Communication Technology),Full time,"$140,000 - $170,000 + super","We’re working with a fast-growing Australian tech company that’s building real, production AI. They’re looking for a Senior AI Engineer to own how LLMs are integrated into customer-facing products. This is a hands-on role for someone who knows how to take AI from idea to production and keep it running properly.

You’ll sit right at the intersection of AI, software engineering, and ML Ops. The LLMs already exist. Your job is to integrate them intelligently, orchestrate workflows, scale them reliably, and make sure they actually deliver value to users.

What you’ll be doing
Building and shipping LLM-powered features used directly by customers
Using Google ADK and modern AI tooling to create agents, workflows, and automation
Owning ML Ops end to end including deployment, monitoring, evaluation, and lifecycle management
Working closely with engineers, product, and stakeholders to turn real business problems into AI solutions
Designing scalable, secure AI systems running in Azure (GCP or AWS experience is also fine)
Influencing architecture and setting best practice for how AI is delivered across the platform
What they’re looking for
Strong background in AI and Machine Learning with real software engineering depth
Proven experience integrating LLMs via APIs and platforms not training your own models
Hands-on ML Ops experience in production not theory
Experience building and supporting customer-facing AI products
Cloud experience with Azure (GCP or AWS also fine)
Someone autonomous, pragmatic, and comfortable talking to both engineers and non-technical stakeholders
This is a role for someone who wants ownership, impact, and the chance to shape how AI is actually used in a growing product, not sit on the sidelines.

If you would like to hear more about this role, please feel free to reach out!
nat@justdigitalpeople.com.au"
89273041,Senior Data Engineer,Elula,https://www.seek.com.au/job/89273041?type=standard&ref=search-standalone&origin=jobCard#sol=b76d944f3f073c51df3acd3614580f72b56e8dad,2h ago,2.0,2025-12-22T04:00:00+00:00,Sydney NSW (Hybrid),Engineering - Software (Information & Communication Technology),Full time,,"Senior Data Engineer

At Elula, we partner with some of Australia's top financial institutions to tackle a wide range of business challenges through cutting-edge AI-as-a-service (AIaaS). Our vision? To make the complex simple and easy, delivering amazing customer experiences and personalisation that matters.

Our products leverage machine learning, productionised models, data pipelines, explainable AI, and rich visualisations to drive customer engagement, retention and insights. We're constantly pushing the envelope, uncovering the ever-evolving needs of customers and staying ahead of the curve.

Join a team of some of the brightest minds in data science and engineering; experts with years of experience and a passion for delivering smarter decision-making. It's a fast-paced, high-performing and collaborative environment where creativity and learning take centre stage, and the work is as fun as it is rewarding.

Find out more about us at https://elula.ai/team/.




The role

As a Senior Data Engineer at Elula, you will play a key role in building and maintaining the data that powers our AI-as-a-Service platform. You will be expected to operate autonomously, support and guide others. You will contribute expert knowledge to design, implement, and optimise data pipelines, models and tools, ensuring that our data is accurate, reliable, and scalable. You will collaborate closely with data scientists, software engineers, and customer-facing teams working end-to-end across the data lifecycle - from ingestion and modelling through to validation and delivery.

We're looking for someone who jumps at the opportunity to work autonomously on open-ended problems and thrives in an environment where collaboration, ambition, and excellence is paramount. Our ideal candidate is a stellar communicator, able to connect with all types of people, who puts their hand up, takes ownership, and is never afraid to ask for help when needed.

To be successful in this role, you will be expected to demonstrate the following skills and experience.
 

Technical and analytical competencies

Analyse, understand and interrogate complex data, assessing quality and fitment to design, build and maintain robust, scalable data pipelines.

Diagnose and resolve complex data quality and pipeline reliability issues, applying structured problem-solving and pragmatic remediation approaches.

Develop and optimise complex SQL logic across large datasets, with a strong focus on correctness, performance and maintainability.

Leverage Python to automate workflows, build and implement reusable tooling or libraries.

Apply data modelling principles in practice, designing data models that support analytical, operational and downstream use cases.

 

Ownership and decision-making

Own the delivery and ongoing reliability of data pipelines and integrations, working independently under general direction.

Exercise sound technical judgement when addressing complex issues, making informed trade-offs and escalating risks where appropriate.

Plan, prioritise and manage work effectively to meet agreed delivery timelines and quality expectations.

 

Technical leadership

Collaborate and influence across disciplines, working closely with engineers, analysts and data scientists to shape and deliver effective data solutions.

Support and enable junior engineers, providing guidance on technical approaches, tooling, and engineering best practices.

Communicate complex technical concepts clearly and confidently to both technical and non-technical stakeholders.

Continuously improve systems and practices, bringing curiosity, adaptability and a mindset of learning and refinement.

Adopt and share new tools, frameworks and techniques, contributing to the uplift of team capability and standards.




Preferred Skills and Experience

While the following are not required, they are highly valued.

Bachelor’s degree in Computer Science, or similar

Experience working in the financial services industry (e.g. banking, insurance or superannuation),

Familiarity with agile ways of working (sprints, huddles, retros, etc.)


Benefits

Elula’s people are at the core of all we do. Our benefits are just one way we show that.

Enjoy flexible working hours, and work from home two days per week, to better balance your personal and professional life.

Experience the freedom of working anywhere in Australia up to five days annually.

Give back to what matters to you with extra paid annual leave for volunteering.

Put your health first with an allowance for fitness and wellbeing.

Drive your development with financial support for approved training courses.

Level up with matched funding for career coaching.




Interested?

If you're excited about shaping the future of AI, this is where you belong! Submit your CV and cover letter telling us why you're the right fit for Elula and what makes you special!

We're committed to fostering a culture of inclusivity and equality. All are welcome to apply for our roles because we truly believe that diversity is a game changer."
89269861,Senior Data Scientist,Queensland Building and Construction Commission (QBCC),https://www.seek.com.au/job/89269861?type=standard&ref=search-standalone&origin=jobCard#sol=467c5543916f7d74f384634b361d3096d560ac3e,4h ago,4.0,2025-12-22T02:00:00+00:00,Brisbane QLD,"Business/Systems Analysts (Information & Communication Technology)
Government - State (Government & Defence)",Full time,+ Super & Leave Loading,"Key Outcomes and Accountabilities  

The aim of this role is to:

Implement cloud-based data science solutions that support large-scale data processing and Machine Learning (ML) workflows.
Enable integration of Artificial Intelligence (AI) and ML models into production systems, ensuring scalability, governance, and performance monitoring.
Collaborate with data analysts, data governance, and business units to deliver data products that support predictive analytics, natural language processing, and other AI-driven use cases.
Establish and maintain robust data governance, metadata management, and model monitoring frameworks to ensure data integrity, compliance, and responsible AI practices.
Provide technical advice and thought leadership on emerging technologies in data science and AI, identifying opportunities for innovation and efficiency improvements.
Support the continuous improvement of data engineering standards, including automation, CI/CD pipelines, and reusable components for AI/ML deployment.
Support and maintain data pipelines and ETL processes that ensure reliable, timely and secure access to data for reporting, analytics, and ML workflows.
Candidate Attributes
Demonstrated experience in building scalable data solutions using Python and SQL.
Proficiency in cloud data platforms (e.g., Snowflake, or similar) and data warehousing concepts.
Strong understanding of machine learning lifecycle management (data preparation, feature engineering, model deployment, monitoring).
Strong understanding of Generative (Gen) AI, Agentic Systems, and AI Agents and be able to implement and develop scalable systems from proof of concept to production.
Ability to translate complex business requirements into robust technical solutions that support AI and analytics outcomes.
Knowledge of MLOps and CI/CD practices for deploying and maintaining AI/ML models at scale.

Why Join QBCC?

Generous 12.75% superannuation contribution with the option to salary sacrifice
Access to leave entitlements (with 17.5% leave loading) and accrual of flex time
Opportunities for career development, training and mentoring
A friendly, collaborative and supportive workplace culture
Fitness Passport

How to apply
To apply for this exciting opportunity, please submit your resume and a written statement (maximum 2 pages) on how you have demonstrated the capabilities outlined in the Candidate Attributes section of the position description."
89269002,IDAM Engineer,Launch Recruitment Pty Ltd,https://www.seek.com.au/job/89269002?type=standard&ref=search-standalone&origin=jobCard#sol=5c2ac8e72895bfc2035805ca00177916ef7b2be1,5h ago,5.0,2025-12-22T01:00:00+00:00,Melbourne VIC (Hybrid),Security (Information & Communication Technology),Contract/Temp,up to $1200 + GST,"Identity Engineer 
Energy Sector | Contract 

Duration: January 2026 - June 2026 with the potential to extend 
Day Rate: $1,000 - $1200 + GST 
Location: Melbourne 
Hybrid role: 2/3 days in the office 


We are seeking an experienced Identity and Access Management (IAM) professional to join a large, complex organisation operating within the energy sector. This role will support critical infrastructure and enterprise platforms, requiring strong security, reliability, and operational maturity.
This opportunity is on an ongoing contract basis and will suit candidates who enjoy working in highly regulated, high-availability environments.
 
Key Responsibilities

Administer, support, and enhance cloud-based identity platforms, with a strong focus on Okta.
Manage SSO, MFA, Risk Engine policies, and Identity Governance workflows across enterprise and operational environments.
Support Infrastructure as Code (IaC) initiatives and identity platform migrations.
Design, configure, and maintain secure identity integrations using OIDC, OAuth2, SAML, ADFS, and Active Directory.
Implement and manage Conditional Access, SCIM provisioning, and identity lifecycle management.
Provide BAU and operational support, troubleshooting identity-related issues in a 24/7 operational context where required.
Collaborate closely with cybersecurity, cloud, DevOps, and operational technology teams.
Maintain and manage certificate lifecycle and encryption processes, including OpenSSL.
Technical Skills & Experience
Essential

Strong hands-on experience with Okta (Cloud Admin, SSO, MFA, Risk Engine).
Solid experience across Azure / Microsoft 365, including:
Entra ID (Azure AD)
Conditional Access
MFA
SCIM
Intune MAM
APIM
Strong working knowledge of identity protocols: OIDC, OAuth2, SAML, ADFS.
Experience with Active Directory in hybrid cloud environments.
Certificate management experience, including OpenSSL.
Desirable

AZ-500 or similar Microsoft security certification.
Experience with AWS identity services (Cognito, Organisations).
Background in AWS Security, DevOps, or platform engineering roles.
Prior experience within energy, utilities, infrastructure, or critical services environments.
What We're Looking For

Strong security mindset with an understanding of risk in critical infrastructure environments.
Ability to work independently and manage competing priorities.
Strong analytical and problem-solving skills.
Clear communicator, comfortable engaging with technical teams and senior stakeholders.
If you are interested in this exciting project and you have strong identity experience, please do click ""Apply today"" or reach out to Sophie Garrison, Practice Lead - Cyber Security & GRC"
89268752,Principal Engineer - Engineering & Data,FutureYou,https://www.seek.com.au/job/89268752?type=standard&ref=search-standalone&origin=jobCard#sol=241ab4b433031abb35163bf17ce8a30cc41b0d98,5h ago,5.0,2025-12-22T01:00:00+00:00,Sydney NSW,Engineering - Software (Information & Communication Technology),Full time,"AUD 220000 per annum, Base Plus Super and Bonus","Client


Our client has ambitious growth plans to double the business over the next 2–3 years, we are investing heavily in technology, data, and digital capability. The role is reporting directly to the Chief Information Officer (CIO), this is a senior, hands-on leadership role where you will guide both engineering and data functions, while remaining deeply involved in delivery.


About the role


You will lead direct reports across engineering and data, spending 60–70% of your time hands-on with code, architecture, and solution design. This role is ideal for a technical leader who enjoys working close to the detail while shaping strategy and driving change in a traditional business modernising at scale.


Key Responsibilities


Lead, mentor, and manage a team of engineers and data specialists
Remain hands-on with development, architecture, and solution delivery
Break down work, assign tasks, and manage team workload and priorities
Act as a key technical contact for external vendors delivering Microsoft Dynamics solutions
Develop and enhance customer portals for residential and commercial clients
Design and implement system integrations and APIs
Contribute to architectural decisions within the Microsoft ecosystem
Support AI initiatives and identify automation opportunities to drive efficiency

Required Skills & Experience


Strong full-stack development background
Deep experience with Microsoft technologies, including:

Microsoft Dynamics (Business Central & Customer Engagement)
Azure Cloud
.NET
React
Power BI
Proven experience building APIs and system integrations
Mobile and web application development experience
Experience leading and developing technical teams
Understanding of AI applications and automation opportunities
Experience working within medium to large organisations
Adaptable and comfortable working in a fast-changing environment
Strong collaborator with cross-functional stakeholders
Passionate about AI, automation, and continuous improvement
Exposure to multiple industries or complex business environments
Strong stakeholder and vendor management skills
Practical, solutions-focused mindset

Offer

Opportunity to shape technology strategy during a major digital transformation
Hands-on technical leadership in a business investing heavily in modern platforms
Competitive salary package
The chance to make a tangible impact in a business scaling rapidly
3 days on site 

For a confidential discussion please apply or reach out to Corin on 0457676048"
89268123,MuleSoft Developer,Slade Group,https://www.seek.com.au/job/89268123?type=standard&ref=search-standalone&origin=jobCard#sol=a59655116d7354a9c0c4ae23d33550501abf3080,5h ago,5.0,2025-12-22T01:00:00+00:00,Melbourne VIC (Hybrid),Developers/Programmers (Information & Communication Technology),Full time,,"We’re looking for an experienced MuleSoft Developer to join our growing integration team and help design, build, and support scalable enterprise integrations across a modern technology ecosystem.

You’ll play a key role in developing new APIs and integration interfaces, enhancing existing codebases, and ensuring smooth communication between multiple enterprise systems. 

What You’ll Do
Design, develop, and maintain MuleSoft integrations and APIs using Mule 4 and Anypoint Platform
Translate technical requirements into scalable and reusable integration solutions
Deliver high-quality, well-documented code
Support existing integrations through analysis, troubleshooting, and defect resolution
Contribute to proofs of concept and prototypes for new connectors and patterns
Collaborate with architects and leads to ensure alignment with integration standards
Work within GitHub, following defined branching and CI/CD practices
What You’ll Bring
5-7+ years’ experience in MuleSoft integration development
Strong knowledge of Mule 4, Anypoint Studio, API Manager, Runtime Manager, and Exchange
Solid understanding of API-led architecture and common integration patterns
Hands-on experience with JMS technologies (e.g. ActiveMQ)
Proficiency with DataWeave, batch processing, exception handling, and OAuth 2.0 security
Familiarity with DevOps practices (Azure DevOps, GitHub, CI/CD pipelines)
Excellent problem-solving and debugging skills across multiple environments
Clear communication skills and the ability to collaborate with technical and non-technical stakeholders
Bonus points if you have:

Experience with SAP connectors
MuleSoft Certification (Developer or Architect)
Degree in Computer Science, Engineering, or Information Systems
If this position is of interest, click APPLY today or contact Sam Makdesi on smakdesi@synchropartners.com.au"
89267844,Senior Engineer - MQ-28 Data Architect,Boeing Defence Australia,https://www.seek.com.au/job/89267844?type=standard&ref=search-standalone&origin=jobCard#sol=278f3822c0edfa73a6dcbb82e7b4a8e5f09919e5,5h ago,5.0,2025-12-22T01:00:00+00:00,Brisbane QLD (Hybrid),Engineering - Software (Information & Communication Technology),Full time,,"The Opportunity

The Boeing MQ-28 - Ghost Bat is a globally significant program delivering disruptive advantage to support Defence operational capabilities. Developed in partnership with the Royal Australian Air Force, it is the first military combat aircraft to be designed, manufactured and assembled in Australia in 50 years. 

MQ-28 is expanding globally with international customers as well as its international design and partner network. Those ambitions require a Global Digital Ecosystem that facilitates a global military digital design network as well as closer ongoing digital collaboration with military operators. 

Role overview

You will define and lead the evolution of a capability-based MQ-28 Global Digital Ecosystem ensuring it is secure, adhering to export-compliant digital architectures and solution patterns that enable global design collaboration. 

Key responsibilities

Design and implement a Global Digital Ecosystem solution architecture for complex, multi‑stakeholder Defence programs
Work with export control and the MQ-28 Data Architect ensuring data sovereignty and contractual IP/data rights as they relate to cloud and collaboration platforms
Lead platform selection and migration for digital toolchains
Produce architectural artefacts such as capability maps, sequence/flow diagrams, data models, interface specifications
Stakeholder engagement with senior leaders and international partners 

Essential skills & experience

Deep understanding of cloud and hybrid integration patterns, including secure data flows, identity federation, multi‑tenant isolation and cross‑jurisdictional compliance
Proven experience in business or solution architecture roles for complex, multi‑stakeholder engineering or defence programs
Expertise in capability‑based planning and translating capability maps into implementable solution roadmaps
Strong background in systems thinking and ability to map value streams across engineering, manufacturing, supply chain and sustainment
Practical experience working with digital engineering toolchains
Excellent stakeholder engagement, communication and leadership skills with ability to influence senior leaders and international partners.
Australian Citizenship (required for Defence security clearance). 

Desirable skills & experience

Hands-on experience with tools such as 3DExperience, Teamcenter, CATIA, NX, DOORS, Ansys, Matlab, GitLab, Python and secure cloud platforms (AWS/Azure/GCP)
Familiarity with model-based systems engineering (MBSE) and digital thread concepts
Practical experience automating tasks via scripting and CI/CD for engineering toolchains
Prior exposure to international defence programs or globally distributed supplier networks 

Other benefits

Work on cutting edge projects with opportunities to work across platforms
Attractive remuneration and annual bonus
Formal reward and recognition program
Access discounts for health insurance, travel and accommodation
Paid parental leave and Defence leave
Salary packaging options available
Health and wellbeing benefits include annual flu vaccinations and Employee Assistance Program
Social and community groups 

BDA works with strong links with our global Boeing community, and we strongly encourage collaboration with our international counterparts.

 We are committed to building a diverse and inclusive workplace. Female applicants, people of Aboriginal or Torres Strait Island descent and veterans are encouraged to apply.

 Please note, this role will be shortlisted in 2026. Your patience is appreciated."
89267798,AI Analyst,DataMesh,https://www.seek.com.au/job/89267798?type=standard&ref=search-standalone&origin=jobCard#sol=b1affb217b3db9f32b5912a4239ce77fb9de9d8f,5h ago,5.0,2025-12-22T01:00:00+00:00,Sydney NSW (Hybrid),Business/Systems Analysts (Information & Communication Technology),Full time,,"Our Story!
DataMesh Group (DMG) is revolutionising the payment systems available to merchants and retailers, delivering integrated payment capabilities and valuable customer insights through bespoke payment and data processing solutions.
The company is in an exciting growth phase, and we are looking for individuals with the appetite and energy to make impactful changes and accelerate their career development with this unique opportunity!

Smarter connections, infinite possibilities! ��
  
About the role
As an AI Analyst, you will work closely with product, engineering, data, and business teams to analyse data, develop AI-driven insights, and support the deployment of machine learning and automation solutions. This role is ideal for someone who enjoys bridging the gap between technical capability and commercial outcomes in a fast-paced tech environment.
  
What you’ll be doing

Analyse large, complex datasets to identify patterns, trends, and insights that support AI and machine learning initiatives.
Support the development, testing, and monitoring of AI and ML models used across products and internal systems.
Translate business problems into analytical and AI-driven solutions.
Partner with product and engineering teams to integrate AI models into software applications.
Build dashboards, reports, and visualisations to communicate insights to stakeholders.
Monitor model performance, data quality, bias, and drift, recommending improvements as needed.
Ensure AI solutions align with regulatory, ethical, and data governance standards, particularly in a fintech context.
  
  
  
What we’re looking for

3–6 years’ experience in data analytics, AI, or machine learning roles, ideally within software, fintech, or technology-led environments.
Bachelor’s degree in Data Science, Computer Science, Mathematics, Statistics, Engineering, or a related field. Postgraduate qualifications are advantageous.
Strong analytical and problem-solving skills with the ability to translate data into actionable insights.
Experience working with machine learning models, statistical analysis, and data pipelines.
Proficiency in tools such as Python, SQL, and data visualisation platforms (e.g. Power BI, Tableau, Looker).
Familiarity with cloud platforms and AI frameworks (e.g. AWS, GCP, Azure, TensorFlow, PyTorch) is desirable.
Strong communication skills and confidence working with both technical and non-technical stakeholders.
  

Why You’ll Love Working with Us

Innovation at Its Core:Be part of a company that’s shaping the future of tech with cutting-edge solutions
Collaborative Culture:Work with smart, driven, and supportive teammates who value your input
Career Growth:Enjoy a clear path for growth and development in an expanding organisation
Impactful Work:See the results of your efforts as you help bring transformative projects to life
Social Perks: Enjoy company events, including lunches, celebrations and after work drinks!
 
If you’re ready to make an impact in the payments tech space and thrive in an agile, high-growth environment, we’d love to chat! ��"
89267405,Control Systems Engineer (Full-time),AIM Defence,https://www.seek.com.au/job/89267405?type=standard&ref=search-standalone&origin=jobCard#sol=e3da17888b9d9519bfc296cdb03bad4616c3cf97,6h ago,6.0,2025-12-22T00:00:00+00:00,"Port Melbourne, Melbourne VIC",Electrical/Electronic Engineering (Engineering),Full time,,"The Role 

AIM is a deep-tech startup building advanced high power laser systems to protect people from weaponised drones. We are seeking a highly motivated and skilled Control Systems Engineer. At AIM, you will be an integral part in the Engineering and R&D team to develop leading edge products and systems for use in tomorrow’s defence technology. We are looking for candidates who are flexible and available to work overtime, based on business needs at our Melbourne facility. 

 What You will do 

Develop software and control systems for precision tracking and mechanical systems 

Work heavily in C++ and CUDA 

Build control systems that vary from PID loops to advanced model predictive and intelligent control in both SISO and MIMO environments  

Write, modify and debug software for embedded and local compute-based applications 

Provide input to architecture discussions 

Use source debuggers and visual development environments, including advanced tools for debugging multi-threaded applications. 

Document research and metrics-based outcomes for improvement and exploration 

Ensure work meets scheduled requirements and brings a software deliverable to completion. 

Provide technical support and mentoring. 

Assist in preparing work estimates and project schedules for work to be performed. 

Work as part of a multi-disciplinary fast paced development team 

Provide leadership to other team members 

Work closely with managers, engineers, and technicians to produce a wide variety of components 

 What You will bring 

Experience with C++, preferably more than 4 years 

A very strong understanding of control theory and intelligent control systems 

Experience with CUDA a bonus 

Tertiary degree in an engineering, science, or computer science discipline preferred 

Experience working with both local compute and embedded platforms 

Experience with python a bonus but not a hard requirement 

Familiarity with source code control and document configuration management systems 

Have excellent time management skills as you will need to be able to prioritise workloads and shift focus as necessary. 

Experience doing the detailed analysis necessary to make data driven decisions 

Ability to work cross-functionally to develop new solutions 

Able to work well under pressure while managing competing demands and tight deadlines 

Work efficiently and productively in independent and team settings 

Exemplary verbal and written communication skills 

Strong organisational skills with meticulous attention to detail 

Ability to acquire a Negative Vetting Level 1 (NV1) Security Clearance 

As a Defence security clearance is required for this role, applicants must be Australian citizens and eligible to obtain and maintain a Negative Vetting Level 1 (NV1) clearance. To learn more about clearances please visit – http://www.defence.gov.au/AGSVA 


How You Will Benefit 

Competitive remuneration 

Exciting projects and industry leading innovations 

Professional learning and development opportunities 

Opportunity to innovate and work in a fast-paced team 

Challenges at the edge of what’s possible 

 We are committed to ensuring diversity; inclusion and equality are embedded throughout our organisation for the benefit of our customers and our team. We strive for a positive and engaging workplace where mental health and wellbeing are supported. We welcome applicants from all diverse backgrounds, including Aboriginal and Torres Strait Islander people. If you are looking for a unique and exciting opportunity, we look forward to your application."
89267334,Computer Vision Engineer (Full-time),AIM Defence,https://www.seek.com.au/job/89267334?type=standard&ref=search-standalone&origin=jobCard#sol=c0363d81cd36758185eb773d8bd083dc86ab99e5,6h ago,6.0,2025-12-22T00:00:00+00:00,"Port Melbourne, Melbourne VIC",Engineering - Software (Information & Communication Technology),Full time,,"The Role 

AIM is a deep-tech startup building advanced high power laser systems to protect people from weaponised drones. We are seeking a highly motivated and skilled Computer Vision Engineer. At AIM, you will be an integral part in the Engineering and R&D team to develop leading edge products and systems for use in tomorrow’s defence technology. We are looking for candidates who are flexible and available to outside of ordinary hours based on business needs at our Melbourne facility. 

 
What You Will Do

Develop software for precision detection and tracking systems 

Work heavily in CUDA on DSP, Neural Network, and classic machine vision applications 

Write, modify and debug software for embedded and GPU based applications 

Provide input to architecture discussions 

Use source debuggers and visual development environments, including advanced tools for debugging multi-threaded applications. 

Document research and metrics-based outcomes for improvement and exploration 

Ensure work meets scheduled requirements and brings a software deliverable to completion. 

Provide technical support and mentoring. 

Assist in preparing work estimates and project schedules for work to be performed. 

Work as part of a multi-disciplinary fast paced development team 

Provide leadership to other team members 

Work closely with managers, engineers, and technicians to produce a wide variety of components 


 What You Will Bring

Experience with C++ and CUDA preferably more than 4 years 

Tertiary degree in an engineering, science, or computer science discipline preferred 

Experience working with both GPU and embedded platforms 

Experience with python a bonus but not a hard requirement 

Familiarity with source code control and document configuration management systems 

Have excellent time management skills as you will need to be able to prioritise workloads and shift focus as necessary. 

Experience doing the detailed analysis necessary to make data driven decisions 

Ability to work cross-functionally to develop new solutions 

Able to work well under pressure while managing competing demands and tight deadlines 

Work efficiently and productively in independent and team settings 

Exemplary verbal and written communication skills 

Strong organisational skills with meticulous attention to detail 

Ability to acquire a Negative Vetting Level 1 (NV1) Security Clearance 

As a Defence security clearance is required for this role, applicants must be Australian citizens and eligible to obtain and maintain a Negative Vetting Level 1 (NV1) Security Clearance. To learn more about clearances please visit – http://www.defence.gov.au/AGSVA 


How You Will Benefit

Competitive remuneration 

Exciting projects and industry leading innovations 

Professional learning and development opportunities 

Opportunity to innovate and work in a fast-paced team 

Challenges at the edge of what’s possible 




We are committed to ensuring diversity; inclusion and equality are embedded throughout our organisation for the benefit of our customers and our team. We strive for a positive and engaging workplace where mental health and wellbeing are supported. We welcome applicants from all diverse backgrounds, including Aboriginal and Torres Strait Islander people. If you are looking for a unique and exciting opportunity, we look forward to your application."
89266720,Principal Engineer - MQ-28 Global Digital Ecosystem,Boeing Defence Australia,https://www.seek.com.au/job/89266720?type=standard&ref=search-standalone&origin=jobCard#sol=132766ece54aa8af2f08affa5a26218fe6d6732d,6h ago,6.0,2025-12-22T00:00:00+00:00,Brisbane QLD (Hybrid),Engineering - Software (Information & Communication Technology),Full time,,"The Opportunity

The Boeing MQ-28 - Ghost Bat is a globally significant program delivering disruptive advantage to support Defence operational capabilities. Developed in partnership with the Royal Australian Air Force, it is the first military combat aircraft to be designed, manufactured and assembled in Australia in 50 years. 

As MQ-28 expands internationally, the program requires robust, secure and export-compliant data architecture to manage and store data across multiple customer nations. 

Role overview

You will partner closely with the MQ-28 Global Digital Ecosystem Principal Engineer to define, implement and govern the MQ-28 enterprise data architecture and reference data platforms.  Your role will deliver on the digital architecture and solution patterns that enable global design collaboration for engineering design, flight test, maintenance, logistics and operational analytics.

Key responsibilities

Define and maintain the MQ-28 enterprise data architecture and data product roadmap in alignment with program strategic roadmaps and product architecture.
Design reference data platform architectures (cloud, hybrid, and on‑prem) to ingest, store, process and serve high‑volume flight test, telemetry, sensor and maintenance data at scale.
Specify data models, canonical schemas, ontologies and metadata standards to enable cross‑domain interoperability (engineering, operations, logistics, analytics).
Establish data governance, stewardship, cataloguing and lifecycle policies that incorporate export control, data rights, IP, and cross‑jurisdictional access constraints.
Define secure data integration and exchange patterns.
Develop architectures for efficient analytics and ML/AI workflows (data lakes, feature stores, data warehouses, MLOps pipelines) supporting test analysis, performance trending and predictive maintenance.
Create reference implementation patterns and reusable data platform blueprints for supplier/partner onboarding and rapid capability delivery.
Collaborate with security, export control, legal and compliance teams to ensure architecture meet export constraints and national security requirements.
Define interoperability contracts, APIs, data contracts and SLAs for internal systems and external partners/nations.
Lead data migrations, ingestion design and coexistence strategies for existing PLM/ALM/SE systems and new data platforms.
Produce architecture artefacts including data flow diagrams, logical & physical data models, data lifecycle diagrams, capacity & cost models and interface specifications.
Provide technical leadership and mentoring to data engineers, platform teams and stakeholders.
Communicate architecture rationale, risks, cost/benefit tradeoffs and timelines to program leadership and international partners.

Essential skills & experience

Proven experience as a Data Architect or Senior Data Engineering/Architecture role on complex, multi‑stakeholder defence, aerospace or mission‑critical programs
Expertise designing large‑scale data platforms: data lakes, data warehouses, streaming platforms, feature stores and analytical pipelines
Strong experience with cloud data architectures (AWS/Azure/GCP) and hybrid/on‑premises integration in regulated environments
Deep understanding of data modelling (relational, time-series, event-sourced), metadata, master data management and ontologies
Practical experience with ingestion and integration patterns (e.g. Kafka/streaming, ETL/ELT, CDC, APIs, message buses and batch processing)
Experience implementing data security controls and familiarity with cyber control frameworks (e.g. Essential 8, ISM, NIST800-43)
Familiarity with export control frameworks (ITAR/EAR or equivalents), data sovereignty requirements and contractual data/IP rights
Australian Citizenship (required for Defence security clearance). 

Desirable skills & experience

Hands-on with data platform technologies and tools such as AWS (S3, Glue, Kinesis, Redshift, SageMaker), Azure (Data Lake, Event Hubs, Synapse, ML), GCP (BigQuery, Dataflow), Kafka, Snowflake, Databricks, Postgres/TimescaleDB.
Familiarity with PLM/ALM/SE ecosystems and integrating engineering toolchains into data platforms.
Experience with observability, data lineage and catalog tools (OpenLineage, Amundsen, DataHub, Collibra).
Knowledge of ML/AI operationalisation, feature stores and MLOps practices.
Scripting and automation skills (Python, CI/CD tooling) to support prototype and reference implementations.
Prior exposure to global defence programs or multi‑national supplier networks. 

Other benefits

Work on cutting edge projects with opportunities to work across platforms
Attractive remuneration and annual bonus
Formal reward and recognition program
Access discounts for health insurance, travel and accommodation
Paid parental leave and Defence leave
Salary packaging options available
Health and wellbeing benefits include annual flu vaccinations and Employee Assistance Program
Social and community groups 

BDA works with strong links with our global Boeing community, and we strongly encourage collaboration with our international counterparts.

We are committed to building a diverse and inclusive workplace. Female applicants, people of Aboriginal or Torres Strait Island descent and veterans are encouraged to apply.

Please note, this role will be shortlisted in 2026. Your patience is appreciated."
89266547,EL2 Senior Cloud Engineer / Architect,"Talent – Specialists in tech, transformation & beyond",https://www.seek.com.au/job/89266547?type=standard&ref=search-standalone&origin=jobCard#sol=6b206d6b05f570f59ec0681502a98e3bfc39b0e0,7h ago,7.0,2025-12-21T23:00:00+00:00,Melbourne VIC (Hybrid),Architects (Information & Communication Technology),Contract/Temp,,"The opportunity

Our client is a community focused Federal Government Agency. They are currently seeking an EL2 Senior Cloud Engineer / Architect to determine the appropriate technologies to be used in the service development and delivery environment.


This is a 12 month initial contract with the possibility of 2x 12 month extensions, offering open market hourly rates. This is a hybrid role based out of the Melbourne CBD.

Your responsibilities will include:

Design and deploy greenfield and brownfield cloud platforms in either Azure or AWS, including foundational structures like Azure Landing Zones/Management Groups or AWS Landing Zone/Organizations/Control Tower, to support organisational scalability and hierarchy.
Implement Infrastructure as Code (IaC) using tools such as Terraform, ARM/Bicep (Azure), or CloudFormation (AWS) for reusable, automated, and secure deployments.
Configure and manage core services, such as Azure Key Vault/Blob Storage/Virtual Machines or AWS Secrets Manager/S3/EC2, ensuring secure-by-design principles like least privilege, encryption at rest/transit, and threat modelling.
Establish robust networking components, including Azure VNets/Subnets/NSGs/Firewall or AWS VPCs/Subnets/Security Groups/Transit Gateway, with focus on secure connectivity (e.g., VPN/ExpressRoute in Azure or Direct Connect in AWS).
Develop and enforce governance frameworks, including policies and guardrails via Azure Policy/RBAC or AWS Control Tower/IAM, to align with Australian government standards (e.g., ISM, PSPF), incorporating security assessments, cost optimisation, and compliance monitoring.
Integrate secure-by-design practices throughout the lifecycle, such as zero-trust models, automated vulnerability scanning, and identity federation.
Provide technical guidance, documentation, and training to teams on best practices for both Azure and AWS environments.
Document, present and discuss the end-to-end implementation options, recommendations and implications, to facilitate and support the decision-making process.
Ensure work aligns with business processes and overall delivery outcomes.
Drive innovation, continuous improvement and manage and lead change.
Proactively share knowledge and expertise as the subject matter expert.
Oversee and prepare a range of documentation and reports.
Collaborate with a broad range of internal and external stakeholders to achieve outcomes and key deliverables.
Resolve very complex, sensitive and/or escalated technical issues.
Develop and present outcomes confidently to a range of stakeholders across multiple forums.

*Please note that Australian Citizenship is requirement to be eligible to work for this Federal Government Agency*

About you

5+ years of hands-on experience as a Cloud Engineer, with expertise in building greenfield and brownfield setups in either Azure OR AWS public clouds, including IaC implementations and secure-by-design principles.
Proven track record with foundational elements in Azure (Landing Zones, Management Groups, Resource Groups, Key Vault, Blob Storage, Virtual Machines) OR AWS equivalents (Landing Zone, Organizations, VPCs, Secrets Manager, S3, EC2).
Strong knowledge of networking in either or both platforms: Azure (VNets, peering, NSGs, routing) and/or AWS (VPCs, subnets, security groups, NAT gateways), including hybrid connectivity.
Experience in governance and security: Implementing policies, guardrails, RBAC/IAM, and tools like Azure Security Center or AWS Security Hub.
Experience with DevOps practices, CI/CD pipelines (e.g., Azure DevOps, AWS CodePipeline), and scripting (PowerShell, Python, Bash).
Understanding of Australian government cloud requirements, including data sovereignty, security classifications, and regulatory compliance.
Proficiency in relevant technologies, frameworks, and tools, as well as the ability to translate complex technical requirements into scalable and sustainable solutions is imperative.
Current or previous held NV1 AGSVA clearance.


Applications close Friday the 16th of January.

APPLY

Submit your resume, or for further information please contact Liam.Lasslett@talentinternational.com or Jarrodd.Edwards@talentinternational.com"
89266485,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266485?type=standard&ref=search-standalone&origin=jobCard#sol=7465729da0295a26c1643299c34adcb8d2904395,7h ago,7.0,2025-12-21T23:00:00+00:00,Canberra ACT,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266481,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266481?type=standard&ref=search-standalone&origin=jobCard#sol=ca88f3756be8d523ed1e75121feab6aa06487075,7h ago,7.0,2025-12-21T23:00:00+00:00,Sydney NSW,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266471,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266471?type=standard&ref=search-standalone&origin=jobCard#sol=8250c1707e09a9c7d73e6154affdfe856547651e,7h ago,7.0,2025-12-21T23:00:00+00:00,Darwin NT,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266464,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266464?type=standard&ref=search-standalone&origin=jobCard#sol=2b287e31ba4513fc9e29b8aec5b453673852072a,7h ago,7.0,2025-12-21T23:00:00+00:00,Brisbane QLD,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266461,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266461?type=standard&ref=search-standalone&origin=jobCard#sol=0a03ce70018e20359ee69cd762323d5d2a59a31c,7h ago,7.0,2025-12-21T23:00:00+00:00,Adelaide SA,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266456,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266456?type=standard&ref=search-standalone&origin=jobCard#sol=f32addae0498d0d9a4d343b6fa90f3e2746fad35,7h ago,7.0,2025-12-21T23:00:00+00:00,Hobart TAS,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266455,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266455?type=standard&ref=search-standalone&origin=jobCard#sol=327309b0bfa1a0e73c22421dcde423c9fe2e4e02,7h ago,7.0,2025-12-21T23:00:00+00:00,Melbourne VIC,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266453,AI Safety Research Scientist (Multiple Positions) –AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89266453?type=standard&ref=search-standalone&origin=jobCard#sol=f83a8924e242f7cf722c2c7bf3c921414cd2cdf5,7h ago,7.0,2025-12-21T23:00:00+00:00,Perth WA,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies. The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division 

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re seeking candidates with deep technical expertise and hands-on experience doing frontier AI safety research.

Senior AI Safety Research Scientist - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Demonstrated experience leading empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience designing safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
A track record of rigorous research contributions. This could include peer-reviewed publications, high-quality preprints, or equivalent research outputs.
Strong ability to translate technical research findings into clear, accessible insights for policymakers and other non-technical audiences.
Experience contributing to international research collaborations or standards development.
The ability to manage competing priorities, deliver complex projects, and thrive in a fast-paced, constantly changing environment.
A collaborative mindset, with experience working in multidisciplinary teams.
A deep understanding of frontier AI risks and mitigation strategies.

We expect these skills will be held by people with 5+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

AI Safety Research Scientist - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Demonstrated experience contributing to empirical AI research on frontier AI systems and safety-relevant behaviours. This could include work on model evaluation, adversarial testing, safety tuning, interpretability, robustness, agentic behaviour or human influence.
Experience contributing to the design of safety-relevant evaluations for frontier AI systems, including assessments of model behaviour, reliability, robustness and other risk-relevant capabilities.
Strong analytical and problem-solving skills, with experience in research and experimental design.
Experience drafting research publications and technical reports.
The ability to effectively communicate research findings to diverse audiences.
Experience managing competing priorities and supporting the delivery of time-sensitive and complex projects.
A collaborative mindset, with experience working in multidisciplinary teams.
A strong interest in international research collaboration.

We expect these skills will be held by people with 3+ years of rigorous empirical research experience, typically in machine learning, data science, computer science or related quantitative fields, or through relevant empirical work in adjacent disciplines including applied statistics, psychometrics, behavioural science, cognitive science, human-computer interaction, cybersecurity research or systems engineering.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate would add to this culture and our workplace in their own way. The department also offers flexible work arrangements.

What you will do

As a Senior AI Safety Research Scientist, you will:

Lead the design of empirical methods to assess the safety of frontier AI models and systems.
Lead the analysis and interpretation of results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Provide strategic advice to policymakers and regulators on emerging AI capabilities, risks and harms.
Collaborate with domestic and international partners across government, industry, civil society and academia to strengthen the science and practice of AI safety.
Work with the Head of AI Safety Research and Testing to develop and deliver a program of research and testing.
Lead the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Research Scientist, you will:

Contribute to the design of empirical methods to assess the safety of frontier AI models and systems.
Analyse and interpret results from evaluations to identify safety-relevant behaviours and generate clear findings and insights.
Represent Australia in international AI safety engagements, including joint testing exercises.
Translate technical findings into actionable insights for policymakers and regulators.
Collaborate with domestic and international partners across industry, civil society and academia to strengthen the science and practice of AI safety.
Contribute to the development of research publications and technical reports.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Scientist role to up to $172,828 for a Senior Research Scientist role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89266288,Senior Software Engineer AI/ML,Cleared Recruitment,https://www.seek.com.au/job/89266288?type=standard&ref=search-standalone&origin=jobCard#sol=6f37242edf9dfd4eaad999bd8383a7afc35431f5,7h ago,7.0,2025-12-21T23:00:00+00:00,"Deakin, Canberra ACT (Hybrid)",Engineering - Software (Information & Communication Technology),Full time,,"Cleared Recruitment are supporting a privately owned Australian defence company seeking a Senior Software Engineer with AI/ML experience and baseline clearance or above to join their Adelaide-based team in a permanent role.
This opportunity suits someone stepping into a hands-on technical leadership role, combining senior-level software engineering with practical AI/ML application. You'll remain deeply technical while helping guide technical direction, mentoring engineers, and working with engineering leadership to define technical goals, scope work, and align development with program and customer objectives.
You'll contribute to impactful defence programs, building AI-enabled, interactive and real-time modelling and simulation applications in a collaborative, delivery-focused environment.
Skills and Experience
Essential


Strong backend software engineering experience using Python, C++, Ja or C#

Experience applying AI/ML techniques in production or R&D environments, including exposure to frameworks such as TensorFlow and/or PyTorch

Ability to design, write, test, and document clean, efficient, and maintainable code

Experience developing Windows and/or Linux native applications, including GUI-based systems

Excellent problem-solving, reasoning, and systems-thinking skills

Exposure to defence-related systems such as weapons, electronic warfare, command and control, or flight systems


Desirable

Experience building distributed and networked systems, including network communications and system configuration
Experience working on modelling and simulation systems

Experience with real-time graphics, visualisation, or user interface design

Familiarity with graphics and compute technologies such as DirectX, OpenGL, Vulkan, CUDA, OpenCL, HLSL, or GLSL

Experience with microservices, virtualisation, and containerisation

Working knowledge of Atlassian tools (Jira, Confluence, Bitbucket)

Experience working in Agile development and testing environments

About you:
You are a senior, highly motivated Software Engineer with strong backend development experience in C++, Python, or C#, and practical exposure to AI/ML techniques used to enhance real-world systems. You enjoy working on complex, mission-critical software and take pride in writing clean, maintainable code that performs reliably in demanding environments.
You thrive in hands-on technical roles where you can contribute at both the code and system level, collaborating closely with multi-disciplinary teams to translate operational and user requirements into robust software solutions. Your experience spans modelling and simulation, native Windows and Linux applications, and integrating software with broader systems, with an appreciation for performance, scalability, and long-term maintainability.
Comfortable working in defence-aligned environments, you bring strong problem-solving skills, sound engineering judgement, and the ability to balance innovation with discipline when delivering software that truly matters.
What you will do
Participate in crafting and advancing systems integral to shaping the future defence capabilities of Australia.

Collaborate with clients and team members to analyse and discern requirements for development initiatives or workflow enhancements.

Advocate for software best practices, including Agile development and testing methodologies; actively encourage and engage in collaboration throughout all stages of the system development life cycle.

Take charge of project advancement and convey project status updates to the team lead, partners, and clients.

Provide proactive mentoring to nurture the growth of software engineers in their development endeavours.

Benefits
Experience fulfilling and captivating tasks within an environment that fosters growth and support in a dynamic and expanding organisation. Enjoy a vibrant and supportive workplace culture that thrives on engagement, creating a stimulating atmosphere.
Benefit from a 37.5-hour workweek complemented by flexible hybrid work arrangements, emphasizing a harmonious work-life balance. Recognize the value placed on professional development and receive competitive remuneration for your contributions. It's an opportunity for interesting and rewarding work in a setting that values your well-being and career growth.

Clearance required
Baseline clearance or above required - Unsure? Visit before applying- https://www.agsva.gov.au/about/security-clearance-definitions

At Cleared, we provide tailored recruitment solutions to individuals seeking their next opportunity and to organisations searching for talent within Defence Industry, Intelligence and National Security.

To arrange a confidential conversation or apply, please contact Emily on 0401791117 or to view all our current openings, please visit https://www.clearedrecruitment.com.au/"
89266220,Senior Software Engineer AI/ML,Cleared Recruitment,https://www.seek.com.au/job/89266220?type=standard&ref=search-standalone&origin=jobCard#sol=57942e27b35c5fd39eb364af4f418887e2b07fb9,7h ago,7.0,2025-12-21T23:00:00+00:00,Adelaide SA (Hybrid),Engineering - Software (Information & Communication Technology),Full time,,"Cleared Recruitment are supporting a privately owned Australian defence company seeking a Senior Software Engineer with AI/ML experience and baseline clearance or above to join their Adelaide-based team in a permanent role.
This opportunity suits someone stepping into a hands-on technical leadership role, combining senior-level software engineering with practical AI/ML application. You'll remain deeply technical while helping guide technical direction, mentoring engineers, and working with engineering leadership to define technical goals, scope work, and align development with program and customer objectives.
You'll contribute to impactful defence programs, building AI-enabled, interactive and real-time modelling and simulation applications in a collaborative, delivery-focused environment.
Skills and Experience
Essential


Strong backend software engineering experience using Python, C++, Ja or C#

Experience applying AI/ML techniques in production or R&D environments, including exposure to frameworks such as TensorFlow and/or PyTorch

Ability to design, write, test, and document clean, efficient, and maintainable code

Experience developing Windows and/or Linux native applications, including GUI-based systems

Excellent problem-solving, reasoning, and systems-thinking skills

Exposure to defence-related systems such as weapons, electronic warfare, command and control, or flight systems


Desirable

Experience building distributed and networked systems, including network communications and system configuration
Experience working on modelling and simulation systems

Experience with real-time graphics, visualisation, or user interface design

Familiarity with graphics and compute technologies such as DirectX, OpenGL, Vulkan, CUDA, OpenCL, HLSL, or GLSL

Experience with microservices, virtualisation, and containerisation

Working knowledge of Atlassian tools (Jira, Confluence, Bitbucket)

Experience working in Agile development and testing environments

About you:
You are a senior, highly motivated Software Engineer with strong backend development experience in C++, Python, or C#, and practical exposure to AI/ML techniques used to enhance real-world systems. You enjoy working on complex, mission-critical software and take pride in writing clean, maintainable code that performs reliably in demanding environments.
You thrive in hands-on technical roles where you can contribute at both the code and system level, collaborating closely with multi-disciplinary teams to translate operational and user requirements into robust software solutions. Your experience spans modelling and simulation, native Windows and Linux applications, and integrating software with broader systems, with an appreciation for performance, scalability, and long-term maintainability.
Comfortable working in defence-aligned environments, you bring strong problem-solving skills, sound engineering judgement, and the ability to balance innovation with discipline when delivering software that truly matters.
What you will do
Participate in crafting and advancing systems integral to shaping the future defence capabilities of Australia.

Collaborate with clients and team members to analyse and discern requirements for development initiatives or workflow enhancements.

Advocate for software best practices, including Agile development and testing methodologies; actively encourage and engage in collaboration throughout all stages of the system development life cycle.

Take charge of project advancement and convey project status updates to the team lead, partners, and clients.

Provide proactive mentoring to nurture the growth of software engineers in their development endeavours.

Benefits
Experience fulfilling and captivating tasks within an environment that fosters growth and support in a dynamic and expanding organisation. Enjoy a vibrant and supportive workplace culture that thrives on engagement, creating a stimulating atmosphere.
Benefit from a 37.5-hour workweek complemented by flexible hybrid work arrangements, emphasizing a harmonious work-life balance. Recognize the value placed on professional development and receive competitive remuneration for your contributions. It's an opportunity for interesting and rewarding work in a setting that values your well-being and career growth.

Clearances
Must be able to obtain baseline - Australian citizenship is a must.

At Cleared, we provide tailored recruitment solutions to individuals seeking their next opportunity and to organisations searching for talent within Defence Industry, Intelligence and National Security.

To arrange a confidential conversation or apply, please contact Emily on 0401791117 or to view all our current openings, please visit https://www.clearedrecruitment.com.au/"
89265620,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265620?type=standard&ref=search-standalone&origin=jobCard#sol=215e2a69bb15cd8a3410c6b7886c1396b911558d,8h ago,8.0,2025-12-21T22:00:00+00:00,Canberra ACT,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265616,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265616?type=standard&ref=search-standalone&origin=jobCard#sol=07906a04ab0692f866cf8b57830a3bef2e460c7c,8h ago,8.0,2025-12-21T22:00:00+00:00,Sydney NSW,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265613,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265613?type=standard&ref=search-standalone&origin=jobCard#sol=c6238d0b3070170ca7dffc33e467ccff85dc23d6,8h ago,8.0,2025-12-21T22:00:00+00:00,Darwin NT,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265606,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265606?type=standard&ref=search-standalone&origin=jobCard#sol=5189d7884728b7559050fab1702111ecbb5d5f84,8h ago,8.0,2025-12-21T22:00:00+00:00,Brisbane QLD,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265598,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265598?type=standard&ref=search-standalone&origin=jobCard#sol=9bacce3c6d4e1c09866db672290395b42cfdf4ce,8h ago,8.0,2025-12-21T22:00:00+00:00,Adelaide SA,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265588,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265588?type=standard&ref=search-standalone&origin=jobCard#sol=96d76698e25326858f7fb64df701bdaf5c404676,8h ago,8.0,2025-12-21T22:00:00+00:00,Hobart TAS,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265541,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265541?type=standard&ref=search-standalone&origin=jobCard#sol=2ad3e4e87c86ea2fc9fb67ee9876177b2c58ba60,8h ago,8.0,2025-12-21T22:00:00+00:00,Melbourne VIC,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89265483,AI Safety Engineer (Multiple Opportunities) - AI Safety Institute,"Department of Industry, Science & Resources",https://www.seek.com.au/job/89265483?type=standard&ref=search-standalone&origin=jobCard#sol=23257bf59a4bd54292ea51145c79e5a3629a3290,8h ago,8.0,2025-12-21T22:00:00+00:00,Perth WA,"Other (Science & Technology)
Government - Federal (Government & Defence)",Full time,,"About the Department

The Department of Industry, Science and Resources and our broader portfolio are integral to the Australian Government’s economic agenda. Our purpose is to help the government build a better future for all Australians through enabling a productive, resilient and sustainable economy, enriched by science and technology. We do this by:

Growing innovative & competitive businesses, industries and regions
Investing in science and technology
Strengthening the resources sector.

The APS and the department offer a clear direction and meaningful work. You will be able to create positive impact in people’s lives whilst contributing to improved outcomes for Australia and our people.

If you would like to feel a strong connection to your work and you are accountable, committed and open to change, join us in shaping Australia’s future.

Please see the APSC’s APS Employee Value Proposition for more information on the benefits and value of employment within the APS.

About the team

About the AI Safety Institute

The Australian Government is establishing an Australian AI Safety Institute (AISI) to support the Government’s ongoing response to emerging risks and harms associated with AI technologies.

The AISI will be the government’s hub of AI safety expertise, operating with transparency, responsiveness and technical rigour. The AISI will conduct technical assessments, support coordinated government action, foster international engagement on AI safety, and publish research to inform industry, academia and the Australian people.

About the Division

The AISI is part of the department’s Technology and Digital Policy Division. The division is responsible for providing policy advice to government, delivering programs and engaging domestically and internationally on enabling and critical technologies as well as the digitisation of the economy.

The division’s priorities include implementing the National AI Plan, providing advice on the safe and responsible use of AI, robotics and automation, the role of critical technologies to support economic security, data policy and emerging digital economy issues.

The opportunity

We’re building a motivated and capable team who will be defining the AISI’s future. As a founding member of the team, you will help shape how Australia monitors, tests and governs AI. You will assess risks from frontier models, including CBRN misuse, enhanced cyber capabilities, loss-of-control scenarios, information integrity and influence risks, and broader systemic risks arising from the deployment of increasingly capable general-purpose AI systems. This is a unique opportunity to work at the frontier of AI, collaborate with domestic and international experts to shape emerging global AI safety standards and help keep Australians safe from AI-related risks and harms.

You’ll have the opportunity to drive positive change, contribute to impactful projects, and develop your expertise in a rapidly evolving field.

Our ideal candidate

We’re looking for candidates with deep technical expertise and hands-on experience working with frontier AI models.

Senior AI Safety Engineer - Science & Technical stream pay scale 8 and 9

Our ideal candidate for this role would have:

Extensive hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Demonstrated experience building and running evaluations of frontier AI systems or safety-relevant model behaviours.
Experience developing or using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing and stress-testing technical safeguards or mitigations, including guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Demonstrated experience running large-scale behavioural evaluations, including managing logs and datasets, diagnosing evaluation or deployment issues and debugging.
A working knowledge of safety-relevant AI failure modes including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
Strong collaborative skills, including the ability to work closely with research scientists and engineers to operationalise evaluation designs and refine testing procedures.
Experience working in multidisciplinary teams and contributing to shared research and engineering workflows.

We expect these skills will be held by people with 5+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

AI Safety Engineer - Science & Technical stream pay scale 7 and 8

Our ideal candidate for this role would have:

Hands-on experience working with frontier or near-frontier AI models and systems, including LLMs, multimodal systems or agentic frameworks.
Experience supporting or contributing to evaluations of frontier AI systems or safety-relevant model behaviours.
Experience using safety-related tooling to support evaluations, such as red-teaming frameworks, test harnesses, automated evaluation pipelines, or continuous monitoring systems.
Experience implementing or testing safety mitigations, such as guardrails, filtering systems, access controls, safety-tuning methods and inference-time controls.
Experience contributing to behavioural evaluations at scale, including working with logs and datasets, supporting issue diagnosis and debugging.
An understanding of common safety-relevant AI failure modes, including robustness issues, jailbreak vulnerabilities, unintended behaviours and reliability failures.
The ability to work effectively in multidisciplinary teams and contribute to the operational delivery of evaluation work.
A willingness to learn, iterate and contribute to shared processes in a fast-paced environment.

We expect these skills might be held by people with 3+ years of industry, academic or equivalent experience working directly on training, tuning, evaluating or operating advanced AI models and systems.

Our department has a commitment to inclusion and diversity, with an ambition of being the best possible place to work. This reflects the importance we place on our people and on creating a workplace culture where every one of us is valued and respected for our contributions. Our ideal candidate adds to this culture and our workplace in their own way.

What you will do

As a Senior AI Safety Engineer, you will:

Operationalise evaluation designs developed in collaboration with AI safety research scientists, translating conceptual testing methodologies into practical, scalable and reproducible experiments.
Build, maintain and operate evaluation and safety-testing tooling for frontier AI systems.
Run large-scale behavioural tests and model evaluations, generating high-quality empirical evidence for safety analysis.
Diagnose emerging failure modes, identify novel vulnerabilities or anomalous behaviours, and work with AI safety research scientists to interpret patterns and assess safety-relevant risks.
Develop and maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Support the continuous improvement of the AISI’s engineering practices, tooling and testing infrastructure in a fast-paced and evolving environment.
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.

As an AI Safety Engineer, you will:

Support the implementation of evaluation designs developed in collaboration with AI safety research scientists, helping translate testing methodologies into repeatable and scalable experiments.
Support the operation and maintenance of evaluation and safety-testing tooling for frontier AI systems.
Assist in running behavioural tests and model evaluations, contributing to the generation of reliable empirical evidence for safety analysis.
Help identify emerging failure modes or anomalous behaviours, and work with AI safety research scientists to interpret results and assess potential risks.
Maintain clear and accurate technical documentation, including evaluation logs, testing reports and safeguard assessments.
Contribute to improving engineering practices, tooling and testing infrastructure as the AISI’s work evolves. 
Collaborate across government, industry, academia and civil society, including participation in international AI safety initiatives and joint evaluation activities.
Contribute to technical reports and research outputs.
Take ownership in building the culture and reputation of the AISI.
Eligibility

Positions require the ability to obtain a minimum baseline security clearance, and the ability to obtain higher security clearance as required.

To be eligible for employment in the APS and the department, candidates must be Australian Citizens.

Notes

A successful candidate will be signed to an initial 12-month contract with the possibility of an extension. Renumeration is determined based on relevant experience and qualifications. Salaries range from $122,235 for a Research Engineer role to up to $172,828 for a Senior Research Engineer role, corresponding to APS Executive Levels 1 and 2 respectively.

Please provide a CV of up to 2 pages (or up to 4 pages if including a list of publications).

Bachelor's degree or equivalent degree in relevant field of study is highly desirable.

A merit pool may be established and used to fill future vacancies within 18 months from the date the vacancy was first advertised in the Gazette. 

The department does currently offer flexible work opportunities for many roles. This vacancy is based Australia-wide, although flexible or remote work arrangements may be considered. Please reach out to the contact officer to discuss this further.

Application information

Your application must not contain any classified or sensitive information. This includes in your application responses, CV and any other documents. The selection panel may not consider applications containing classified information.

Please provide a pitch explaining how your skills, knowledge and experience will be relevant to this role and why you are the best candidate for the position. Your pitch can contain no more than 750 words and should align to the key duties listed above.

Please complete your application online and provide your current CV with your application. (CVs must be in .doc, .docx, or .pdf format).

Accessible application documentation is available in other formats on request. Please contact recruitment@industry.gov.au or (02) 6276 1235 if you require assistance with your application.

Please refer to our Applying for a position information for additional information on how to apply.

Contact Information

For more information regarding this opportunity, please contact Bill Black on 02 6102 9885 or via email on Bill.Black@industry.gov.au"
89263856,Senior Data Engineer,Department of Health - Queensland,https://www.seek.com.au/job/89263856?type=standard&ref=search-standalone&origin=jobCard#sol=2ad52697189107a70d03e8bf8455509eca5eef5a,16h ago,16.0,2025-12-21T14:00:00+00:00,"Fortitude Valley, Brisbane QLD","Engineering - Software (Information & Communication Technology)
Government - State (Government & Defence)",Full time,"$136,035 - $145,990 per annum + super","What you'll do  

Be working within the Queensland Health Enterprise Reporting Team, which involves members of a multi-disciplinary team supporting the department's SAP reporting instance that includes the clinical data.
Lead the development and maintenance of QLD health data warehouse including associated integrations and process orchestration.
Lead the development and maintenance of QLD Health semantic and security models for access to health data.
Lead the development and maintenance of QLD Health reports and dashboards.
Consult, Develop and maintain QLD Health business intelligence architecture and support processes.
Provide expert technical and functional consulting to wider support team.
Provide strategic and expert advice to management in the support and maintenance of health data and associated processes.
Consult and mentor QLD Health staff in the processes and technology supporting health data.

About you  

You will be assessed on your ability to demonstrate the following key capabilities, knowledge and experience. Within the context of the responsibilities described above under ‘Key Responsibilities', the ideal applicant will be someone who can demonstrate the following:

Demonstrate extensive experience in the implementation and maintenance of the Business Intelligence & Data Warehousing Systems
Proven ability to analyse both business and system problems and develop innovative solutions with a strong focus on delivering high quality client services and outcomes
Proven high level of knowledge in data ETL and reporting products.
Proven high level of knowledge in Health Data modelling, security and mining, familiar with data relationship behind Clinical Application systems.
Proven ability to work effectively as a member of a diverse team and assist management and team leaders in supervising and assisting other team members to deliver effective service to clients
Proven high level of client service skills and working to deadlines and service level timelines
Proven high level of knowledge in ITIL foundations and the expert provision of consulting in service management and the design of business intelligence or information services
Proven high level of written and verbal communication skills with demonstrated ability to build effect client and stakeholder relationships by negotiating client needs and ensuring proposed solutions are properly understood and resolved.

Why work with us?  

Work alongside passionate professionals in a supportive and inclusive environment that values people and prioritises employee success and wellbeing. 

Competitive salaries 

12.75% superannuation  
17.5% leave loading 

Employee wellbeing & development 

Access to 24/7 confidential employee support providers and counsellors including for immediate family members 
Additional flexibility to support your work life balance including access to generous leave entitlements, such as purchased leave, domestic violence leave, reproductive health leave, cultural leave, study and examination leave. 
Access to a variety of programs and initiatives to support training and career growth.  
Grow your skills through hands-on experience and access to internal training opportunities and additional financial and leave benefits for approved external training and development. 

Our commitment to equity, diversity and inclusion  

At Queensland Health, our work environment is inclusive and supportive, and we value our employees. We are an equal opportunity employer and encourage applications from people of all cultures, abilities and backgrounds.  

Our commitment to cultural safety, equity, diversity and inclusion means we understand some people may need changes to the recruitment process. If you need support during the recruitment process, such as meeting with the panel virtually instead of in person, please reach out to the hiring manager. We value diverse candidates and your need for adjustments will not affect our hiring decisions.  

Ready to apply? 

For further information on how to apply please review the attached Role Description."
