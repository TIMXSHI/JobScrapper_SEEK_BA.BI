Job ID,Job Title,Company,Detail URL,Posted Label,Hours Old,Posted Datetime (Local),Location,Category,Work Type,Salary,Ad Text
90401667,AI Network Domain Architect,World Wide Technology,https://www.seek.com.au/job/90401667?type=standard&ref=search-standalone&origin=jobCard#sol=288f8302ead30b2011528d6941d7004257af5f64,1h ago,1.0,2026-02-18T01:00:00+00:00,Sydney NSW (Remote),Architects (Information & Communication Technology),Contract/Temp,"$20,000 – $27,000 per month","The Domain Architect - AI Network acts as the primary technical authority for the physical and logical lifecycle of high-performance interconnect fabrics across diverse client environments, who bridges the gap between architectural design and hands-on execution. You are a ""doer"" who is as comfortable configuring Adaptive Routing on leaf and spine switches in the CLI as you are explaining that configuration to a C-level client.

As a System Integrator, we do not simply manage a static cloud; we design and deliver bespoke, high-scale AI factories for the world's leading enterprises. In this role, you will define the ""Gold Standard"" for network infrastructure, moving beyond single-switch management to architect repeatable, scalable, and automated lossless fabrics. You will serve as the technical lead for NVIDIA Cloud Provider (NCP) and private enterprise AI cloud deployments, owning the ""Network"" in the critical ""Compute-Network-Storage"" triad.

In this role, you will operate with a 60/40 split between delivering (60) complex AI infrastructure and providing Pre-Sales (40) Subject Matter Expertise (SME). You will lead the physical provisioning of InfiniBand and Spectrum-X Ethernet fabrics for NVIDIA SuperPOD, NVIDIA BasePOD, and Cisco AI Factory environments, ensuring our clients receive ""Day 2"" ready AI factories, while assisting the sales team in defining the scope and cost of future deployments.

Key Responsibilities

1. Delivery & Implementation (60%)

High-Performance Fabric Design:

Architect and deploy Non-Blocking Fat-Tree (Clos) topologies using NVIDIA Quantum-2 (NDR) / Quantum-3 (XDR) InfiniBand switches and Spectrum-4 Ethernet switches.

Implement Rail-Optimised network designs to ensure GPU-to-GPU traffic is perfectly aligned with compute node PCIe trees, minimising latency for NCCL collectives.

Configure Adaptive Routing, Congestion Control, and Quality of Service (QoS) to prevent ""Head-of-Line Blocking"" and ensure lossless data delivery.

In-Network Computing & Offload Strategy:

InfiniBand (Switch-Based): Enable and tune SHARP (Scalable Hierarchical Aggregation and Reduction Protocol) on Quantum switches to offload collective operations (AllReduce, ReduceScatter) from the GPU to the switch silicon.

Ethernet (Endpoint-Based): Architect high-performance Ethernet AI fabrics utilising SmartNIC/DPU offloading (e.g., NVIDIA BlueField-3) to accelerate collective operations and isolate management traffic from the data path.

Future Stacks: Evaluate and roadmap emerging Ultra Ethernet Consortium (UEC) standards and hardware capabilities to transition In-Network Collectives from proprietary InfiniBand to open Ethernet standards.

Tune RoCEv2 and adaptive routing algorithms on Ethernet fabrics and SmartNICs to approximate InfiniBand-like lossless behaviour.

Fabric Management & Telemetry:

Deploy NVIDIA UFM (Unified Fabric Manager) to manage InfiniBand subnets and NetQ for Ethernet telemetry.

Monitor fabric health to identify ""Slow Receivers"" and link degradation in real-time.

Implement PTP (Precision Time Protocol) for nanosecond-level clock synchronisation across the entire cluster.

Layer 1 Precision:

Oversee the physical cabling strategy, defining strict cable schedules (DAC vs. AOC vs. OSFP transceivers) to meet signal integrity requirements over specific distances.

Validate the ""Link Budget"" to ensure optical loss falls within acceptable limits for 400G/800G links.

2. Pre-Sales SME & Consulting (40%)

Technical Scoping & Sizing:

Calculate the required Bisectional Bandwidth for client workloads (e.g., Training requires 1:1 non-blocking, Inference may tolerate 3:1 oversubscription).

Produce accurate Labour Estimates (LOE) for complex network integrations.

BoM Validation:

Own the Network Bill of Materials (BoM), validating that every transceiver, cable, and switch is on the NVIDIA/OEM HCL.

Manage the complexities of breakout cables (e.g., 800G to 2x400G) and connector types (OSFP, QSFP112) to prevent on-site installation failures.

Client Strategy Workshops:

Educate clients on the difference between standard Enterprise Ethernet (Lossy, TCP-based) and AI Fabric (Lossless, RDMA-based).

Design integration points between the high-speed ""Backend"" AI fabric and the client's existing ""Frontend"" management network (BGP/EVPN handoffs).

Technical Competencies

Essential Skills

NVIDIA Networking (Mellanox):

Deep expertise in NVIDIA Quantum InfiniBand switch architecture and management via MLNX-OS and UFM.

Mastery of Spectrum-X Ethernet platforms running NVIDIA Cumulus Linux or SONiC (Software for Open Networking in the Cloud).

Proficiency in configuring RoCEv2 (RDMA over Converged Ethernet), including PFC (Priority Flow Control) and ECN (Explicit Congestion Notification).

Architectural understanding of NVIDIA BlueField DPU and DOCA use cases for offloading network functions.

Network Automation (NetDevOps):

Proficiency in Python and Ansible for switch configuration management.

Experience with Infrastructure as Code (IaC) principles to treat network config as software.

Fabric Telemetry:

Hands-on experience with UFM, Prometheus, and Grafana for visualising fabric congestion and ""tail latency.""

Desirable Experience

Multi-Vendor Exposure: Experience with Arista (EOS) for high-performance AI Ethernet or Cisco (Nexus Dashboard) for AI infrastructure.

Routing Protocols: Solid understanding of BGP, EVPN, and VXLAN for multi-tenant isolation.

Compute Integration: Understanding of how the network interacts with the host OS (IPoIB, Netlink) and optimisation of GPU Direct RDMA (GDR) and NCCL communication patterns.

Scale-Across: Extending an InfiniBand fabric across multiple data centre halls (NVIDIA Metro-X).

Certifications:

NVIDIA-Certified Professional: AI Networking (NCP-AIN)

NVIDIA-Certified Associate: AI Infrastructure and Operations (NCA-AIIO)

Arista ACE (Cloud Engineer).

Cisco CCNP/CCIE Data Center.

Success Metrics (KPIs)

Fabric Performance: Achieving >95% effective bandwidth efficiency on NCCL-test benchmarks across the full cluster.

Deployment Accuracy: Zero ""Layer 1"" rework required due to incorrect transceiver/cable specification in the BoM.

Stability: Zero topology or design-induced link instability (e.g., cabling mismatches) in production."
90401499,AI Compute Domain Architect,World Wide Technology,https://www.seek.com.au/job/90401499?type=standard&ref=search-standalone&origin=jobCard#sol=3afb059e9f6a65e6c65155455812f1d1ecc34f2e,1h ago,1.0,2026-02-18T01:00:00+00:00,Sydney NSW (Remote),Architects (Information & Communication Technology),Contract/Temp,"$22,000 – $28,000 per month","Job Description:

About the Role

The Domain Architect - AI Compute acts as the primary technical authority for the physical and logical lifecycle of high-performance GPU compute fleets across diverse client environments, who bridges the gap between architectural design and hands-on execution. You are a ""doer"" who is as comfortable configuring a cluster in the CLI as you are explaining that configuration to a C-level client.

As a System Integrator, we do not simply manage a static cloud; we design and deliver bespoke, high-scale AI factories for the world's leading enterprises. In this role, you will define the ""Gold Standard"" for compute infrastructure, moving beyond single-server management to architect repeatable, scalable, and automated compute fabrics. You will serve as the technical lead for NVIDIA Cloud Provider (NCP) and private enterprise AI cloud deployments, owning the ""Compute"" in the critical ""Compute-Network-Storage"" triad.

In this role, you will operate with a 60/40 split between delivering (60) complex AI infrastructure and providing Pre-Sales (40) Subject Matter Expertise (SME). You will lead the physical provisioning of NVIDIA SuperPOD, NVIDIA BasePOD, and Cisco AI Factory environments, ensuring our clients receive ""Day 2"" ready AI factories, while assisting the sales team in defining the scope and cost of future deployments. 

Key Responsibilities

1. Delivery & Implementation (60%)

Bare Metal Build & Provisioning:

Lead the physical provisioning of clusters: NVIDIA NVL72, DGX SuperPOD, BasePOD, HGX, MGX, Cisco AI Factory.

Utilise NVIDIA Base Command Manager (BCM) for diskless booting, firmware management, and OS hardening.

Establish monitoring with NVIDIA Mission Control.

Execute automated ""Zero Touch Provisioning"" (ZTP) workflows to transform bare-metal hardware into production-ready nodes.

Scheduler & Workload Configuration:

Define and enforce ""Fair Share"" policies, fractional GPU quotas using Multi-Instance GPU (MIG), and pre-emption logic for multi-tenant environments.

Ensure orchestration layers respect hardware topology (NUMA affinity, PCIe trees) for maximum performance.

Implement and configure advanced schedulers: Slurm (bare metal), NVIDIA Run:AI (Kubernetes), Kueue (Kubernetes), Volcano (Kubernetes).

Orchestration & Day 2 Operations:

Deploy and configure management planes like Rafay or Armada to enable multi-cluster management and observability.

Implement high-fidelity telemetry using DCGM (Data Centre GPU Manager) to monitor GPU health, thermal throttling, and XID error rates.

Lead the ""Day 2"" handover, ensuring the environment is fully integrated with the client's identity providers and storage backends.

Performance Engineering:

Conduct validation testing using NCCL-tests, HPL, and HPCG to verify cluster performance.

Perform kernel-level tuning (huge pages, sysctl) to optimise the OS for high-bandwidth InfiniBand/RoCEv2 fabrics.

2. Pre-Sales SME & Consulting (40%)

Technical Scoping & Estimation:

Assist the sales team by validating customer technical requirements and producing accurate Labour Estimates (LOE) for Statements of Work (SOWs).

Define the ""Standard Operating Environment"" (SOE) for proposals to ensure repeatability.

BoM Validation & Architecture:

Own the technical accuracy of the Compute Bill of Materials (BoM).

Ensure all components (RAM, NVMe, NICs, Transceivers) are strictly aligned with the NVIDIA HCL (Hardware Compatibility List) and approved reference architectures (DGX, HGX, MGX, NVL72).

Ensure alignment of GPU selection with client workloads.

Client Workshops:

Lead technical discovery workshops to determine specific workload requirements (e.g., distinguishing between ML workloads vs. LLM Inference vs. LLM Training requirements vs. Omniverse Digital Twin rendering).

Technical Competencies

Essential Skills

NVIDIA Ecosystem:

Deep architectural understanding of NVIDIA GPU platforms (Hopper, Grace-Hopper, Blackwell, Grace-Blackwell).

Mastery of NVL72 rack-scale integration and NVSwitch fabrics.

Expertise in the associated software stack (CUDA, cuDNN, NCCL).

Linux Systems Engineering:

Expert-level knowledge of Linux distributions (Ubuntu, RHEL) optimised for HPC/AI.

Deep experience with kernel tuning, driver management, and system hardening.

Infrastructure as Code (IaC):

Proficiency in Python and Ansible for hardware configuration management and automation.

Desirable Experience

Industry Background: Experience working within a System Integrator (SI) or Managed Service Provider (MSP) environment.

Cluster Management: Hands-on experience with NVIDIA Base Command Manager (BCM) (previously Bright Cluster Manager) and/or NVIDIA Mission Control.

Network Integration: Solid understanding of high-speed interconnects (InfiniBand NDR/HDR, RoCEv2) and how they interface with host PCIe/NVLink topologies.

Facilities & Cooling: Familiarity with liquid cooling implementation (Direct-to-Chip, Rear Door Heat Exchangers) and its impact on server maintenance.

Container Platforms: Experience with Kubernetes/Red Hat OpenShift installation and administration.

Cloud/Hyperscaler Architecture: Azure/AWS/GCP/OCI compute design for AI workloads.

AI & Orchestration Tools: Hands-on exposure to:

Rafay

NVIDIA Run:AI

NVIDIA Omniverse

OpenShift AI

KubeFlow

Success Metrics (KPIs)

Deployment Success: Successful handover of clusters that pass all NVIDIA validation tests (NCCL/HPL) on the first attempt.

Estimation Accuracy: Achieving <10% variance between estimated LOE and actual hours delivered on implementation projects.

Client Satisfaction: Positive technical feedback from client workshops and handover sessions."
90401316,AI Storage Domain Architect,World Wide Technology,https://www.seek.com.au/job/90401316?type=standard&ref=search-standalone&origin=jobCard#sol=049cb248ce5ef3bc7e12efc6a778e37f5fa7dba8,1h ago,1.0,2026-02-18T01:00:00+00:00,Sydney NSW (Remote),Architects (Information & Communication Technology),Contract/Temp,"$24,000 – $29,000 per month","Job Description:

 

About the Role

The Domain Architect - AI Storage acts as the primary technical authority for the physical and logical lifecycle of high-performance data platforms across diverse client environments, who bridges the gap between architectural design and hands-on execution. You are a ""doer"" who is as comfortable configuring an NVMe-over-Fabrics connection in the CLI as you are explaining that configuration to a C-level client.

As a System Integrator, we do not simply manage a static cloud; we design and deliver bespoke, high-scale AI factories for the world's leading enterprises. In this role, you will define the ""Gold Standard"" for storage infrastructure, moving beyond single-array management to architect repeatable, scalable, and automated data fabrics. You will serve as the technical lead for NVIDIA Cloud Provider (NCP) and private enterprise AI cloud deployments, owning the ""Storage"" in the critical ""Compute-Network-Storage"" triad.

In this role, you will operate with a 60/40 split between delivering (60) complex AI infrastructure and providing Pre-Sales (40) Subject Matter Expertise (SME). You will lead the physical provisioning of high-throughput storage clusters for NVIDIA SuperPOD, NVIDIA BasePOD, and Cisco AI Factory environments, ensuring our clients receive ""Day 2"" ready AI factories, while assisting the sales team in defining the scope and cost of future deployments.

Key Responsibilities

1. Delivery & Implementation (60%)

Parallel File System (PFS) Deployment:

Lead the installation and configuration of high-performance storage clusters using technologies such as WEKA, DDN (Lustre), VAST Data, or Pure Storage.

Optimise storage client configurations on compute nodes, managing kernel modules and mounting parameters to ensure stability at scale.

Implement GPUDirect Storage (GDS) technologies to bypass the CPU and enable direct data paths between NVMe drives and GPU memory.

Container Storage Integration:

Deploy and configure Container Storage Interface (CSI) drivers for Kubernetes/Red Hat OpenShift, ensuring persistent storage is dynamically provisioned for AI workloads.

Design storage classes that differentiate between ""Scratch"" (High Performance) and ""Home/Project"" (General Purpose) tiers.

Performance Tuning & I/O Profiling:

Execute synthetic benchmark suites (IOR, FIO, mdtest) to validate throughput (GB/s) and metadata performance (IOPS) against agreed SLAs.

Troubleshoot ""straggler"" issues where slow I/O starves GPU utilisation, analysing client-side logs and fabric counters.

Data Lifecycle Management:

Implement automated data tiering strategies to move datasets between Hot (NVMe), Warm (QLC Flash), and Cold (Object/S3/Tape) tiers based on access frequency.

2. Pre-Sales SME & Consulting (40%)

Technical Scoping & Sizing:

Lead the architectural sizing for storage opportunities. Move the conversation beyond ""How many Petabytes?"" to ""How many Terabytes per Second per GPU?"".

Calculate required performance for specific workloads (e.g., massive small-file ingestion for Computer Vision vs. large-file streaming for LLMs) to create accurate estimates.

BoM Validation:

Own the Storage Bill of Materials (BoM), ensuring the correct ratio of Storage Servers to Compute Nodes/GPUs.

Validate interoperability between Storage Controllers, Host Channel Adapters (HCAs), and Transceivers against the NVIDIA Hardware Compatibility List (HCL) and vendor compatibility matrices.

Client Strategy Workshops:

Advise clients on the transition from legacy Enterprise NAS (NFSv3) to modern AI-Native Storage protocols (NFS over RDMA, NVMe-oF).

Design namespace architectures that support multi-tenancy, data sovereignty requirements, and potentially hybrid architectures for workload bursting capability.

Technical Competencies

Essential Skills

High-Performance Storage Ecosystem:

Expert-level knowledge of Parallel File Systems (WEKA, Lustre, BeeGFS, GPFS).

Deep understanding of Object Storage (S3 protocols) for model checkpointing and archiving.

Mastery of storage protocols: NVMe-over-Fabrics (NVMe-oF), NFS over RDMA, and NVIDIA GPUDirect Storage (GDS).

Linux I/O Engineering:

Deep understanding of the Linux I/O stack, including Block Device drivers, file system tuning (xfs, ext4), and client-side caching mechanisms.

Infrastructure as Code (IaC):

Proficiency in one of Python, Ansible, or Terraform for automating storage cluster deployment and client configuration management.

Desirable Experience

Industry Background: Experience working within a System Integrator (SI), Storage Vendor (e.g., NetApp, Dell, Pure), or MSP environment.

Platform Integration: Hands-on experience integrating storage with bare metal, and Kubernetes/Red Hat OpenShift.

Network Affinity: Understanding of InfiniBand and RoCEv2 fabrics from a storage perspective (Congestion Control, Quality of Service).

LLM Inference & Caching Stack:

Understanding of technologies such as NVIDIA Dynamo, vLLM, SGLang, for distributed inference serving ad KV cache management.

Understanding of Distributed Pre-fill concepts and their storage I/O requirements.

Understanding LMCache for KV cache offloading and sharing.

Success Metrics (KPIs)

I/O Saturation: Achieving >90% of the theoretical wire-speed throughput on compute clients during validation testing (IOR/FIO).

Deployment Velocity: Successful ""Day 1"" mount availability across all compute nodes using automated playbooks.

Storage BoM Accuracy: Usable capacity vs. Raw capacity calculations are accurate to within 5% of client requirements (i.e. accounting for product functional overhead)."
90399862,Principal Systems Architect,NSW Electoral Commission,https://www.seek.com.au/job/90399862?type=standard&ref=search-standalone&origin=jobCard#sol=9972b9fd385df1563f402949b7d118c01638059c,2h ago,2.0,2026-02-18T00:00:00+00:00,Sydney NSW (Hybrid),"Architects (Information & Communication Technology)
Government - State (Government & Defence)",Full time,"$149,739 - $173,174","Enjoy the opportunity to work in lean dynamic and dedicated team, collaborative and dynamic learning environment 
Excellent work/life balance

About the Role

The Principal Systems Architect is responsible for providing expert technical leadership in the design and optimisation of the organisation’s technology ecosystem, ensuring that systems are integrated, resilient, and scalable. This position ensures that technology investments deliver long-term value, minimise technical debt, and remain compliant with NSW Government digital standards.

This role will suit a senior enterprise architect who has led end-to-end digital transformation initiatives within complex enterprise environments and is motivated by delivering long-term strategic outcomes rather than short-term project engagements.

You will play a critical leadership role in shaping and delivering a future-state architecture across a hybrid on-premise and cloud environment, with a strong emphasis on Microsoft Azure. The role requires deep experience designing integrated ecosystems that support multiple mission-critical applications, ensuring interoperability, security, performance, and scalability.

Working within a lean but high-performing Technology Assurance function, you will influence architectural direction across large-scale digital programs that underpin high-profile, immovable election events. You will provide strategic oversight across business, application, data, technology and security domains, balancing immediate delivery requirements with long-term architectural integrity.

This is a Temporary full-time position up to 30 June 2027, with potential to be extended.

About the NSW Electoral Commission

The New South Wales Electoral Commission delivers trusted and independent systems, processes, oversight and engagement that support democracy in New South Wales. Our vision is to maintain confidence in the integrity of the democratic process and make it easy for people to understand and participate.

Our work includes:

Running and regulating elections
Communicating and engaging with current and future voters, key NSW community stakeholders and NSW election participants; and
Investigating possible offences and enforcing electoral and lobbying laws such as the Electoral Act 2017 and the Electoral Funding Act 2018.

What we offer

Opportunity to work on large scale events and assist your local community  
Career development opportunities through study and face to face training
Access to self-paced expert-led training via LinkedIn Learning
Employee Assistance Program for wellbeing support 
Staff social events to connect with colleagues  
Work/Life balance (35 hour working week), flex leave
Access to Fitness Passport for eligible staff 
Free annual flu vaccination
Convenient CBD location, access to public transport

Key knowledge, experience and essential requirements:

Extensive experience in senior systems architecture roles within complex enterprise environments, including significant experience in cloud and hybrid environments, with strong Azure capability.
Proven experience leading enterprise-wide digital transformation initiatives and developing target-state architecture roadmaps.
Demonstrated experience designing integrated ecosystems across multiple critical business applications, including complex integrations between bespoke systems and third-party platforms.
Extensive knowledge and practical application of security-by-design principles, enterprise risk management, and compliance with NSW Government Cyber Security and Digital standards.
Strong capability in balancing architectural governance with delivery pragmatism, particularly in environments with fixed regulatory or operational deadlines.
Politically neutral with no affiliation to political parties or lobbyists/campaigners.
Satisfactory Criminal Record check result.

How to apply

Please include a cover letter addressing the essential requirements of the role with relevant examples from your experience, along with an up-to-date resume. Also include your responses to the two targeted questions below. Send your application to henry.brosius@clicks.com.au 

As part of your application, you will be asked to respond to the two targeted questions:

Provide details of the most complex architecture work you have done, outlining its impact on the critical business outcome (maximum 300 words)
Provide details of your contribution to the adoption of governance practice to systems architecture (maximum 300 words)  

For further information regarding the role please download the Role Description.

For additional information, please contact Henry Brosius at henry.brosius@clicks.com.au

Applying for a role in the NSW Public Service

For more information on how to apply for a role in the NSW Public Service, please refer here.

The NSW Electoral Commission embraces diversity and inclusion and is committed to creating a workplace that reflects the population of New South Wales. We welcome applications from people from diverse backgrounds and encourage women, Aboriginal and Torres Strait Islander people, LGBTQIA+, people with disability, mature-age people, and people from culturally diverse backgrounds to apply for this role. 

If you have any questions about applying or would benefit from an adjustment to the recruitment process to help you perform your best please contact talent@elections.nsw.gov.au. For more information on recruitment adjustments visit I Work for NSW Adjustments for individual needs.

Applications received and completed after closing time will not be considered for selection. 

The selection process will include a range of assessment techniques to assist in determining your suitability for the role.

For further information, contact NSW Electoral Commission’s Talent team on talent@elections.nsw.gov.au.

Other Information

Your employment will be subject to National Criminal Records Check to determine your suitability for employment. 

The NSW Electoral Commission is committed to maintaining public confidence in the integrity of the electoral system. The Commission requires all its employees to refrain from membership of any political party and from engaging in political activity which could be seen as reflecting adversely on the strict political neutrality of the Commission. To maintain political neutrality, applicants for roles with the Commission who are, who have been or who may be perceived to be or have been connected with political activities may also be ineligible for appointment and should disclose such information as part of their application. This does not include voting in a Commonwealth, State or Local Government election, which is compulsory in NSW.  The Commission’s Political Neutrality Policy may be viewed on its website.

A talent pool may be created from this recruitment action for ongoing and temporary roles of the same work classification that may become available for filling over the next 18 months.

This role is based in at our Elizabeth Street, Sydney office with a hybrid work arrangement.

Applications Close: Sunday 1st March 2026 @ 11.59pm"
90399515,"Lead AI Engineer - Gain Production GenAI/Agentic AI - $220,000-Melbourne/Hybrid",Morgan Consulting,https://www.seek.com.au/job/90399515?type=standard&ref=search-standalone&origin=jobCard#sol=703ed67deb53b625a743d9f39dd168341b741a02,2h ago,2.0,2026-02-18T00:00:00+00:00,Melbourne VIC (Hybrid),Engineering - Software (Information & Communication Technology),Full time,AUD 180000 - 220000 per annum,"Lead AI Engineer - Gain Production GenAI/Agentic AI - $220,000 - Melbourne - Hybrid 

Morgan Consulting is partnering with a data driven innovator that is shaping the next era of Generative AI, Agentic AI, and Machine Learning. As they scale advanced AI capabilities across products, platforms, and engineering practices, they are seeking a Lead AI Engineer to define technical direction, build high impact solutions, and mentor a cross‑functional squad working across production GenAI, Agentic AI and ML Systems.


About the Role:(reference V-66350)

This is a hands‑on technical leadership role, you will architect, build, and operate reliable ML/AI solutions, elevate engineering standards, and accelerate the adoption of Generative and Agentic AI across mission‑critical, client‑facing platforms. This position combines strategic influence with deep technical execution, ideal for someone who wants to lead, innovate, and deliver tangible impact.

What You Will Do:

Set the technical vision for ML/AI engineering (GenAI testing, automation, Agentic AI patterns, MLOps, and production GenAI) and own the roadmap across multiple workstreams.
Lead and mentor engineers (automation, frontend test, ML engineers) through code reviews, pairing, design forums, and capability uplift.
Architect end to end ML/AI systems including feature pipelines, model training & evaluation, inference/agentic services, observability/monitoring, and continuous delivery at scale.
Stand up GenAI and Agentic AI testing frameworks and custom test models for LLMs, generative pipelines, and autonomous agent behaviours; drive best practice in model quality, evaluation, safety, and release governance.
Develop and evolve automation frameworks for web/mobile (Playwright, Cypress, Appium/Detox), integrating GenAI and Agentic AI for test generation, autonomous prioritisation, self healing, and risk driven execution.
Standardise ML and GenAI delivery patterns (feature stores, CI/CD, model registries, canary/blue‑green, rollbacks, A/B testing & back‑testing, agent orchestration) across teams and brands.
Own reliability and performance, low latency design, concurrency, resilience, cost optimisation; ensure SLOs, alerting, and runbooks are in place for both ML and production GenAI workloads.
Close gaps across DevSecOps, security guardrails, data governance, secrets management, PII handling, and compliance for ML, LLMs, and autonomous agents.
Partner with Data Science to productionise cutting edge models (LLMs, multi‑modal, agentic systems) and continuously improve them through experimentation, error analysis, telemetry, and robust monitoring.
Champion continuous improvement, automation‑first mindset, developer experience uplift, and pragmatic platform investments to accelerate both ML and GenAI delivery.
Contribute to Flutter brands by sharing reusable capabilities, patterns, and frameworks across the group.
Design and implement feature pipelines, inference services, and agentic execution paths (APIs, streaming, batch), with rigorous monitoring for drift, hallucination, performance, and cost.
Build and maintain CI/CD pipelines for ML, GenAI, and test automation (GitHub Actions preferred; Jenkins/Codemagic as needed).
Lead test strategy for ML, LLMs, and Agentic AI systems: contract testing, model evaluation, guardrails, synthetic data, behavioural tests for autonomous agents, and production validation.
Perform peer reviews and uphold engineering standards (coding guidelines, secure defaults, documentation, reproducibility).
Drive delivery estimation, prioritisation, and outcome accountability, aligning with product and platform stakeholders.
Diagnose and resolve production issues end‑to‑end, including model failures, LLM degradation, agentic misbehaviour, data drift, and infra bottlenecks; manage post‑incident analysis and remediation.
Ensure observability and explainability (metrics, logs, traces, model cards, evaluation reports) are embedded for all ML/AI systems, including GenAI and Agentic AI.
Support adoption of price‑assurance and quantitative frameworks, and contribute to solver/simulation‑based applications where relevant.

What you will bring:

Proven experience leading engineering teams or guilds across Gen AI and Agentic AI/ML/MLOps and test automation in production, customer-facing contexts.
Strong software engineering in Python and one of Rust/C++/Java/Go, with demonstrable knowledge of concurrency, parallelisation, performance tuning, and memory safety.
Hands-on with ML pipelines, model registries, feature stores, containerisation (Docker) and orchestration (Kubernetes).
Expertise in CI/CD and quality engineering at scale; deep experience integrating GitHub Actions (preferred) or Jenkins/Codemagic.
Solid track record with frontend/mobile test frameworks (Playwright, Cypress, Appium/Detox, Selenium) and GenAI enabled testing (test synthesis, self healing, flake reduction).
Proficient in model experimentation & evaluation (A/B testing, back testing, cross validation, error analysis), plus real time prediction use cases (regression, classification, time-series, anomaly detection).
Strong grasp of DevSecOps for ML, secrets, compliance, access control, PII handling, dependency risk, and secure SDLC.
Excellent communication, stakeholder management, and the ability to influence standards across multiple teams.
Experience with quant/price assurance frameworks or solver/simulation based applications.
Familiarity with data models such as Medallion, Kimball, or Data Vault.
TypeScript/JavaScript for tooling and test frameworks; mobile CI familiarity.
Knowledge of LLM evaluation frameworks, prompt testing/hardening, and guardrail libraries.

Why Join:

Opportunity to gain significant GenAI and Agentic AI production experience at enterprise scale. 
Strong Career Development.
Amazing culture - data driven innovator that is shaping the next era of Generative AI, Agentic AI, and Machine Learning.

If you're a Lead AI Engineer, who thrives in a fast-paced environment, and is outcome focussed we would love to hear from you. Apply now or reach out for a confidential conversation (reference V-66350)."
90398558,AI Solutions Specialist,BAI Communications Pty Limited,https://www.seek.com.au/job/90398558?type=standard&ref=search-standalone&origin=jobCard#sol=08a219f3ad115c4e18d67f594839f46bbe11240e,3h ago,3.0,2026-02-17T23:00:00+00:00,"North Sydney, Sydney NSW (Hybrid)",Other (Information & Communication Technology),Full time,"+ super, bonus, great location and company culture","WHY BAI COMMUNICATIONS

It’s an exciting time to be part of BAI Communications. Building on our achievements in broadcasting, telecommunications and critical communications, we continue to expand our operations, helping connect people and support communities.

 

We operate one of the world’s most extensive broadcast networks, delivering fully managed television and radio services to 99% of the Australian population. During crises such as natural disasters, national broadcasters depend on BAI to maintain vital communications, while emergency services trust us to keep them connected and informed.




As 5G technology transforms connectivity, BAI is leveraging global experience to enable comprehensive coverage in challenging environments—buildings, tunnels, stadiums, and high-density areas. This expertise positions us at the forefront of intelligent, connected infrastructure development across Australia.




Our acquisition of Titan ICT has strengthened our mission-critical capabilities, adding deep expertise in mining, resources, and energy industries. This expansion enables us to deploy robust solutions across Australia’s most demanding operational environments.




Discover more through BAI360, our virtual tour platform. 

 







LET’S EXPLORE THE ROLE

As the AI Solutions Specialist, you will execute BAI’s AI capability roadmap—shaping strategic direction, uplift organisational literacy, deliver AI pilot outcomes, and scale successful solutions across the enterprise. You’ll partner with technical and business leaders to embed AI into the organisation in a secure, compliant, and value‑driven way




Key Responsibilities:

Lead AI strategy in partnership with the CIO and Enterprise Platforms Manager, identifying high‑value opportunities across the business.
Build BAI’s AI literacy by designing and delivering learning and engagement programs.
Manage the AI Incubator, prioritising and executing pilots with clear business cases and measurable success metrics.
Drive pilot delivery, track outcomes, and present updates to the AI Steering Committee.
Scale successful pilots into production, ensuring enterprise integration, architecture alignment, and security compliance.
Build strong working relationships across the business to gather requirements and secure buy‑in.
Evaluate AI platforms, vendors, and tools, making recommendations for enterprise adoption.
Prepare reports, briefings, and insights for senior executives and governance stakeholders.




LET’S HEAR ABOUT YOU

You are an innovative, future‑focused technology professional who thrives at the intersection of strategy, delivery, and emerging AI capabilities. You excel in stakeholder engagement, can translate complex concepts into practical solutions, and enjoy helping organisations adopt new ways of working.

 

Technical Skills Required

Expert: AI Solution Design, AI Prompt Engineering
Advanced: Vibe (AI) Engineering, LLMs, Python/C++, Agentic AI, workflow automation
Intermediate: Solution architecture, data analysis, project management, documentation, EA frameworks, SDLC, API integration, training delivery, data governance & privacy
Working knowledge: Security frameworks, Azure/AWS cloud platforms

 

You’ll also bring:

A tertiary qualification in IT, Computer Science or related discipline (or equivalent experience)
5–7 years’ experience in enterprise technology roles with demonstrated AI/technology delivery success
Strong communication, stakeholder and vendor management experience




BENEFITS & CULTURE

At BAI, we value diversity and welcome applications from Aboriginal and Torres Strait Islander peoples, culturally diverse communities, people with disability, and LGBTQIA+ individuals.

Guided by our principles—One BAI Team, Customer First, Adapt and Learn, and Drive Sustainable Growth—we create an environment where you can thrive.

Why join us?

Inclusive culture supported by a DEI strategy, Champion Network, Diversity Council membership, and regular events.
Strong focus on development with a performance framework and LinkedIn Learning access.
Flexible work options, gender-neutral parental leave, study and volunteer leave."
90397725,Microsoft Dynamics 365 Developer,Motorsport Australia,https://www.seek.com.au/job/90397725?type=standard&ref=search-standalone&origin=jobCard#sol=26b71d07a1f0683753cd089329bc2ce757a836b0,3h ago,3.0,2026-02-17T23:00:00+00:00,"Canterbury, Melbourne VIC (Hybrid)",Developers/Programmers (Information & Communication Technology),Full time,,"About Us

We are a passionate team, focused on the development, regulation, promotion and administration of motorsport across Australia. As the National Sporting Authority and custodian of four wheeled motorsport in this country, we are a dedicated, talented and collaborative team committed to driving our Vision of “More people enjoying more motorsport, in more places, more often”.

 About the Role

Motorsport Australia is on an exciting Digital Transformation journey, implementing a multi-faceted program including Dynamics 365 to manage our Members, Officials, Licenses, Venues, Events and more.

 We’re looking for an entry to mid-level Dynamics 365 and Power Apps Developer to join our passionate team. You’ll play a key role in our Transformation Program developing, enhancing, and supporting our business systems — primarily Dynamics 365, Power Platforms, and Power BI, and Azure.

 Key responsibilities include:

Develop, configure, test, and support business solutions in the Microsoft Dynamics 365 Ecosystem

Develop and maintain automation, workflows, plug-ins, and custom applications using Power Platform tools, including Power Automate, Power Apps, and Power BI.

Build, automate, and maintain business processes using forms, workflows, integrations, and notifications

Write clean, maintainable, repeatable code to technical specifications, including Maintain and Build CI/CD pipelines and DevOps practices

Monitor System performance, troubleshoot issues, and analyse and resolve enhancements, defects, work requests and project implementations to maintain optimal availability and reliability.

Conduct unit and integration testing to ensure quality

Support other areas of the business including Web pages, portals, and integrations where required

Collaborate with external vendors and internal teams to gather requirements, design solutions, translate needs, and deliver new features, upgrades, and system changes with minimal disruption to business operations.

About You

To be successful in this role you will have:

Hands-on experience designing, implementing and maintaining Microsoft Dynamics 365 CE including: System integrations, plug-ins, scripts, forms & customisations, data mapping, workflows, and API-based connections

Tertiary qualification in Computer Science, IT, or related field

Experience with Agile/Scrum and/or Waterfall methodologies

Strong problem-solving skills, a proactive mindset, and the ability to work both independently and collaboratively across teams whilst taking initiative.

Strong communication and relationship skills

Willingness to develop skills in data platforms such as Azure Data Factory, Data Lake, Power BI, and Microsoft Fabric.


Essential Technical Skills:

·         Dynamics 365 CE development

·         Power Platform (Power Apps, Power Portals, Power Automate)

·         JavaScript, C#, Python, HTML/CSS

·         Azure DevOps, Pipelines, Releases,

Desirable Technical Skills:

·         MS Azure Integration services

·         Power BI, Power Query

·         MS SQL, Data Factory/Fabric exposure

·         Microsoft certifications in Dynamics 365 Customer Engagement (CRM)Microsoft Azure Fundamentals (AZ-900)

·         Microsoft Power Platform Fundamentals (PL-900)

·         Certifications such as: PL-100, PL-200, or PL-400 certification would be advantageous

 This role may involve some after-hours support.

 How to Apply:

If you would like to join the team, visit our website at https://www.motorsport.org.au/ to access the Position Description under ‘About / Careers’. Please email your resume and a brief cover letter summarising your response to the selection criteria (as outlined in the Position Description) to Human Resources at recruitment@motorsport.org.au.  Applications close 5pm Tuesday 10th March.

 Motorsport Australia embraces diversity of gender, age, ethnicity, race, cultural background, disability, religion and sexual orientation. Applicants from diverse backgrounds are welcome and encouraged to submit their applications. Motorsport Australia is committed to making motorsport welcoming, safe and inclusive for all. We prioritise the wellbeing of children participating in our sport, who have a right to take part in sport in a safe, positive and enjoyable environment.

 We are equally committed to removing barriers and improving the employment prospects of people with visible or invisible disabilities. We encourage you to share any support and adjustments you need to be your best and participate equitably in our recruitment process. We understand sharing your needs with us can be daunting, so if you have questions before or during your application, we welcome you to get in touch at recruitment@motorsport.org.au. Anything you tell us will be kept completely confidential."
90396755,Data Engineer - Azure,FourQuarters Recruitment,https://www.seek.com.au/job/90396755?type=standard&ref=search-standalone&origin=jobCard#sol=7b043e2e7f4635d9d35822c589504a206db780d3,4h ago,4.0,2026-02-17T22:00:00+00:00,Sydney NSW (Hybrid),Other (Information & Communication Technology),Contract/Temp,800 package daily rate,"The Company:
Our client, an established Australian organisation is looking for an Azure Data Engineer to work on data projects within their enterprise organisation. You will thrive in a fast-paced & collaborative environment. You will be Sydney based and be able to work in the office up to 3 days per week.
The initial contract length is 6 months with an opportunity to be extended.

The Role:

Collaborate within a cross functional team to understand business requirements and translate into technical solutions. 
Develop and maintain data ingestion, integration, and transformation processes to support data use cases.
Transform raw data into a useable format; cleaning, validating and enriching in preparation for reporting and analytics.
Design and develop scalable data pipelines, ensuring seamless data flow and optimisation.
Creation of documentation and guidelines for data pipelines and infrastructure.
Your Skillset:

Proven hands-on expertise in the Azure technical stack including Synapse, Azure Data Factory, ADLS, Azure Data Lake, SQL, PySpark
Strong knowledge of data warehousing, data lakes and ETL of large data sets within an enterprise environment. 
Advanced SQL query writing skills & stored procedures.
DBT & Python experience highly regarded.
Proven hands-on experience with AI coding tools.
Enjoys working within a collaborative team and able to build good relationships with business and technical stakeholders. 
You must have full working rights within Australia and be Sydney based to be considered for this opportunity."
